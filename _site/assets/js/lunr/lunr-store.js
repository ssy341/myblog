var store = [{
        "title": "维修记-修屏幕灯管",
        "excerpt":"现象：电脑运行一段时间屏幕黑掉初步判断：由于电脑已有几年，再加上夏天温度高，导致显卡芯片温度太高，致芯片烧毁，运行不稳定，或者是排线松动判断依据:打开电脑，运行一段时间，发现屏幕黑暗，然后重新关机，致电脑恢复平常温度，再开机，正常，过一会儿再出现黑屏，通过安装温度检测软件，得知显卡的温度并不是很高，然后对显示屏上下开关，也不能点亮屏幕于。是对之前的判断提出质疑，最终仔细发现，电脑黑屏后，在强光下依然可见桌面，有次可见是屏幕的灯管坏了。ps：液晶显示器的灯管使用时间长，容易老化，随着时间的推移，会越来越不稳定，导致开机一段时间，屏幕黑掉判断结果：显示器灯管坏了解决办法:更换灯管附维修截图:____最后谢谢朋友对我的信任，我会做得越来越好！","categories": ["other"],
        "tags": ["更换液晶屏灯管"],
        "url": "http://www.thxopen.com/other/2013/06/29/fix-screen-light.html",
        "teaser":null},{
        "title": "维修记-修屏幕",
        "excerpt":"今天要介绍的可真是悲惨啊，废话不说，先来张图，让我们一起可怜可怜她屏幕是笔记本最最脆弱的地方，所以大家不要用一阳指去点点点她，要是修得正果，你的屏幕就会像这样 可能比这更厉害。不过我不知道我朋友这个是怎么弄的。拿到本本，先打开电脑，静静等待，最后听到熟悉的windows启动的声音，证明电脑其他地方没有问题，二话不说，换屏，看下图先拆……接下来变个魔术，1，2，3……我变哈哈，很神奇吧，显示屏好了，壳也装好了~~~大功告成！告诫那些对本本不温柔的人，如果你对她不温柔 ，她就用最丑陋的一面对着你……","categories": ["other"],
        "tags": ["更换液晶屏"],
        "url": "http://www.thxopen.com/other/2013/07/04/fix-screen.html",
        "teaser":null},{
        "title": "在intellij idea下远程调试项目",
        "excerpt":"  1，首先发布一个和本地一模一样的代码到服务器，假设到 f:/bjhgtest（最后有说明）  2，打开服务器下tomcat安装目录bin文件夹下的catalina.bat，加入以下代码：set JAVA_OPTS=%JAVA_OPTS%  -server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,address=54341,server=y,suspend=nset JAVA_OPTS=%JAVA_OPTS%  -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=1099 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false  3，配置intellij，首先为项目添加一个remote tomcat      4,加入项目        5,配置jvm debug监听的端口  和上面修改的配置文件一致:set JAVA_OPTS=%JAVA_OPTS%  -server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,address=54341,server=y,suspend=n  6,启动服务器的tomcat，可以看到以下信息启动本地的tomcat,开始调试本地tomcat会打印如下日志：验证是否成功：我在登陆这段代码上打上断点，然后我访问远程的项目，在登陆的时候，进入断点，远程调试成功~需要注意的是本地的输出class路径要和服务器的上一致。本地的：服务器的：这样直接调试服务器上的代码，出现问题后就容易解决，一般服务器的运行环境是很难在本地模拟的，远程调试就不会有那样的问题了，而且还很方便","categories": ["ide"],
        "tags": ["intellij","远程调试","tomcat"],
        "url": "http://www.thxopen.com/ide/2013/10/17/intellij-idea-remote-debug-project.html",
        "teaser":null},{
        "title": "查看jquery的版本号",
        "excerpt":"在chrome控制台输入$.fn.jquery即可显示jquery的版本","categories": ["javascript"],
        "tags": ["jQuery"],
        "url": "http://www.thxopen.com/javascript/2013/12/13/veiw_jQuery_vesion.html",
        "teaser":null},{
        "title": "git基本操作",
        "excerpt":"git clone git@github.com:ssy341/myblog.git  克隆项目到本地（项目名称即为文件夹名称）git remote add origin git@github.com:你的github用户名/你的github项目名.gitgit branch 查看当前分支git pull origin master(分支名)git add * 加入所有文件到缓存区git commit -m “注释”git push -u origin master(分支名称)图片来自网络参考:如何生成公钥","categories": ["git"],
        "tags": ["git基本操作命令"],
        "url": "http://www.thxopen.com/git/2013/12/18/git.html",
        "teaser":null},{
        "title": "Datatables基本使用",
        "excerpt":"  0配置datatables  Datatables（数组数据源）  datatables增删改查0配置datatables                标题        地址                        Datatables中文网        http://datatables.club/                Datatables中文网博客        http://datatables.club/blog/        Datatables（数组数据源）                标题        地址        操作                datatables增删改查                        标题        地址        操作        操作                            ×                信息                                                        标题：                                         地址：                                     确定        保存        取消            ","categories": ["javascript"],
        "tags": ["Datatables"],
        "url": "http://www.thxopen.com/javascript/2013/12/18/DataTables_Demo.html",
        "teaser":null},{
        "title": "方法命名务必避开关键字",
        "excerpt":"我在js里定义了如下方法function clear(){    alert(123);}html里如下调用&lt;button onclick=\"clear()\"&gt;清除&lt;/button&gt;但是死活不打印123，查看控制台后有如下提示：document.clear() is deprecated. This method doesn’t do anything.```查阅资料后，得知clear本为浏览器的内置方法，现在已经废弃了，但是少部分浏览器还支持，如果使用这个，可能会导致程序异常 更改方法名后，程序正常参考: Document.clear","categories": ["javascript"],
        "tags": ["Document.clear"],
        "url": "http://www.thxopen.com/javascript/2013/12/19/clear_error.html",
        "teaser":null},{
        "title": "linux查看文件基本命令 ls pwd",
        "excerpt":"如果不清楚命令的具体用法，可以在命令后跟上 --help如果记不起命令了，直接输入 help列出当前目录下的文件：lsls -l 列出文件的详细信息ls -tl 按时间排序列出文件ls -trl把最近修改的文件列在最后通用的做法ls -l |sort +[r]nn用日期所在列的 列数－1 替代一下，r代表反向排序pwd 列出当前路径","categories": ["linux"],
        "tags": ["linux命令","鸟哥私房菜"],
        "url": "http://www.thxopen.com/linux/2013/12/26/Linux-basic.html",
        "teaser":null},{
        "title": "linux如果获取帮助 help --help",
        "excerpt":"如果不清楚命令的具体用法，可以在命令后跟上 --help如果记不起命令了，直接输入 help","categories": ["linux"],
        "tags": ["linux命令","鸟哥私房菜"],
        "url": "http://www.thxopen.com/linux/2013/12/26/Linux-help.html",
        "teaser":null},{
        "title": "java的split方法使用问题",
        "excerpt":"首先看如下代码import org.apache.commons.lang3.StringUtils;import org.junit.Test; public class StrTest {    @Test    public void sterTst(){        String ster = \"1-1-101|admin\";        System.out.println(ster.split(\"|\")[0]);        System.out.println(ster.split(\"|\")[1]);        System.out.println(StringUtils.split(ster,\"|\")[0]);        System.out.println(StringUtils.split(ster,\"|\")[1]);    }}执行结果如下：1-1-1-101admin很奇怪，我想把1-1-101和admin分开，直接使用String类的split方法确得不到我想要的结果，而使用工具类却可以，这是怎么回事，查询java api后明白了public String[] split(String regex)可以看出参数是regex正则表达式，如果直接使用split方法来处理|的话，还需要转义，否则直接使用|作为分割符号得不到正确结果，如下：String[] strarr = \"1-1-101|admin\".split(\"\\\\|\");这样就能达到和工具类一样的结果了虽然split是平时用的比较频繁的方法，但恰恰容易犯错，以后使用方法前先看看api，就不会犯这个低级错误了","categories": ["java"],
        "tags": ["split"],
        "url": "http://www.thxopen.com/java/2014/03/05/java-split.html",
        "teaser":null},{
        "title": "linux 文件操作命令 rmdir mkdir rm",
        "excerpt":"rmdir 删除一个空的目录● -v 选项提示删除操作成功● -p 选项如果一个目录及其子目录都是空的，其中在删除最子目录的时候，使用-p选项，则这些相关的目录都会被删除掉。mkdir filename 新建文件夹rmdir filename 删除目录rm -rf filename 删除文件/目录cp -r  a.txt /home 复制文件或目录语法：cp [参数] 源文件目录 目标文件或目录","categories": ["linux"],
        "tags": ["linux命令","鸟哥私房菜"],
        "url": "http://www.thxopen.com/linux/2014/03/26/Linux-file.html",
        "teaser":null},{
        "title": "linux 文件解压、压缩 tar zip",
        "excerpt":"tar/zip 解压tar xvfz jdk.tar.gzzip -r 1.zip a.txt ruleunzip yasuo.zipunzip abc\\?.zip` ?表示一个字符，如果用*表示任意多个字符unzip -v large.zipunzip -t large.zipunzip -j music.zip","categories": ["linux"],
        "tags": ["linux命令","鸟哥私房菜"],
        "url": "http://www.thxopen.com/linux/2014/03/26/Linux-tar-zip.html",
        "teaser":null},{
        "title": "执行keystone-manage db_sync错误",
        "excerpt":"最近学习openstack，事情总是不会想象的那么好，挫折总会有,我的系统是ubuntu12.0.4,执行keystone-manage db_sync报如下错误：Traceback (most recent call last):  File \"/usr/bin/keystone-manage\", line 28, in &lt;module&gt;    cli.main(argv=sys.argv, config_files=config_files)  File \"/usr/lib/python2.7/dist-packages/keystone/cli.py\", line 148, in main    return run(cmd, (args[:1] + args[2:]))  File \"/usr/lib/python2.7/dist-packages/keystone/cli.py\", line 134, in run    return CMDS[cmd](argv=args).run()  File \"/usr/lib/python2.7/dist-packages/keystone/cli.py\", line 36, in run    return self.main()  File \"/usr/lib/python2.7/dist-packages/keystone/cli.py\", line 55, in main    driver = utils.import_object(getattr(CONF, k).driver)  File \"/usr/lib/python2.7/dist-packages/keystone/common/utils.py\", line 60, in import_object    __import__(import_str)TypeError: __import__() argument 1 must be string, not None解决办法：在执行命令前加上sudo，获取到管理员权限即可，这是因为/etc/keystone/文件夹有权限，普通用户无法直接访问，而执行keystone-manage db_sync命令需要使用到keystone的配置文件：/etc/keystone/keystone.conf 所以导致了此错误参考网址:tools/openstack_ubuntu install fails on Ubuntu 12.04","categories": ["openstack"],
        "tags": ["keystone"],
        "url": "http://www.thxopen.com/openstack/2014/03/27/openstack_FAQ.html",
        "teaser":null},{
        "title": "登陆openstack提示You are not authorized for any projects.",
        "excerpt":"一路配置过来，安装keystone glance nova 最后能打开主页面，我输入登录名和密码提示我没有授权任何project下面是我执行的 keystone_data.sh#!/bin/sh## Keystone Datas## Description: Fill Keystone with datas.# Mainly inspired by http://www.hastexo.com/resources/docs/installing-openstack-essex-20121-ubuntu-1204-precise-pangolin# Written by Martin Gerhard Loschwitz / Hastexo# Modified by Emilien Macchi / StackOps## Support: openstack@lists.launchpad.net# License: Apache Software License (ASL) 2.0##ADMIN_PASSWORD=${ADMIN_PASSWORD:-password}ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}SERVICE_PASSWORD=${SERVICE_PASSWORD:-$ADMIN_PASSWORD}export SERVICE_TOKEN=\"1234567890\"export SERVICE_ENDPOINT=\"http://localhost:35357/v2.0\"SERVICE_TENANT_NAME=${SERVICE_TENANT_NAME:-service}get_id () {    echo `$@ | awk '/ id / { print $4 }'`}# TenantsADMIN_TENANT=$(get_id keystone tenant-create --name=admin)SERVICE_TENANT=$(get_id keystone tenant-create --name=$SERVICE_TENANT_NAME)DEMO_TENANT=$(get_id keystone tenant-create --name=demo)INVIS_TENANT=$(get_id keystone tenant-create --name=invisible_to_admin)# UsersADMIN_USER=$(get_id keystone user-create --name=admin --pass=\"$ADMIN_PASSWORD\" --email=admin@domain.com)DEMO_USER=$(get_id keystone user-create --name=demo --pass=\"$ADMIN_PASSWORD\" --email=demo@domain.com)# RolesADMIN_ROLE=$(get_id keystone role-create --name=admin)KEYSTONEADMIN_ROLE=$(get_id keystone role-create --name=KeystoneAdmin)KEYSTONESERVICE_ROLE=$(get_id keystone role-create --name=KeystoneServiceAdmin)# Add Roles to Users in Tenantskeystone user-role-add --user-id $ADMIN_USER --role-id $ADMIN_ROLE --tenant-id $ADMIN_TENANTkeystone user-role-add --user-id $ADMIN_USER --role-id $ADMIN_ROLE --tenant-id $DEMO_TENANTkeystone user-role-add --user-id $ADMIN_USER --role-id $KEYSTONEADMIN_ROLE --tenant-id $ADMIN_TENANTkeystone user-role-add --user-id $ADMIN_USER --role-id $KEYSTONESERVICE_ROLE --tenant-id $ADMIN_TENANT# The Member role is used by Horizon and SwiftMEMBER_ROLE=$(get_id keystone role-create --name=Member)keystone user-role-add --user-id $DEMO_USER --role-id $MEMBER_ROLE --tenant-id $DEMO_TENANTkeystone user-role-add --user-id $DEMO_USER --role-id $MEMBER_ROLE --tenant-id $INVIS_TENANT# Configure service users/rolesNOVA_USER=$(get_id keystone user-create --name=nova --pass=\"$SERVICE_PASSWORD\" --tenant-id $SERVICE_TENANT --email=nova@domain.com)keystone user-role-add --tenant-id $SERVICE_TENANT --user-id $NOVA_USER --role-id $ADMIN_ROLEGLANCE_USER=$(get_id keystone user-create --name=glance --pass=\"$SERVICE_PASSWORD\" --tenant-id $SERVICE_TENANT --email=glance@domain.com)keystone user-role-add --tenant-id $SERVICE_TENANT --user-id $GLANCE_USER --role-id $ADMIN_ROLESWIFT_USER=$(get_id keystone user-create --name=swift --pass=\"$SERVICE_PASSWORD\" --tenant-id $SERVICE_TENANT --email=swift@domain.com)keystone user-role-add --tenant-id $SERVICE_TENANT --user-id $SWIFT_USER --role-id $ADMIN_ROLERESELLER_ROLE=$(get_id keystone role-create --name=ResellerAdmin)keystone user-role-add --tenant-id $SERVICE_TENANT --user-id $NOVA_USER --role-id $RESELLER_ROLEQUANTUM_USER=$(get_id keystone user-create --name=quantum --pass=\"$SERVICE_PASSWORD\" --tenant-id $SERVICE_TENANT --email=quantum@domain.com)keystone user-role-add --tenant-id $SERVICE_TENANT --user-id $QUANTUM_USER --role-id $ADMIN_ROLECINDER_USER=$(get_id keystone user-create --name=cinder --pass=\"$SERVICE_PASSWORD\" --tenant-id $SERVICE_TENANT --email=cinder@domain.com)keystone user-role-add --tenant-id $SERVICE_TENANT --user-id $CINDER_USER --role-id $ADMIN_ROLE执行完上面的，用命令查看 keystone user-list   keystone role-list  keystone tenant-list 均有值 ，这是为什么呢？根据错误提示“没有被授权任何项目”，我联想到是不是user和role没有进行关联呢？打开keystone实例，总共10张表，分别为：  ec2_credential  ENDPOINT  metadata  migrate_version  role  service  tenant  token  user  user_tenant_membership我一个表一个表查看，发现user_tenant_membership这张表有两个字段user_id和tenant_id，但是没有值，我查看表结构发现时外键关联的，我尝试把user和tenant进行关联，重新登录，竟然ok了分析：初次接触openstack，太多东西不明白，对照书上操作，新的技术更新比较快，书上的内容就不同步了，以上的keystone datas 应该是少添加了user的权限或添加错误，或许还有其他问题，不过暂时还没有发现，再以后的操作过程中再记录下来","categories": ["openstack"],
        "tags": ["keystone"],
        "url": "http://www.thxopen.com/openstack/2014/03/28/openstack_login_error_note.html",
        "teaser":null},{
        "title": "ubuntu server下建立分区表/分区/格式化/自动挂载",
        "excerpt":"流程为：新建分区–》格式化分区–》挂载分区首先弄明白分区的定义，我在网上找到MBR和GPT分区的介绍：MBR分区（主引导记录）表：支持最大卷：2T （T; terabytes,1TB=1024GB）分区的设限：最多4个主分区或3个主分区加一个扩展分区。GPT分区（GUID分区表）表：支持最大卷：18EB，（E：exabytes,1EB=1024TB）每个磁盘最多支持128个分区第一：新建分区在linux下有fdisk和parted命令，由于fdisk不支持gpt，需要使用parted来对硬盘进行接下来的操作（ps：使用fdisk命令，会有下面的警告信息：WARNING: GPT (GUID Partition Table) detected on ‘/dev/sda’! The util fdisk doesn’t support GPT. Use GNU Parted.)  以下所有操作本人已经操作过，显示的信息略有不同。数据无价，操作前请备份好数据。不过首先要通过fdisk查看当前系统识别的硬盘smotive@ubuntu-nas:~$ sudo fdisk -l[sudo] password for smotive: Disk /dev/sda: 320.1 GB, 320072933376 bytes255 heads, 63 sectors/track, 38913 cylinders, total 625142448 sectorsUnits = 扇区 of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisk identifier: 0x000109ef   设备 启动      起点          终点     块数   Id  系统/dev/sda1   *        2048   617381887   308689920   83  Linux/dev/sda2       617383934   625141759     3878913    5  扩展Partition 2 does not start on physical sector boundary./dev/sda5       617383936   625141759     3878912   82  Linux 交换 / SolarisWARNING: GPT (GUID Partition Table) detected on '/dev/sdb'! The util fdisk doesn't support GPT. Use GNU Parted.Disk /dev/sdb: 500.1 GB, 500107862016 bytes255 heads, 63 sectors/track, 60801 cylinders, total 976773168 sectorsUnits = 扇区 of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0xd87cd87c   设备 启动      起点          终点     块数   Id  系统/dev/sdb1               1   976773167   488386583+  ee  GPT\t  --这里显示不同，是因为我已经操作过了，对照完成下面的操作即可 ,/dev/sdb1 在下面将会用到可以看出系统识别了两个硬盘 /dev/sda &amp; /dev/sdb,现在我要把/dev/sdb 进行建立分区表，分区和格式化并让系统自动挂载smotive@ubuntu-nas:~$ sudo parted /dev/sdbGNU Parted 2.3使用 /dev/sdb欢迎使用 GNU Parted! 输入 'help'可获得命令列表.(parted)  mklabel gpt 此时会提示你此操作会删掉所有数据，是否继续，这里输入yes，执行完成后，再输入打印命令，查看已经建立好分区表的硬盘信息(parted) printModel: ATA WDC WD5000AADS-0 (scsi)磁盘 /dev/sdb: 500GBSector size (logical/physical): 512B/512B分区表：gpt数字  开始：  End    大小   文件系统  Name     标志 1    17.4kB  500GB  500GB  ext4      primary     --在实际操作过程这个是暂时不会显示，这里由于我的硬盘已经执行过操作了接下来分区，输入如下命令mkpart primary 0 -1这个代表把整个硬盘作为一个分区使用，在执行的时候会提示你是否继续，这里选择yes，之后会警告，分区后的对齐不能达到最佳性能，忽略or取消，这里忽略，然后再打印信息(parted) printModel: ATA WDC WD5000AADS-0 (scsi)磁盘 /dev/sdb: 500GBSector size (logical/physical): 512B/512B分区表：gpt数字  开始：  End    大小   文件系统  Name     标志 1    17.4kB  500GB  500GB  ext4      primary   --分区完后这里即显示，但是文件系统还是空白，接下来需要格式化才行到这里，建立分区表，分区就完成了，退出parted(parted)quit                                                             Information: You may need to update /etc/fstab. --这里的提示就是下面要说的系统启动自动挂载，需要修改   /etc/fstab这个文件现在来格式化硬盘，一块硬盘需要格式化了，才能被系统使用，根据fdisk -l 列出的信息，我需要格式化的设备名称为/dev/sdb1,具体参考上面的信息mkfs.ext4 /dev/sdb1  --把硬盘格式化为ext4的文件系统格式 接下来会自动完成，等待提示成功即可。接下来就是挂载硬盘到系统，windows会有c d e f盘之分，而linux是按文件夹的名称才区别设备的，既然系统要使用这块硬盘，那么就需要建立一个文件夹来和这个硬盘进行关联我在我的主目录下创建一个文件夹mkdir /home/smotive/wd500然后挂载硬盘mount /dev/sdb1 /home/smotive/wd500然后再查看系统挂载信息smotive@ubuntu-nas:~$ df -h文件系统        容量  已用  可用 已用% 挂载点/dev/sda1       290G  2.3G  273G    1% /udev            1.8G  4.0K  1.8G    1% /devtmpfs           731M  420K  730M    1% /runnone            5.0M     0  5.0M    0% /run/locknone            1.8G     0  1.8G    0% /run/shmcgroup          1.8G     0  1.8G    0% /sys/fs/cgroup/dev/sdb1       459G   70M  435G    1% /home/smotive/wd500  --此时硬盘已经挂载到系统，可以存放文件使用了接下来修改/etc/fstab文件让系统重启后自动挂载硬盘，打开文件# /etc/fstab: static file system information.## Use 'blkid' to print the universally unique identifier for a# device; this may be used with UUID= as a more robust way to name devices# that works even if disks are added and removed. See fstab(5).## &lt;file system&gt; &lt;mount point&gt;   &lt;type&gt;  &lt;options&gt;       &lt;dump&gt;  &lt;pass&gt;proc            /proc           proc    nodev,noexec,nosuid 0       0# / was on /dev/sda1 during installationUUID=6ffe07b3-2c5f-4a82-b3b0-bed73c0efe47 /               ext4    errors=remount-ro 0       1# swap was on /dev/sda5 during installationUUID=9eaf6d20-c2cf-407b-b06b-fc93c486634c none            swap    sw              0       0/dev/sdb1       /home/smotive/wd500     ext4    defaults        0       2  #第一列：设备名或者设备卷标名，（/dev/sda10 或者 LABEL=/）#第二列：设备挂载目录        （例如上面的“/”或者“/mnt/D/”）#第三列：设备文件系统       （例如上面的“ext3”或者“vfat”）#第四列：挂载参数     （看帮助man mount）#第五列：指明是否要备份。（0为不备份，1为要备份，一般根分区要备份）#第六列：指明自检顺序。 （0为不自检，1或者2为要自检，如果是根分区要设为1，其他分区只能是2）修改好后保存退出修改完/etc/fstab时，应该用 mount -a将所以设备挂载进行测试 ，这时mount读取/etc/fstab中内容进行挂载，如果/etc/fstab的条目无错误，则mount -a后无显示，表示挂载成功；如有错误，则根据提示排查。我第一次操作由于挂载目录写错导致不能开机，后再网上寻找办法，进入恢复模式修改，具体看这里恢复模式下修改/etc/fatab文件大功告成，以上为本人学习鸟哥私房菜的笔记，同时也参考了网上的资料，希望能给大家带来帮助参考：第八章、Linux 磁盘与文件系统管理ext4介绍Linux 下添加硬盘/新建分区（fdisk + mkfs.ext4 + mount）parted创建GPT分区（fdisk不支持创建GPT分区，GPT支持大于2TB分区，MBR不支持）一次添加硬盘分区并修改/etc/fstab引起的故障","categories": ["linux"],
        "tags": ["parted","鸟哥私房菜","mkfs","ext4","linux","fdisk"],
        "url": "http://www.thxopen.com/linux/2014/03/30/Linux-parted.html",
        "teaser":null},{
        "title": "ubuntu server 恢复模式下修改/etc/fstab文件",
        "excerpt":"由于自己操作不慎，在修改挂载目录信息的时候少些了一个字母，导致系统不能启动，下面介绍怎么在恢复模式下修改/etc/fstab文件首先进入ubuntu server的启动选项，一共四个，第二个就是恢复模式，根据下面的提示，按e键进入启动参数的编辑模式，其中有一句 no recovery nomodeset，把它替换为rw single init=/bin/bash然后按ctrl+x进入系统，接下里的操作都是在root下进行vi /etc/fatab修改完后保存退出，重启系统即可参考：ubuntu 进入单用户模式，修改sudoers权限，修改root密码","categories": ["linux"],
        "tags": ["fstab","鸟哥私房菜"],
        "url": "http://www.thxopen.com/linux/2014/03/30/Linux-recover-etc-fstab.html",
        "teaser":null},{
        "title": "DataTables官方例子引导-入门",
        "excerpt":"下面列举了datatables的基本使用例子0配置开启/屏蔽功能指定列排序（升序/降序）多列自定义排序初始化多个datatables隐藏列表头合并列自定义datatables各个组件的位置（sdom属性）自适应页面大小允许状态保存，下次访问回到上次的状态datatables分页类型设置在x轴设置滚动条在y轴设置滚动条在x轴和y轴同时设置滚动条语言国际化（自定义按钮标签显示）  更多例子参考这里","categories": ["javascript"],
        "tags": ["Datatables"],
        "url": "http://www.thxopen.com/javascript/2014/03/31/Datatables-example-basic.html",
        "teaser":null},{
        "title": "DataTables官方例子引导-4种数据源",
        "excerpt":"下面列举了DataTables支持的四种数据源dom（直接把数据写在html页面上）js数组异步请求(json格式的文件)请求服务器（json数据源）  更多例子参考这里","categories": ["javascript"],
        "tags": ["Datatables"],
        "url": "http://www.thxopen.com/javascript/2014/03/31/Datatables-example-data-source.html",
        "teaser":null},{
        "title": "ajaxFileupLoad多文件上传",
        "excerpt":"打开google 搜索 ‘ajaxFileupload’ ‘多文件上传’ 可以搜到许许多多类似的，那我为什么还要写一下呢？  一个是对之前大神的贡献表示感谢；  二个是自己知识的总结；  三个是自己在原有的基础上改动了下，在此记录，可能帮助其他朋友。用过这个插件的都知道这个插件的基本用法，我就不废话，直接上代码。我需要实现多个文件上传，之前的做法是定义多个不同id的input，然后把ajaxfileuplod方法放在for循环里，这个方法是在网上看到的，我觉得不怎么好，后面在网上找到的，就高级点了，直接改源码（因为作者好久没有跟新了，也确实满足不了要求了）。接下来看看我是怎么改的。引用网上的做法：  1，看没有修改前的代码var oldElement = jQuery('#' + fileElementId);  var newElement = jQuery(oldElement).clone();  jQuery(oldElement).attr('id', fileId);  jQuery(oldElement).before(newElement);  jQuery(oldElement).appendTo(form);很容易看出，这个就是根据id把input加到from里去，那么要实现多个文件上传，就改成下面的样子：if(typeof(fileElementId) == 'string'){      fileElementId = [fileElementId];  }  for(var i in fileElementId){      var oldElement = jQuery('#' + fileElementId[i]);      var newElement = jQuery(oldElement).clone();      jQuery(oldElement).attr('id', fileId);      jQuery(oldElement).before(newElement);      jQuery(oldElement).appendTo(form);  }这样改之后，初始化的代码就要这么写：$.ajaxFileUpload({      url:'/ajax.php',      fileElementId:['id1','id2']//原先是fileElementId:’id’ 只能上传一个  });到这里，确实可以上传多个文件，但是对于我来说新问题又来，多个id，我的界面的文件不是固定的，是动态加载的，那么id要动态生成，我觉得太麻烦，为什么不取name呢？然后把以上代码改为如下：if (typeof(fileElementId) == 'string') {    fileElementId = [fileElementId];}for (var i in fileElementId) {    //按name取值      var oldElement = jQuery(\"input[name=\" + fileElementId[i] + \"]\");    oldElement.each(function () {        var newElement = jQuery($(this)).clone();        jQuery(oldElement).attr('id', fileId);        jQuery(oldElement).before(newElement);        jQuery(oldElement).appendTo(form);    });}这样改了 那么就可以实现多组多个文件上传，接下来看我是怎么应用的。&lt;div&gt;    &lt;img id=\"loading\" src=\"scripts/ajaxFileUploader/loading.gif\" style=\"display:none;\"&gt;    &lt;table cellpadding=\"0\" cellspacing=\"0\" class=\"tableForm\" id=\"calculation_model\"&gt;        &lt;thead&gt;        &lt;tr&gt;            &lt;th&gt;多组多个文件&lt;/th&gt;        &lt;/tr&gt;        &lt;/thead&gt;        &lt;tbody&gt;        &lt;tr&gt;            &lt;td&gt;第一组&lt;/td&gt;            &lt;td&gt;第二组&lt;/td&gt;        &lt;/tr&gt;        &lt;tr&gt;            &lt;td&gt;&lt;input type=\"file\" name=\"gridDoc\" class=\"input\"&gt;&lt;/td&gt;            &lt;td&gt;&lt;input type=\"file\" name=\"caseDoc\" class=\"input\"&gt;&lt;/td&gt;        &lt;/tr&gt;        &lt;/tbody&gt;        &lt;tfoot&gt;        &lt;tr&gt;            &lt;td&gt;                &lt;button class=\"button\" id=\"up1\"&gt;Upload&lt;/button&gt;            &lt;/td&gt;            &lt;td&gt;                &lt;button class=\"button\" id=\"addInput\"&gt;添加一组&lt;/button&gt;            &lt;/td&gt;        &lt;/tr&gt;        &lt;/tfoot&gt;    &lt;/table&gt;&lt;/div&gt;          /**  * Created with IntelliJ IDEA.  * User: Administrator  * Date: 13-7-3  * Time: 上午9:20  * To change this template use File | Settings | File Templates.  */  $(document).ready(function () {      $(\"#up1\").click(function(){          var temp = [\"gridDoc\",\"caseDoc\"];          ajaxFileUpload(temp);      });        $(\"#addInput\").click(function(){          addInputFile();      });    });    //动态添加一组文件  function addInputFile(){      $(\"#calculation_model\").append(\" &lt;tr&gt;\"+          \"&lt;td&gt;&lt;input type='file'  name='gridDoc' class='input'&gt;&lt;/td&gt;   \"+          \"&lt;td&gt;&lt;input type='file' name='caseDoc' class='input'&gt;&lt;/td&gt; \"+          \"&lt;/tr&gt;\");  }      //直接使用下载下来的文件里的demo代码  function ajaxFileUpload(id){      //starting setting some animation when the ajax starts and completes      $(\"#loading\").ajaxStart(function(){              $(this).show();          }).ajaxComplete(function(){              $(this).hide();          });        /*      prepareing ajax file upload      url: the url of script file handling the uploaded files      fileElementId: the file type of input element id and it will be the index of  $_FILES Array()      dataType: it support json, xml      secureuri:use secure protocol      success: call back function when the ajax complete      error: callback function when the ajax failed       */      $.ajaxFileUpload({              url:'upload.action',              //secureuri:false,              fileElementId:id,              dataType: 'json'          }      )        return false;    }我action是用的struts2，它的上传是比较简单的，只要声明约定的名字，即可得到文件对象，和名称，代码如下：package com.ssy.action;import com.opensymphony.xwork2.ActionSupport;import org.apache.commons.io.FileUtils;import org.apache.struts2.util.ServletContextAware;import javax.servlet.ServletContext;import java.io.*;import java.text.SimpleDateFormat;import java.util.Date;import java.util.Random;/** * Created with IntelliJ IDEA. * User: Administrator * Date: 13-7-2 * Time: 下午4:08 * To change this template use File | Settings | File Templates. */public class Fileupload extends ActionSupport implements ServletContextAware {    private File[] gridDoc, caseDoc;    private String[] gridDocFileName, caseDocFileName;    private ServletContext context;    public String execute() {        for (int i = 0; i &lt; gridDocFileName.length; i++) {            System.out.println(gridDocFileName[i]);        }        for (int i = 0; i &lt; caseDocFileName.length; i++) {            System.out.println(caseDocFileName[i]);        }        //System.out.println(doc1FileName);          //System.out.println(doc2FileName);          String targetDirectory = context.getRealPath(\"/uploadFile\");        /*         *这里我只取得  第一组的文件进行上传，第二组的类似         */        try {            for (int i = 0; i &lt; gridDoc.length; i++) {                String targetFileName = generateFileName(gridDocFileName[i]);                File target = new File(targetDirectory, targetFileName);                FileUtils.copyFile(gridDoc[i], target);            }        } catch (Exception e) {            e.printStackTrace();        }        return SUCCESS;    }    public File[] getGridDoc() {        return gridDoc;    }    public void setGridDoc(File[] gridDoc) {        this.gridDoc = gridDoc;    }    public File[] getCaseDoc() {        return caseDoc;    }    public void setCaseDoc(File[] caseDoc) {        this.caseDoc = caseDoc;    }    public String[] getGridDocFileName() {        return gridDocFileName;    }    public void setGridDocFileName(String[] gridDocFileName) {        this.gridDocFileName = gridDocFileName;    }    public String[] getCaseDocFileName() {        return caseDocFileName;    }    public void setCaseDocFileName(String[] caseDocFileName) {        this.caseDocFileName = caseDocFileName;    }    /**     * 用日期和随机数格式化文件名避免冲突     *     * @param fileName     * @return     */    private String generateFileName(String fileName) {        System.out.println(fileName);        SimpleDateFormat sf = new SimpleDateFormat(\"yyMMddHHmmss\");        String formatDate = sf.format(new Date());        int random = new Random().nextInt(10000);        int position = fileName.lastIndexOf(\".\");        String extension = fileName.substring(position);        return formatDate + random + extension;    }}写到这里，我就有疑问了，之前的大神改的多文件，为什么还是取id，而且后台是怎么取的，我还是没怎么弄明白，我改的这个代码可行么？是不是存在bug呢？这个还有待考验，如果看出问题，请指出，共同学习修改后的js文件:ajaxfileupload.zip","categories": ["javascript"],
        "tags": ["ajaxFileupload"],
        "url": "http://www.thxopen.com/javascript/2014/03/31/ajaxFileupLoad-multi-file-upload.html",
        "teaser":null},{
        "title": "spring之aop（ThrowsAdvice）拦截指定方法的的异常",
        "excerpt":"近段时间需要对程序的异常做统一的处理，比如写日志或者发送邮件，在网上找了下aop貌似可以解决，经过不懈努力，终于完成了这个效果，异常统一发送邮件，迅速知道异常所在，下面看代码。spring的配置文件：&lt;!-- 异常集中捕获--&gt;    &lt;!-- 自定义拦截异常通知类 --&gt;    &lt;bean id = \"aopTest\" class=\"com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest\"/&gt;        &lt;!-- 自定义异常通知类 --&gt;    &lt;bean id=\"customAdvice\" class=\"com.daja.paymp.presentation.interceptor.ExceptionThrowsAdvice\" /&gt;    &lt;bean class=\"org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator\"&gt;&lt;/bean&gt;     &lt;bean class=\"org.springframework.aop.support.RegexpMethodPointcutAdvisor\"&gt;        &lt;property name=\"advice\"&gt;            &lt;ref bean=\"customAdvice\"/&gt;        &lt;/property&gt;        &lt;property name=\"patterns\"&gt;            &lt;value&gt;com\\.daja\\.paymp\\.infrastructure\\.scheduling\\.service\\.AutoJobService\\.work&lt;/value&gt;        &lt;/property&gt;    &lt;/bean&gt;ExceptionThrowsAdvice.javapackage com.daja.paymp.presentation.interceptor; import java.lang.reflect.Method; import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.aop.ThrowsAdvice; import com.daja.paymp.infrastructure.exception.CustomException; /** * 异常拦截类 aop spring *  * @author smotive *  */ public class ExceptionThrowsAdvice implements ThrowsAdvice {    Logger logger = LoggerFactory.getLogger(ExceptionThrowsAdvice.class);     // Second preference    public void afterThrowing(Method m, Object args[], Object target,            Throwable e) {        try {            throw new CustomException(e,\"自动任务出现异常\");        } catch (CustomException e1) {            e1.printStackTrace();        }    }}接口类： AutoJobService.javapackage com.daja.paymp.infrastructure.scheduling.service; /** *  自动任务公共接口 * @author smotive * */public interface AutoJobService  {    /**     * 自动任务公共执行方法     */    public void work()throws Exception;}实现类：SpringAopTest.javapackage com.daja.paymp.infrastructure.scheduling.service.impl; import org.springframework.stereotype.Service; import com.daja.paymp.infrastructure.scheduling.service.AutoJobService;  public class SpringAopTest implements AutoJobService {     @Override    public void work(){        System.out.print(\"aop拦截测试方法进入\"+(1/0));    }}测试方法类：import org.springframework.context.ApplicationContext;import org.springframework.context.support.FileSystemXmlApplicationContext; import com.daja.paymp.infrastructure.scheduling.service.AutoJobService;public class AopTest {     public static void main(String args[])    {        ApplicationContext context = new FileSystemXmlApplicationContext(\"classpath:applicationContext-aop.xml\");         AutoJobService inter =(AutoJobService)context.getBean(\"aopTest\");        try {            inter.work();        } catch (Exception e) {            e.printStackTrace();        }    }}运行结果：18:04:27 [main] &amp;quot;ERROR&amp;quot; c.d.p.i.exception.CustomException - / by zerocom.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest.work(SpringAopTest.java:12)com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest$$FastClassByCGLIB$$e20000f1.invoke(&amp;lt;generated&amp;gt;)net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:618)com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest$$EnhancerByCGLIB$$d12593c6.work(&amp;lt;generated&amp;gt;)sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)java.lang.reflect.Method.invoke(Method.java:597)org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:318)org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)org.springframework.aop.framework.adapter.ThrowsAdviceInterceptor.invoke(ThrowsAdviceInterceptor.java:124)org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)$Proxy7.work(Unknown Source)AopTest.main(AopTest.java:14) 18:04:28 [main] &amp;quot;INFO &amp;quot; c.d.p.i.common.email.Warning - 邮件顺利送达!com.daja.paymp.infrastructure.exception.CustomException: 自动任务出现异常    at com.daja.paymp.presentation.interceptor.ExceptionThrowsAdvice.afterThrowing(ExceptionThrowsAdvice.java:25)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)    at java.lang.reflect.Method.invoke(Method.java:597)    at org.springframework.aop.framework.adapter.ThrowsAdviceInterceptor.invokeHandlerMethod(ThrowsAdviceInterceptor.java:144)    at org.springframework.aop.framework.adapter.ThrowsAdviceInterceptor.invoke(ThrowsAdviceInterceptor.java:129)    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)    at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)    at $Proxy7.work(Unknown Source)    at AopTest.main(AopTest.java:14)Caused by: java.lang.ArithmeticException: / by zero    at com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest.work(SpringAopTest.java:12)    at com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest$$FastClassByCGLIB$$e20000f1.invoke(&amp;lt;generated&amp;gt;)    at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)    at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:618)    at com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest$$EnhancerByCGLIB$$d12593c6.work(&amp;lt;generated&amp;gt;)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)    at java.lang.reflect.Method.invoke(Method.java:597)    at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:318)    at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)    at org.springframework.aop.framework.adapter.ThrowsAdviceInterceptor.invoke(ThrowsAdviceInterceptor.java:124)    ... 4 morejava.lang.ArithmeticException: / by zero    at com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest.work(SpringAopTest.java:12)    at com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest$$FastClassByCGLIB$$e20000f1.invoke(&amp;lt;generated&amp;gt;)    at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)    at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:618)    at com.daja.paymp.infrastructure.scheduling.service.impl.SpringAopTest$$EnhancerByCGLIB$$d12593c6.work(&amp;lt;generated&amp;gt;)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)    at java.lang.reflect.Method.invoke(Method.java:597)    at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:318)    at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:183)    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150)    at org.springframework.aop.framework.adapter.ThrowsAdviceInterceptor.invoke(ThrowsAdviceInterceptor.java:124)    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)    at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)    at $Proxy7.work(Unknown Source)    at AopTest.main(AopTest.java:14)当指定的方法抛出异常后，spring就会拦截到，做出相应的动作，系统加入这个，出现问题就可以及时察觉了，O(∩_∩)O哈哈~","categories": ["spring"],
        "tags": ["ThrowsAdvice","aop"],
        "url": "http://www.thxopen.com/spring/2014/03/31/spring-aop-ThrowsAdvice.html",
        "teaser":null},{
        "title": "jekyll支持中文解决办法",
        "excerpt":"如果文件里包含中文，会报如下错误：F:\\xxx\\jekyll serverConfiguration file: F:/xxx/_config.yml            Source: F:/xxx       Destination: F:/xxx/_site      Generating... Error reading file F:/xxx/_layouts/post.html: invalidte sequence in GBKerror: invalid byte sequence in GBK. Use --trace to view backtrace在网上找到一个谁都能找到的解决方法，进入如下路径E:\\tools\\ruby\\lib\\ruby\\gems\\2.0.0\\gems\\jekyll-1.5.1\\lib\\jekyll打开convertible.rb文件，找到如下代码：self.content = File.read_with_options(File.join(base, name),                                             merged_file_read_opts(opts))ps:不知道是不是版本的原因，网上的都是self.content = File.read_with_options(File.join(base, name)）没有我上面贴出的后面一节，一开始找到这个代码，不知道如何修改，以为是错误的，去掉后面一节修改为：self.content = File.read_with_options(File.join(base, name), :encoding =&gt; \"utf-8\")然后在_config.yml 文件里加上 encoding: utf-8 属性，中文问题即可解决","categories": ["jekyll"],
        "tags": ["jekyll中文"],
        "url": "http://www.thxopen.com/jekyll/2014/04/17/jekyll-able-gbk.html",
        "teaser":null},{
        "title": "运行jekyll相关命令给出警告",
        "excerpt":"jekyll安装完后，执行jekyll的相关命令，都报如下警告信息：    SafeYAML Warning  ----------------  You appear to have an outdated version of libyaml (0.1.5) installed on your system.  Prior to 0.1.6, libyaml is vulnerable to a heap overflow exploit from malicious YAML payloads.  For more info, see:  https://www.ruby-lang.org/en/news/2014/03/29/heap-overflow-in-yaml-uri-escape-parsing-cve-2014-2525/  The easiest thing to do right now is probably to update Psych to the latest version and enable  the 'bundled-libyaml' option, which will install a vendored libyaml with the vulnerability patched:  gem install psych -- --enable-bundled-libyaml一开始百思不得其解，在网上搜索也没有什么答案，然后仔细看看这些提示，发现在提示最后不是告诉我怎么做么？输入下面命令，问题解决，自己太粗心了gem install psych -- --enable-bundled-libyaml以后遇到错误提示，不要着急，首先简单阅读错误提示，或许就能找到答案 :)","categories": ["jekyll"],
        "tags": ["jekyll"],
        "url": "http://www.thxopen.com/jekyll/2014/04/17/jekyll-error.html",
        "teaser":null},{
        "title": "jekyll安装出现错误",
        "excerpt":"在本地部署jekyll环境，不仅要安装ruby，还要安装devkit（网上都这么说，具体不知什么原因，个人觉得是ruby的开发环境？暂时不知）我电脑上的ruby和devkit是在这里下载 http://rubyinstaller.org/downloads/下载和电脑对应的版本，我是64位的操作系统，下载的  Ruby 2.0.0-p451 (x64)  DevKit-mingw64-64-4.7.2-20130224-1432-sfx.exe这个我在公司的电脑里安装没有问题，但是在我笔记本上同样都是64位的操作系统，却出现问题，配置好ruby的环境后，执行gem install jekyll`会报错，我查看错误日志，gem_make.out 文件如下E:/tools/ruby/bin/ruby.exe extconf.rb\tcreating Makefilemake \"DESTDIR=\" cleanmake \"DESTDIR=\"generating stemmer-i386-mingw32.defcompiling porter.cporter.c: In function 'step1ab':porter.c:233:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:234:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:234:7: warning: passing argument 2 of 'setto' discards 'const' qualifier from pointer target type [enabled by default]porter.c:196:13: note: expected 'char *' but argument is of type 'const char *'porter.c:237:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:238:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:238:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:240:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:240:7: warning: passing argument 2 of 'setto' discards 'const' qualifier from pointer target type [enabled by default]porter.c:196:13: note: expected 'char *' but argument is of type 'const char *'porter.c:241:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:241:7: warning: passing argument 2 of 'setto' discards 'const' qualifier from pointer target type [enabled by default]porter.c:196:13: note: expected 'char *' but argument is of type 'const char *'porter.c:242:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:242:7: warning: passing argument 2 of 'setto' discards 'const' qualifier from pointer target type [enabled by default]porter.c:196:13: note: expected 'char *' but argument is of type 'const char *'porter.c:249:7: warning: passing argument 2 of 'setto' discards 'const' qualifier from pointer target type [enabled by default]porter.c:196:13: note: expected 'char *' but argument is of type 'const char *'porter.c: In function 'step1c':porter.c:257:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c: In function 'step2':porter.c:267:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:267:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:268:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:268:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:270:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:270:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:271:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:271:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:273:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:273:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:275:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:275:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:280:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:280:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:281:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:281:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:282:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:282:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:283:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:283:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:285:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:285:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:286:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:286:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:287:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:287:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:289:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:289:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:290:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:290:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:291:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:291:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:292:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:292:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:294:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:294:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:295:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:295:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:296:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:296:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:298:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:298:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c: In function 'step3':porter.c:308:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:308:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:309:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:309:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:310:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:310:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:312:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:312:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:314:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:314:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:315:14: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:315:14: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c:317:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:317:4: warning: passing argument 2 of 'r' discards 'const' qualifier from pointer target type [enabled by default]porter.c:205:13: note: expected 'char *' but argument is of type 'const char *'porter.c: In function 'step4':porter.c:325:4: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:326:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:327:17: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:328:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:329:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:330:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:331:17: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:332:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:333:17: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:334:17: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:335:17: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:336:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:337:17: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:339:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:340:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:341:17: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:342:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:343:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'porter.c:344:7: warning: passing argument 2 of 'ends' discards 'const' qualifier from pointer target type [enabled by default]porter.c:182:12: note: expected 'char *' but argument is of type 'const char *'compiling porter_wrap.cporter_wrap.c: In function 'stem_word':porter_wrap.c:20:17: warning: unused variable 'i' [-Wunused-variable]linking shared-object stemmer.somake \"DESTDIR=\" install/usr/bin/install -c -m 0755 stemmer.so ./.gem.20140409-3484-15df381installing default stemmer libraries看上去是编译错误，无奈只好求助google，搜了一片，和我这个问题沾不上边，虽然都是同样的错误，不过有个说道可能是devkit版本的问题，抱着试试的心态，我下载了32位的devkit，重新安装jekyll没有出现上述错误，安装一路ok可是公司也是这样的环境能成啊，这是什么原因呢？附：更换ruby源，解决gem install可能安装速度慢或者失败点我","categories": ["jekyll"],
        "tags": ["jekyll"],
        "url": "http://www.thxopen.com/jekyll/2014/04/17/not-install-jekyll.html",
        "teaser":null},{
        "title": "更换ruby源，解决gem install可能安装速度慢或者失败",
        "excerpt":"首先移除默认源$ gem sources --remove https://rubygems.org/再添加淘宝ruby源gem sources -a http://ruby.taobao.org/然后检查是否添加成功gem sources -l*** CURRENT SOURCES ***http://ruby.taobao.org # 请确保只有 ruby.taobao.org参考：http://ruby.taobao.org/","categories": ["jekyll"],
        "tags": ["jekyll","gem sources"],
        "url": "http://www.thxopen.com/jekyll/2014/04/17/speed-gem-source.html",
        "teaser":null},{
        "title": "cannot load such file -- wdm (LoadError)",
        "excerpt":"好像是更新jekyll版本后，自动检测文件更新的命令不是--auto了，而是--watch，这个也好理解，观察，有变动我就更新在之前我都是一个命令窗口执行jekyll server，如果代码有更新了，再到另一个窗口执行jekyll build，时间长了会感觉有点繁琐，于是我就是用--watch参数，结果并不是那么好，执行jekyll server --watch 直接报错，如下：\tF:/xxx&gt;jekyll server --watchConfiguration file: F:/xxx/_config.yml            Source: F:/xxx       Destination: ../deploy      Generating... done. Auto-regeneration: enabledE:/tools/ruby/lib/ruby/site_ruby/2.0.0/rubygems/core_ext/kernel_require.rb:55:in 'require': cannot load such file -- wdm (LoadError)由于对ruby不熟悉，不知道什么意思，google查询  cannot load such file – wdm (LoadError)我点开了排在第一个的网址，于是结果就出了，原来是缺少包，执行gem install wdmwdm – “Windows Directory Monitor” 由这个意思看来貌似是针对windows一个插件，windows文件夹监视器，是不是在linux下就不用安装这个插件就可以了呢？下会在linux下去试试","categories": ["jekyll"],
        "tags": ["jekyll","wdm","gem"],
        "url": "http://www.thxopen.com/jekyll/2014/04/18/jekyll-server-watch-error.html",
        "teaser":null},{
        "title": "jekyll初级入门-jekyll安装运行",
        "excerpt":"  jekyll[‘dʒekil; ‘dʒi:kil] - 官方解释为”把你的纯文本转换为静态网页和blog”,可以读”杰克”或者”吉克’。说到jekyll，我也是无意之间接触到的，以前都用svn管理代码，中国近几年【开源】也是越来越旺盛，不过我们不得不感谢开源给我们带来的好处。说到开源，有些人就会想起github（简单说就是一个在线托管代码的），上面托管了很多优秀的开源软件，给我们程序员带来极大的便利，再次感谢开源。从github开始，我管理代码的方式也从svn到git了，通过后面的学习，发现git确实有独特之处，让我一下子爱上了她。github是外国人做的，她的功能不简单，不仅仅可以托管代码，他还提供了一个生成demo的静态网页的功能，这个就是jekyll的功劳。jekyll是ruby上的一款插件（ps：我对于ruby不熟悉，如果对ruby的描述上有误的还请指出）基于jekyll的性质，在github上搭建免费、不限流量的blog貌似就火起来了，有些程序员爱折腾，不喜欢那些已经很成熟的blog系统，比如c*n,博客等等，即使jekyll提供的功能没有那些丰富、高级，但是用来做blog，我觉得已经非常好了。本站就是使用jekyll，不过在这里给大家提醒下，虽然github上搭建blog是免费的，但是对于我们中国人来说，免费好像就是无限制的压榨，像之前github上就因为一个js的引用，导致中国ip暂时不能访问github，所以我觉得开源，免费我们还得好好像外国人学习。之前我也是在github上弄的，后面还是自己购买了空间，而且速度还快些，毕竟github是国外的服务器。说了这么多废话，还么进入正题呢？呵呵！其实我也是比较爱折腾的，而且希望能一直折腾下去.我在使用jekyll的过程中有遇到问题和困难，自己搜索记录下来，下面就简单讲讲怎么安装jekyll搭建自己的网站。安装jekyll之前要安装ruby环境，ruby安装很简单，在网站下载ruby核心包和开发包，解压后配置下环境变量即可使用，下面是在windows下安装ruby相关包下载地址：http://rubyinstaller.org/downloads/下载自己对应系统的版本即可，我是64位的操作系统，下载的  Ruby 2.0.0-p451 (x64)  DevKit-mingw64-64-4.7.2-20130224-1432-sfx.exe下载完后，把ruby放在d:/tool/ruby下，devkit放在d:/tool/devkit,接下来打开命令行(开始键+r，输入cmd)然后添加环境变量：RUBY_HOME  d:/tool/ruby修改path环境，在最后追加 %RUBY_HOME%/bin保存环境变量，再到命令行输入 ruby --version，可以看到打印出版本信息d:\\tool\\ruby&gt;ruby --versionruby 2.0.0p451 (2014-02-24) [i386-mingw32]这里配置好后，cmd下进入到devkit目录d:\\tool&gt;cd devkitd:\\tool\\devkit&gt;lsbin         devkitvars.bat  dk.rb  include  m.ico  msys.bat  postinstall  sharedevkitvars.ps1  etc    lib      mingw  msys.ico  sbin执行初始化命令, 执行完后可以看到有config.yml文件生成d:\\tool\\devkit&gt;ruby dk.rb initd:\\tool\\devkit&gt;lsbin         devkitvars.bat  dk.rb  include  m.ico  msys.bat  postinstall  shareconfig.yml  devkitvars.ps1  etc    lib      mingw  msys.ico  sbin打开config.yml文件，配置ruby的目录---- d:\\tool\\ruby保存退出，然后再执行ruby dk.rb install到这里ruby的环境已经安装完毕，你可以查看相关信息，比如gem版本d:\\tool\\devkit&gt;gem --version2.2.2本地安装了那些插件E:\\tools\\devkit&gt;gem list --local*** LOCAL GEMS ***bigdecimal (1.2.0)blankslate (2.1.2.4)celluloid (0.15.2)celluloid-io (0.15.0)classifier (1.3.4)colorator (0.1)commander (4.1.6)fast-stemmer (1.0.2)ffi (1.9.3 x86-mingw32)highline (1.6.21)io-console (0.4.2)jekyll (1.5.1)json (1.7.7)liquid (2.5.5)listen (2.7.1, 1.3.1)maruku (0.7.0)minitest (4.3.2)nio4r (1.0.0)parslet (1.5.0)posix-spawn (0.3.8)psych (2.0.5, 2.0.0)pygments.rb (0.5.4)rake (0.9.6)rb-fsevent (0.9.4)rb-inotify (0.9.3)rb-kqueue (0.2.2)rdoc (4.0.0)redcarpet (2.3.0)rubygems-update (2.2.2)safe_yaml (1.0.2)test-unit (2.0.0.0)timers (1.1.0)toml (0.1.1)wdm (0.1.0)yajl-ruby (1.1.0 x86-mingw32)以上步骤安装完后，在命令行输入gem install jekyll，等待自动安装完成，成功之后，再输入jekyll --version查看版本接下来最神奇的时刻来到了，在命令行下随便进入一个目录，这里假设是d:/,输入jekyll new myblog，这时会在该目录下生成一个myblog的文件夹，先不管，命令行进入该目录cd myblog，再输入jekyll serve ,这个时候打开浏览器访问http://localhost:4000怎么样，是不是很神奇，一个简单的站点就完成了，如果你需要更好的使用jekyll，下面有官方的api，有详细的介绍，相信只要按照api来，你很快就会创建出属于自己的站点，just do it如果遇到问题，在文章下方留言，我尽快回复，或者直接发邮件和在微博私信我附：  git基本操作  jekyll英文官方文档  jekyll中文官方文档","categories": ["jekyll"],
        "tags": ["jekyll","jekyll入门"],
        "url": "http://www.thxopen.com/jekyll/2014/04/25/i-and-jekyll.html",
        "teaser":null},{
        "title": "freenas启动过程中屏幕不断提示ata status error",
        "excerpt":"在这之前我有一个疑问，自己没弄懂，如果你知道，请求你在下面留下你的见解，非常感谢！问题就是freenas有必要安装在硬盘上么？官方提供了三种安装方法:  iso-刻录在光盘上然后安装在其他介质上面，比如硬盘、闪存；  img，直接用工具写入到u盘上，u盘插上主机，从u盘启动即可运行freenas；  虚拟机安装文件，下载后，直接用虚拟机软件读取即可。如果freenas要用阵列，那么freenas不能安装在属于阵列的磁盘中，我的主板支持阵列，一共四个sata接口，如果接4个硬盘组成阵列，那freenas只能安装在其他存储设备上，比如u盘，移动硬盘。这么弄我感觉有点别扭，系统的运行肯定不会那么流畅，现在给我的感觉就是要么用阵列，要么不用阵列，好矛盾啊，谁能解答我这个疑问？言归正传，下面我要说的就是我在实验把freenas安装在一个单独的硬盘上遇到的问题和思考我先把从官方下载好的iso镜像刻录在光盘上（文章下面有下载地址），然后设置从光盘启动，电脑有一个80G的硬盘，安装过程很简单，光盘启动后，最后会停留在一个界面，一共四个选项：  第一是安装/升级  第二是进入shell  第三是重启  第四是关闭选择第一项后，直接提示当前识别到的硬盘，一路ok下来(此操作会格式化硬盘数据，操作前请备份好数据)。根据提示信息，最后确定安装freenas到该硬盘，当我点ok的时候，报错，安装失败。这时候我想起在光盘启动freenas的时候，屏幕一直不停的提示”ATA STATUS ERROR”，从提示来看和硬盘有关系，但是不知是什么问题，google一番，还是找到问题解决办法(原文在文章下方)，其中有一楼网友说道是AHCI的问题，要把硬盘模式切换为IDE模式。我切换硬盘模式后，freenas安装成功。帖子中还有其他说法，我没有仔细查看。这个时候通过浏览器访问freenas地址，既可以看到freenas的web GUI界面。之前只接用u盘启动，使用比较起来，感觉安装在硬盘的freenas操作起来要比u盘上的快一些，不知道是错觉还是真的有提升？但是这个时候80g的硬盘就全部用来安装freenas了，如果需要安装插件或者开启共享，需要再挂载其他硬盘，感觉装硬盘有点浪费空间啊，在安装的时候也没有相关操作是划分分区的，或者是我还没找到方法。这样看来把freenas装在u盘上是目前对于我来说最佳办法，不知道大家是不是也是这么做的呢？参考:CAM status: ATA Status ErrorFreeNAS-9.2.1.5-RELEASE-x64.iso","categories": ["nas"],
        "tags": ["freenas"],
        "url": "http://www.thxopen.com/nas/2014/05/29/ata-status-error.html",
        "teaser":null},{
        "title": "8年前的我",
        "excerpt":"高考结束了，每当这个时候我也会想起自己那个时候高考，那真是不堪回首！不好的就让它过去吧，美好的明天在向我招手今天翻以前空间里的日志，看到一篇《寻找目标》，原文如下  我的目标，你离我还有多远 ­？我去问沙子，它告诉我，­还远着呢，要加把劲­；我去问骆驼，它告诉我，就在前面，继续努力吧 ；­我去问小草，它告诉我，不远不远，就要到了；我去问小树，它告诉我，继续继续，马上就到；我去问大树，它告诉我，坚持坚持，你要一直走下去；最后我明白了，在我的生命中是没有终点的，唯独坚持不懈，才是我要做的，为了我的理想一直走下去……看着这个，不由自主笑起来，笑自己的文笔，写的这么差还发到空间里，哈哈……今天我贴出来是想告诉自己，只有坚持不懈，坚持做一件事，把一件事做好，那我离成功就不远了8年前我是一个不太懂事的小孩，8年后我不能还是不懂事的小孩，我要成长起来，为了我的理想竭尽全力，奋斗一生！","categories": ["life"],
        "tags": ["thinking"],
        "url": "http://www.thxopen.com/life/2014/06/09/thinking.html",
        "teaser":null},{
        "title": "mysql以utf-8字符集创建数据库",
        "excerpt":"CREATE DATABASE 的语法：CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name[create_specification [, create_specification] ...]create_specification:[DEFAULT] CHARACTER SET charset_name| [DEFAULT] COLLATE collation_name创建utf-8字符集数据库CREATE DATABASE db_name DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;对已有的数据库更改字符编码ALTER DATABASE db_name DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci","categories": ["database"],
        "tags": ["mysql","database"],
        "url": "http://www.thxopen.com/database/2016/09/22/create-mysql-database-by-utf-8.html",
        "teaser":null},{
        "title": "在mysql中获取表格自增长列（AUTO_INCREMENT）当前的值",
        "excerpt":"使用下面的查询语句获得表格详细的信息SHOW TABLE STATUS FROM `DatabaseName` WHERE `name` LIKE 'TableName' ;使用下面的查询语句获得表格具体的信息SELECT `AUTO_INCREMENT`FROM  INFORMATION_SCHEMA.TABLESWHERE TABLE_SCHEMA = 'DatabaseName'AND   TABLE_NAME   = 'TableName';修改自动增长列的值ALTER TABLE tablename AUTO_INCREMENT = 1;  Reference:      https://stackoverflow.com/questions/15821532/get-current-auto-increment-value-for-any-table  ","categories": ["database"],
        "tags": ["mysql","database"],
        "url": "http://www.thxopen.com/database/2017/03/22/get-auto-increment-value-of-table.html",
        "teaser":null},{
        "title": "如果从一个主机复制文件到另一个主机：rsync",
        "excerpt":"rsync这个命令仅仅用来复制文件，是有点大材小用了，在我了解之后，它的用途太强大了。  rsync 可以作为一个相当棒的异地备援系统的备份指令！ 因为 rsync 可以达到类似『镜相 (mirror) 』的功能！rsync 最早是想要取代 rcp 这个指令的，因为 rsync 不但传输的速度快，而且他在传输时， 可以比对本地端与远程主机欲复制的档案内容，而仅复制两端有差异的档案而已，所以传输的时间就相对的降低很多！虽然我没有去查，但根据上面的描述，我觉得rsync就是remote synchronization的简写，远程同步。没想到让我知道一个这么强大的命令。rsync 语法如下：rsync [-avrlptgoD] [-e ssh] [user@host:/dir] [/local/path]选项与参数：# -v ：观察模式，可以列出更多的信息，包括镜像时的档案档名等；# -q ：与 -v  相反，安静模式，略过正常信息，仅显示错误讯息；# -r ：递归复制！可以针对『目录』来处理！很重要！# -u ：仅更新 (update)，若目标档案较新，则保留新档案不会覆盖；# -l ：复制链接文件的属性，而非链接的目标源文件内容；# -p ：复制时，连同属性 (permission) 也保存不变！# -g ：保存源文件的拥有群组；# -o ：保存源文件的拥有人；# -D ：保存源文件的装置属性 (device)# -t ：保存源文件的时间参数；# -I ：忽略更新时间 (mtime) 的属性，档案比对上会比较快速；# -z ：在数据传输时，加上压缩的参数！# -e ：使用的信道协议，例如使用 ssh 通道，则 -e ssh# -a ：相当于 -rlptgoD ，所以这个 -a 是最常用的参数了！   示例一：将 /etc 的数据备份到 /tmp 底下：rsync -av /etc /tmp说明： 第一次运作时会花比较久的时间，因为首次建立嘛！如果再次备份呢？  示例二：利用 ubuntu 的身份登入 hostname 将home目录复制到本机 /tmprsync -av -e ssh ubuntu@hostname:~ /tmpps： ~和home是一个意思scp的使用参考这里参考：鸟哥私房菜：rsync","categories": ["linux"],
        "tags": ["linux命令","鸟哥私房菜"],
        "url": "http://www.thxopen.com/linux/2017/12/26/how-to-copy-file-to-host-from-host-rsync.html",
        "teaser":null},{
        "title": "如果从一个主机复制文件到另一个主机：scp",
        "excerpt":"在linux下复制文件通常使用cp命令完成，今天介绍另外两个命令scp,rsync在操作服务器的时候，要求把a服务器的文件备份到b服务器上来，最开始想的就是通过ftp先把文件下载的本地，然后上传到另一个服务器，由于文件太大，放弃了这个想法，开始搜索其他办法，在查看了鸟哥私房菜工具书后，得知今天要讲的这两个命令，在两台主机上直接进行复制操作，有一种”山重水复疑无路，柳暗花明又一村”的感觉，我马上试试，果然好用。下面分享下这两个命令的用法：scp [-pr] [-l 速率] file [账号@]主机:目录名  &lt;== 上传scp [-pr] [-l 速率] [账号@]主机:file 目录名   &lt;== 下载# 选项与参数：# -p 保留文件原有的权限信息# -r 复制来源为目录时，可以复制整个目录（包含子目录）# -l 可以限制传输的速率，单位为 Kbits/s ，例如 [-l 800] 代表传输速率 100KKbytes/s   示例一：从远程服务器复制单个文件到本地目录scp ubuntua@hostname:/home/ubuntua/images/1.jpg /home/ubuntub/images/ 说明： 从hostname机器上的/home/ubuntua/images/的目录中下载 1.jpg 文件到本地/home/ubuntub/images/ 目录中  示例二：从远程复制目录到本地目录scp -r ubuntua@hostname:/home/ubuntua/images /home/ubuntub/说明： 从hostname机器上的/home/ubuntua/中下载images目录到本地的/home/ubuntub/目录来。  示例三：复制本地文件到远程机器指定目录scp /home/ubuntub/images/1.jpg ubuntua@hostname:/home/ubuntua/images说明： 复制本地/home/ubuntub/images/目录下的文件1.jpg 到远程机器hostname的/home/ubuntua/images目录  示例四：复制本地目录到远程机器指定目录scp -r /home/ubuntub/images ubuntua@hostname:/home/ubuntua说明： 上传本地目录 /home/ubuntub/images到远程机器hostname上/home/ubuntua的目录中rsync的使用参考这里参考：鸟哥私房菜：scpscp命令使用","categories": ["linux"],
        "tags": ["linux命令","鸟哥私房菜"],
        "url": "http://www.thxopen.com/linux/2017/12/26/how-to-copy-file-to-host-from-host-scp.html",
        "teaser":null},{
        "title": "如何查看磁盘使用情况 du df",
        "excerpt":"查看某目录占用空间情况du -smh folder_name查看磁盘占用df -hT列出某目录下文件占用空间情况du -smh *","categories": ["linux"],
        "tags": ["linux命令","鸟哥私房菜"],
        "url": "http://www.thxopen.com/linux/2017/12/26/how-to-look-up-disk-use-du-df.html",
        "teaser":null},{
        "title": "用Intellij IDEA断点调试远程服务器部署的tomcat项目",
        "excerpt":"回顾在很早之前我已经写过一篇关于 在intellij idea下远程调试项目 的文章，时隔几年，又遇到同样的情况，再参考自己写的东西已经不适用了，我总结了一下，可能是以下几个问题  之前没有写清楚  时隔久远，已经更新了，不再适用当前  没有完全理解，草率就记了，知其然不知其所以然  ……发现疑点一：相同的目录下写上一篇文章的时候环境都是windows，所以可以把代码放在相同的目录下，但是这次环境不一样了一个是windows一个是linux，怎么放到相同的目录下呢？发现疑点二：配置remote tomcat由于第一步已经发生了变化，导致第二步不知道该怎么配置了为了搞清楚这两个疑点，我开始在网上重新查找了相关文章，看了几篇，在其中简书的一篇IDEA远程调试Tomcat文章解决了我的两个疑点拨开云雾见青天  原来并不需要相同的目录，服务器代码位置和本地代码位置没有关系  应该是配置Remote而不是Tomcat Server Remote但不知为什么在上篇文章中我使用Tomcat Server Remote的方式也达到效果，对这个功能的理解应该有误差，后面再说吧。如何使用intellij idea如何远程调试？搞清楚我的疑点，那我就可以进入正题了，如何使用intellij idea如何远程调试？一共分为2步在intellij idea里添加remote配置这一步是配置你要调试的目标，服务器的地址和调试端口选择 【Select Run/Debug configuration】,【Edit Configurations…】点击左上角绿色加号，选择Remote，这里需要填写的就是host和port，然后在【Search sources using module‘s classpath】选择自己的项目复制remote JVM参数，后面需要用到-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000编辑远程服务器tomcat catalina.sh 文件第二步需要打开tomcat远程调试的功能，找到tomcat目录下的bin目录的catalina.sh文件ubuntu@VM-179-90:/home/apache-tomcat-8.5.23/bin$ pwd/home/apache-tomcat-8.5.23/binubuntu@VM-179-90:/home/apache-tomcat-8.5.23/bin$ lsbootstrap.jar  catalina-tasks.xml            configtest.bat  digest.bat        setclasspath.sh  startup.bat      tomcat-native.tar.gz  version.batcatalina.bat   commons-daemon.jar            configtest.sh   digest.sh         shutdown.bat     startup.sh       tool-wrapper.bat      version.shcatalina.sh    commons-daemon-native.tar.gz  daemon.sh       setclasspath.bat  shutdown.sh      tomcat-juli.jar  tool-wrapper.shubuntu@VM-179-90:/home/apache-tomcat-8.5.23/bin$ vi catalina.sh在catalina.sh文件里添加上面复制的jvm参数export JAVA_OPTS='-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000'#   UMASK           (Optional) Override Tomcat's default UMASK of 0027##   USE_NOHUP       (Optional) If set to the string true the start command will#                   use nohup so that the Tomcat process will ignore any hangup#                   signals. Default is \"false\" unless running on HP-UX in which#                   case the default is \"true\"# -----------------------------------------------------------------------------export JAVA_OPTS='-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000'# OS specific support.  $var _must_ be set to either true or false.大概在文件头部注释结束的地方加入，如上所示，保存并退出。ps：需要注意的是address配置的端口8000是能够外网访问的，在后面idea的配置中需要用到的两步配置完毕后，确保远程的tomcat是启动的，然后以Debug方式启动本机的Remote，当IDEA控制台打印如下语句表示成功Connected to the target VM, address: '192.168.0.3:8000', transport: 'socket'这个时候就可以远程调试代码了","categories": ["ide"],
        "tags": ["intellij idea","远程调试","tomcat"],
        "url": "http://www.thxopen.com/ide/2018/02/04/how-to-debug-remote-host-in-intellij.html",
        "teaser":null},{
        "title": "初探oss-事件通知（http endpoint）",
        "excerpt":"初识ossit技术更新换代太快了，我们的思想也必须跟上才行。最近项目里需要用到文件上传，我想想挺简单的啊，关于spring mvc文件上传网上的示例太多了啊，抄一抄，三下五除二就弄好了。好景不长，文件上传问题太多了，虽然从头到尾只出了两个问题，但是用户体验太差了，该怎么办呢？又要支持大文件，又要支持批量，又在web端，感觉再好的插件也拯救不了我了。于是问问公司的前辈，才刚说上几句，前辈就说怎么不用oss？啥？oss是什么？oss（Object Storage Service）即对象存储服务。  海量、安全、低成本、高可靠的云存储服务，提供99.999999999%的数据可靠性。使用RESTful API 可以在互联网任何位置存储和访问，容量和处理能力弹性扩展，多种存储类型供选择全面优化存储成本。了解到这里，我感觉这个就是能拯救我的方案了，立马查阅文档开始试试。确定使用场景根据之前的需求，用户通过网站上传图片到服务器上，然后对图片进行识别处理。改用oss方案后，用户通过使用oss控制台客户端上传文件,项目监听到文件上传完成，再获取资源进行识别处理。使用oss之后逻辑稍有改变，由于文件存放不在同一个地方，这里需要使用oss提供的事件通知来完成。oss事件通知整体架构图如下（借用图一张）由图中可以看到，oss事件通知提供了两种方式：  HttpServer http的方式，即配置一个自己项目的访问地址（公网），当匹配规则匹配到时，往该地址推送数据  MNS Queue 队列的方式，即在项目中订阅oss提供的主题，获取匹配规则推送的数据这里要介绍的是Http方式，后面如果需要再使用队列方式试试。小试牛刀关于oss事件通知的配置，阿里云已经提供了一篇文档 如何使用OSS事件通知功能？，虽然讲的很清楚了（事后才觉得清楚，在没会之前是蒙圈的），但我觉得有必要把一些要点再提一下，少踩坑！第一步：配置事件通知简单理解，就是当bucket有文件变化（上传，覆盖，删除，追加……）时给予通知帮助文档提供的截图和截止文章当前时间已经有所不同，下面带大家一步一步配置首先进入oss管理控制台如下图：选中bucket，右侧页面进入到该bucket的相关信息，然后点击【事件通知】，由于我已经创建了一条规则，所以这里能看到有一条规则点击【创建规则】,在右侧会弹出界面，如下图所示，需要填写规则名称，事件类型，资源描述，接受终端  规则名称          规则的唯一标识，同一账号同一 Region 同一产品下规则名称不能重名。字符必须是英文，数字，横划线，长度不超过 128 个        事件类型          选择您想要触发通知的事件，可以选择多个。同样的事件不可以多次配置在同一资源上      PutObject ，创建/覆盖文件：简单上传      这里我只举一个例子，更多其他的事件类型参考事件类型列表        资源描述          资源描述可以是全名、前缀、后缀以及前后缀，不同资源描述不能有交集。      在本次实例中，我配置了全名，前后缀                  第一行代表固定文件名（movie.zip）上传，就会触发事件          第二行代表以m开头的文件上传，就会触发事件          第三行代表.jpg格式的文件上传，就会触发事件                    在我第一次使用时这个地方没有理解资源描述是什么意思，我上传文件怎么都不触发，直到发送工单，才得知是这里的问题        接受终端          有两种可以选择，一个是http，一个是队列，本篇讲的是http方式，这里我选择http      http://domain.com:8080/oss/listener 地址是公网能够访问到的      填写完毕后，点击底部的【确认】按钮确认添加该规则，确认之后就会像之前看到的，出现一条规则。这里需要注意的是，每添加一条规则会自动创建一条对应的主题，可以在消息服务控制台查看到该主题，如下图：还需要注意的是图中指出的温馨提示,主题实例是会产生费用的到这里，在阿里云控制台配置的工作就已经完成了，接下来要做的就是实现接受消息第二步：接受消息通知在上一步接受终端操作中我配置了一个可以公网访问的地址http://domain.com:8080/oss/listener，他的作用就是当规则匹配之后oss会向该地址发送消息。根据oss技术人员提供的信息，我们可以从 MNS Java SDK 这个页面下载示例代码解压下载后的文件，我们需要关注的是 HttpEndpoint.java 这个文件，这里对该文件代码不做详细的解释，根据自己项目的环境，做相应改动即可我的项目环境是spring mvc，下面贴出我已经调试好的代码：import lombok.extern.slf4j.Slf4j;import org.apache.commons.codec.binary.Base64;import org.apache.http.HttpEntity;import org.apache.http.HttpStatus;import org.apache.http.entity.InputStreamEntity;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.ResponseBody;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.BufferedReader;import java.io.InputStream;import java.io.InputStreamReader;import java.io.UnsupportedEncodingException;import java.util.Enumeration;import java.util.HashMap;import java.util.Locale;import java.util.Map;/** * oss文件上传成功 * * @return */@PostMapping(value = \"/oss/listener\")@ResponseBodypublic ResponseEntity&lt;String&gt; ossfileuploadsuccess(HttpServletRequest request, HttpServletResponse response) {    log.info(\"oss客户端上传文件\");    long start = System.currentTimeMillis();    try {        HttpEntity entity = new InputStreamEntity(request.getInputStream(),                request.getContentLength());        String method = request.getMethod().toUpperCase(Locale.ENGLISH);        String target = request.getRequestURI();        Enumeration&lt;String&gt; headerNames = request.getHeaderNames();        Map&lt;String, String&gt; hm = new HashMap&lt;&gt;();        while (headerNames.hasMoreElements()) {            String name = headerNames.nextElement();            String value = request.getHeader(name);            log.debug(\"{}:{}\", name, value);            hm.put(name, value);        }        //verify request        String certHeader = request.getHeader(\"x-mns-signing-cert-url\");        if (certHeader == null) {            log.info(\"SigningCerURL Header not found\");            return ResponseEntity.status(HttpStatus.SC_BAD_REQUEST).body(\"SigningCerURL Header not found\");        }        String cert = certHeader;        if (cert.isEmpty()) {            log.info(\"SigningCertURL empty\");            return ResponseEntity.status(HttpStatus.SC_BAD_REQUEST).body(\"SigningCertURL empty\");        }        cert = new String(Base64.decodeBase64(cert));        log.info(\"SigningCertURL:\\t\" + cert);        if (!authenticate(method, target, hm, cert)) {            log.info(\"authenticate fail\");            return ResponseEntity.status(HttpStatus.SC_BAD_REQUEST).body(\"authenticate fail\");        }        //parser content of simplified notification        InputStream is = entity.getContent();        BufferedReader reader = new BufferedReader(new InputStreamReader(is));        StringBuffer buffer = new StringBuffer();        String line = \"\";        while ((line = reader.readLine()) != null) {            buffer.append(line);        }        String content = buffer.toString();        String result = null;        byte[] messageBodyAsBytes = content.getBytes();        if (messageBodyAsBytes != null) {            result = new String(Base64.decodeBase64(messageBodyAsBytes), \"UTF-8\");        }        //这里的result就是文件的信息        log.info(\"Simplified Notification: \\n {}\", result);                log.info(\"处理oss文件线程启动完毕,耗时：{}\", System.currentTimeMillis() - start);    } catch (UnsupportedEncodingException var4) {        log.error(\"Not support encoding: UTF-8\", var4);        return ResponseEntity.status(HttpStatus.SC_INTERNAL_SERVER_ERROR).body(\"Not support encoding: UTF-8\");    } catch (Exception e) {        log.error(\"oss文件上传监听系统错误\", e);        return ResponseEntity.status(HttpStatus.SC_INTERNAL_SERVER_ERROR).body(\"system error\");    }    return ResponseEntity.noContent().build();}/** * check if this request comes from MNS Server * * @param method,  http method * @param uri,     http uri * @param headers, http headers * @param cert,    cert url * @return true if verify pass */private Boolean authenticate(String method, String uri, Map&lt;String, String&gt; headers, String cert) {    String str2sign = getSignStr(method, uri, headers);    //System.out.println(str2sign);    //这里需要注意大小写，官方给出的代码这里是大写A，在我实际操作中为小写，到底是什么，需要结合实际情况    String signature = headers.get(\"authorization\");    byte[] decodedSign = Base64.decodeBase64(signature);    //get cert, and verify this request with this cert    try {        //String cert = \"http://mnstest.oss-cn-hangzhou.aliyuncs.com/x509_public_certificate.pem\";        URL url = new URL(cert);        HttpURLConnection conn = (HttpURLConnection) url.openConnection();        DataInputStream in = new DataInputStream(conn.getInputStream());        CertificateFactory cf = CertificateFactory.getInstance(\"X.509\");        Certificate c = cf.generateCertificate(in);        PublicKey pk = c.getPublicKey();        java.security.Signature signetcheck = java.security.Signature.getInstance(\"SHA1withRSA\");        signetcheck.initVerify(pk);        signetcheck.update(str2sign.getBytes());        Boolean res = signetcheck.verify(decodedSign);        return res;    } catch (Exception e) {        e.printStackTrace();        log.warn(\"authenticate fail, \" + e.getMessage());        return false;    }}/** * build string for sign * * @param method,  http method * @param uri,     http uri * @param headers, http headers * @return String fro sign */private String getSignStr(String method, String uri, Map&lt;String, String&gt; headers) {    StringBuilder sb = new StringBuilder();    sb.append(method);    sb.append(\"\\n\");    //注意大小写    sb.append(safeGetHeader(headers, \"content-md5\"));    sb.append(\"\\n\");    //注意大小写    sb.append(safeGetHeader(headers, \"content-type\"));    sb.append(\"\\n\");    //注意大小写    sb.append(safeGetHeader(headers, \"date\"));    sb.append(\"\\n\");    List&lt;String&gt; tmp = new ArrayList&lt;String&gt;();    for (Map.Entry&lt;String, String&gt; entry : headers.entrySet()) {        if (entry.getKey().startsWith(\"x-mns-\")){            tmp.add(entry.getKey() + \":\" + entry.getValue());        }    }    Collections.sort(tmp);    for (String kv : tmp) {        sb.append(kv);        sb.append(\"\\n\");    }    sb.append(uri);    return sb.toString();}private String safeGetHeader(Map&lt;String, String&gt; headers, String name) {        if (headers.containsKey(name)) {            return headers.get(name);        } else {            return \"\";        }    }需要注意的是由于主题默认的重试策略为 EXPONENTIAL_DECAY_RETRY ，上面的程序需要在[5s]之类返回[204]httpcode，否则阿里认为该推送为不成功。即，按照重试规则来重新推送数据直到收到204代码为止代码虽然很多，但是不复杂，其实就是对request进行解析，进行验证，把oss包含信息取出来，最终获取到base64编码的文件信息。第三步：检验成果把项目启动，然后使用oss控制台客户端上传文件当文件上传完毕后，在java控制台打印出如下数据：{  \"events\": [    {      \"eventName\": \"ObjectCreated:PutObject\",      \"eventSource\": \"acs:oss\",      \"eventTime\": \"2018-02-22T08:32:21.000Z\",      \"eventVersion\": \"1.0\",      \"oss\": {        \"bucket\": {          \"arn\": \"acs:oss:cn-beijing:1234346345345345:display-sjf-event-notification-test\",          \"name\": \"display-sjf-event-notification-test\",          \"ownerIdentity\": \"1234346345345345\",          \"virtualBucket\": \"\"        },        \"object\": {          \"deltaSize\": 312148,          \"eTag\": \"D9703079D307A57C4967B30AC36FCA81\",          \"key\": \"20170731095417740.png\",          \"size\": 312148        },        \"ossSchemaVersion\": \"1.0\",        \"ruleId\": \"oss-upload-success-img-http\"      },      \"region\": \"ch-china\",      \"requestParameters\": {        \"sourceIPAddress\": \"10.0.0.0\"      },      \"responseElements\": {        \"requestId\": \"5A815115776D389D9FE118C1\"      },      \"userIdentity\": {        \"principalId\": \"12345678934534534\"      }    }  ]}//参数解释{  \"events\": [    {      \"eventName\": \"\", //事件通知类型      \"eventSource\": \"\", //消息源，固定为\"acs:oss\"      \"eventTime\": \"\", //事件事件，格式为ISO-8601      \"eventVersion\": \"\", //版本号，目前为\"1.0\"      \"oss\": {        \"bucket\": {          \"arn\": \"\", //bucket的唯一标识符，格式为\"acs:oss:region:uid:bucket\"          \"name\": \"\", //bucket名称          \"ownerIdentity\": \"\" //bucket的owner        },        \"object\": {          \"deltaSize\":, //object大小的变化量，比如新增一个文件，这个值就是文件大小，如果是覆盖一个文件，这个值就是新文件与旧文件的差值，因此可能为负数          \"eTag\": \"\", //object的etag，与GetObject()请求返回的ETag头的内容相同          \"key\": \"\", //object名称          \"position\":, //可变项，只有在ObjectCreated:AppendObject事件中才有，表示此次请求开始append的位置，注意是从0开始          \"readFrom\":, //可变项，只有在ObjectDownloaded:GetObject事件中才有，表示文件开始读取的位置，如果不是Range请求，则此项为0，否则则是Range请求的开始字节，注意是从0开始          \"readTo\":,//可变项，只有在ObjectDownloaded:GetObject事件中才有，表示文件最后读取的位置，如果不是Range请求，则此项为文件的大小，否则则是Range请求的结束字节增1          \"size\"://object大小        }        \"ossSchemaVersion\": \"\", //此字段域的版本号，目前为\"1.0\"        \"ruleId\": \"GetObject\" //此事件匹配的规则ID      },      \"region\": \"\", //bucket所在的region      \"requestParameters\": {        \"sourceIPAddress\": \"\" //请求的源IP      },      \"responseElements\": {        \"requestId\": \"\"  //请求对应的requestid      },      \"userIdentity\": {        \"principalId\": \"\"  //请求发起者的uid      },      \"xVars\": {        //oss的callback功能中的自定义参数        \"x:callback-var1\": \"value1\",        \"x:vallback-var2\": \"value2\"      }    }  ]}结语在信息化时代，我们需要跟上时代的步伐，与时俱进。本篇关于oss事件通知的介绍到此结束，希望对家有所帮助。","categories": ["storage"],
        "tags": ["oss","阿里云"],
        "url": "http://www.thxopen.com/storage/2018/02/22/first-time-to-use-oss-events-httpendpoint.html",
        "teaser":null},{
        "title": "在Ubuntu下安装Gitlab",
        "excerpt":"GitLab是由GitLab Inc.开发，使用MIT许可证的基于网络的Git仓库管理工具，且具有wiki和issue跟踪功能。安装Gitlab  1，安装必要的依赖sudo apt-get install -y curl openssh-server ca-certificates  ps: -y 参数代表默认同意安装，不需要再手动输入y继续安装接下来，为了发送提醒邮件，需要安装Postfix。如果你想使用其他方案发送邮件请跳过此步骤，在gitlab安装完成之后配置额外的smtp服务参考»sudo apt-get install -y postfix安装postfix的时候，会出现配置界面，如下所示：Package configuration┌───────────────────────────┤ Postfix Configuration ├───────────────────────────┐│ Please select the mail server configuration type that best meets your needs.  ││                                                                               ││  No configuration:                                                            ││   Should be chosen to leave the current configuration unchanged.              ││  Internet site:                                                               ││   Mail is sent and received directly using SMTP.                              ││  Internet with smarthost:                                                     ││   Mail is received directly using SMTP or by running a utility such           ││   as fetchmail. Outgoing mail is sent using a smarthost.                      ││  Satellite system:                                                            ││   All mail is sent to another machine, called a 'smarthost', for delivery.    ││  Local only:                                                                  ││   The only delivered mail is the mail for local users. There is no network.   ││                                                                               ││ General type of mail configuration:                                           ││                                                                               ││                            No configuration                                   ││                            Internet Site                                      ││                            Internet with smarthost                            ││                            Satellite system                                   ││                            Local only                                         ││                                                                               ││                                                                               ││                     &lt;Ok&gt;                         &lt;Cancel&gt;                     ││                                                                               │└───────────────────────────────────────────────────────────────────────────────┘选择【Internet Site】选项完成本页配置。下一步配置mail_name，如下图所示：Package configuration ┌────────────────────────────────────────────┤ Postfix Configuration ├────────────────────────────────────────────┐ │ The \"mail name\" is the domain name used to \"qualify\" _ALL_ mail addresses without a domain name. This includes  │ │ mail to and from &lt;root&gt;: please do not make your machine send out mail from root@example.org unless             │ │ root@example.org has told you to.                                                                               │ │                                                                                                                 │ │ This name will also be used by other programs. It should be the single, fully qualified domain name (FQDN).     │ │                                                                                                                 │ │ Thus, if a mail address on the local host is foo@example.org, the correct value for this option would be        │ │ example.org.                                                                                                    │ │                                                                                                                 │ │ System mail name:                                                                                               │ │                                                                                                                 │ │ localhost.localdomain                                                                                           │ │                                                                                                                 │ │                                &lt;Ok&gt;                                    &lt;Cancel&gt;                                 │ │                                                                                                                 │ └─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘实际使用中不需要用到邮件通知，所以这里使用默认的地址，回车完成postfix的安装配置。  2，配置软件源由于官网的资源安装会很慢，推荐使用国内的镜像去安装，网上推荐的使用清华大学的镜像信任 GitLab 的 GPG 公钥:curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/null添加清华大学的镜像到/etc/apt/sources.listecho 'deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu xenial main' | sudo tee /etc/apt/sources.list.d/gitlab.listps: 如果是Ubuntu 14.04就把xenial换成trusty，附一张对照表            系统版本      Codename      支持平台                  14.04      trusty      x86_64, i386, aarch64/arm64              16.04      xenial      x86_64, i386        3，安装 gitlab-ce ，虽然换了国内的镜像，但是软件大小有400M，还是需要安装一会儿    sudo apt-get updatesudo apt-get install gitlab-ce      安装完成后出现如下界面：       *.                  *.      ***                 ***     *****               *****    .******             *******    ********            ********   ,,,,,,,,,***********,,,,,,,,,  ,,,,,,,,,,,*********,,,,,,,,,,,  .,,,,,,,,,,,*******,,,,,,,,,,,,      ,,,,,,,,,*****,,,,,,,,,.         ,,,,,,,****,,,,,,            .,,,***,,,,                ,*,.     _______ __  __          __    / ____(_) /_/ /   ____ _/ /_   / / __/ / __/ /   / __ `/ __ \\  / /_/ / / /_/ /___/ /_/ / /_/ /  \\____/_/\\__/_____/\\__,_/_.___/Thank you for installing GitLab!GitLab was unable to detect a valid hostname for your instance.Please configure a URL for your GitLab instance by setting `external_url`configuration in /etc/gitlab/gitlab.rb file.Then, you can start your GitLab instance by running the following command:  sudo gitlab-ctl reconfigureFor a comprehensive list of configuration options please see the Omnibus GitLab readmehttps://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md配置Gitlab  4，配置gitlab实例访问路径编辑gitlab配置文件sudo vi /etc/gitlab/gitlab.rb## GitLab configuration settings##! This file is generated during initial installation and **is not** modified##! during upgrades.##! Check out the latest version of this file to know about the different##! settings that can be configured by this file, which may be found at:##! https://gitlab.com/gitlab-org/omnibus-gitlab/raw/master/files/gitlab-config-template/gitlab.rb.template## GitLab URL##! URL on which GitLab will be reachable.##! For more details on configuring external_url see:##! https://docs.gitlab.com/omnibus/settings/configuration.html#configuring-the-external-url-for-gitlabexternal_url 'http://111.111.111.111/gitlab'把 gitlab.example.com 修改为自己主机的ip或者域名（如果是绑定了域名），由于gitlab默认使用的80端口，这里我们使用nginx代理转发一下在gitlab里配置nginx的监听端口，打开gitlab的配置文件sudo vi /etc/gitlab/gitlab.rb大概在文件中间部分，948行，有如下配置，去掉#注释，修改nil为8888 946 ##! **Override only if you use a reverse proxy** 947 ##! Docs: https://docs.gitlab.com/omnibus/settings/nginx.html#setting-the-nginx-listen-port 948 nginx['listen_port'] = 8888 949配置Nginx代理保存文件退出。接下来配置nginx，打开nginx配置文件sudo vi /etc/nginx/conf.d/default.conf在文件里添加如下配置：upstream git {    server  localhost:8888;}server {    listen 80;    server_name 111.111.111.111;    location /gitlab {        # 设置最大允许上传单个的文件大小        client_max_body_size 1024m;        proxy_redirect off;        #以下确保 gitlab中项目的 url 是域名而不是 http://git，不可缺少        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        # 反向代理到 gitlab 内置的 nginx        proxy_pass http://git/gitlab;        index index.html index.htm;    }}保存退出，重新加载nginx配置sudo nginx -s reload重新加载gitlab配置并重启sudo gitlab-ctl reconfiguresudo gitlab-ctl restart打开必要的服务sudo service sshd startsudo service postfix start查看gitlab运行状态sudo gitlab-ctl statusrun: alertmanager: (pid 26373) 1361s; run: log: (pid 26390) 1361srun: gitaly: (pid 26289) 1362s; run: log: (pid 26306) 1362srun: gitlab-monitor: (pid 26314) 1362s; run: log: (pid 26337) 1361srun: gitlab-workhorse: (pid 32531) 125s; run: log: (pid 26280) 1362srun: logrotate: (pid 25729) 1411s; run: log: (pid 26282) 1362srun: nginx: (pid 32549) 125s; run: log: (pid 26281) 1362srun: node-exporter: (pid 25949) 1399s; run: log: (pid 26388) 1361srun: postgres-exporter: (pid 26397) 1360s; run: log: (pid 26487) 1360srun: postgresql: (pid 25351) 1462s; run: log: (pid 26333) 1362srun: prometheus: (pid 26346) 1361s; run: log: (pid 26366) 1361srun: redis: (pid 25267) 1468s; run: log: (pid 26255) 1363srun: redis-exporter: (pid 26034) 1391s; run: log: (pid 26338) 1361srun: sidekiq: (pid 32456) 137s; run: log: (pid 26258) 1363srun: unicorn: (pid 32631) 115s; run: log: (pid 26334) 1362s打开浏览器，访问 http://111.111.111.111/gitlab 开始使用  Reference      https://zh.wikipedia.org/wiki/Gitlab    https://about.gitlab.com/installation/#ubuntu    https://www.jianshu.com/p/a86a1529d253    https://docs.gitlab.com/omnibus/settings/smtp.html    https://www.jianshu.com/p/4a5877d1e14b    https://www.zybuluo.com/lovemiffy/note/418758  ","categories": ["linux"],
        "tags": ["ubuntu","Gitlab"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-gitlab-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu上安装常用的和Java相关的工具",
        "excerpt":"工作中经常需要在新服务器上搭建环境，项目中用到的工具有Tomcat、RabbitMQ、Nginx、Redis、MySQL、MongoDB、Jenkins、Gitlab。还别说，这几个工具把他安装好配置好，需要花的时间还是挺长的。在多次安装和配置过程中我也遇到一些问题，也总结了些经验。在此纪录下来，方便自己也方便他人。本篇为目录，列出标题，我在单独的文章里再详细介绍每个工具的安装和使用。  在Ubuntu下安装JAVA开发环境  在Ubuntu下安装Tomcat  在Ubuntu下安装RabbitMQ  在Ubuntu下安装Nginx  在Ubuntu下安装MySQL  在Ubuntu下安装Redis  在Ubuntu下安装MongoDB  在Ubuntu下安装Jenkins  在Ubuntu下安装Gitlab上面的方法同样适用 Win10 带的子系统 Bash on Windows ，都是Ubuntu，本人电脑就是直接在子系统里安装这些软件用来开发，比起安装虚拟机要方便很多，希望这一系列文章对大家有所帮助","categories": ["linux"],
        "tags": ["ubuntu","tomcat","rabbitmq","nginx","redis","jdk","mysql","jenkins","gitlab","mongodb"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-java-ee-environment-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu下安装JAVA开发环境(手动)",
        "excerpt":"JDK即Java Development Kit，java开发工具包，是java开发人员开发中需要用到的软件开发工具包。下载JDK在Ubuntu下安装java开发环境有两种途径：  通过apt-get在线安装  下载tar包，自行解压安装本文介绍的是第二种方式  第一步：下载jdk，从官网下载需要的jdk压缩包本次选择jdk8作为演示，下载文件到/home/thxopen/app目录下    thxopen@PC201503302026:~/app$ pwd/home/thxopen/appthxopen@PC201503302026:~/app$ lsjdk-8u211-linux-x64.tar.gz        第二步：解压到当前目录    thxopen@PC201503302026:~/app$ tar -zxvf jdk-8u211-linux-x64.tar.gzthxopen@PC201503302026:~/app$ lsjdk-8u211-linux-x64.tar.gz  jdk1.8.0_211      配置JDK  第三步：配置环境变量    thxopen@PC201503302026:~/app$ sudo vi ~/.bashrc        ps: /.bashrc 代表当前用户下的配置文件，只应用于当前用户，如果使用其他用户，需要重新配置在配置文件的末尾添加如下配置：export JAVA_HOME=/home/thxopen/app/jdk1.8.0_211export JRE_HOME=${JAVA_HOME}/jre  export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib  export PATH=${JAVA_HOME}/bin:$PATH  ps: /home/thxopen/app/jdk1.8.0_211 为jdk解压后的路径，替换成自己检验JDK  第四步：生效配置，检查是否配置成功    thxopen@PC201503302026:~/app$ source ~/.bashrcthxopen@PC201503302026:~/app$ java -versionjava version \"1.8.0_211\"Java(TM) SE Runtime Environment (build 1.8.0_211-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)      返回目录  Reference      https://blog.csdn.net/qq_2300688967/article/details/81702153#  ","categories": ["linux"],
        "tags": ["ubuntu","jdk","java"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-java-on-ubuntu-custom.html",
        "teaser":null},{
        "title": "在Ubuntu下安装JAVA开发环境",
        "excerpt":"JDK即Java Development Kit，java开发工具包，是java开发人员开发中需要用到的软件开发工具包。安装JDK在Ubuntu下安装java开发环境有两种途径：  通过apt-get在线安装  下载tar包，自行解压安装本文介绍的是第一种方式，使用apt-get安装java开发环境  第一步：添加源    thxopen@PC201503302026:~$ sudo add-apt-repository ppa:webupd8team/java        ps: 如果提示 sudo: add-apt-repository: command not found 先执行下面命令      sudo apt-get install python-software-properties    第二步：更新源    thxopen@PC201503302026:~$ sudo apt-get update        第三步：安装jdk，这里选择的是jdk 8    thxopen@PC201503302026:~$ sudo apt-get install oracle-java8-installer          安装过程中，会提示同意条款，输入y即可  ps: 也可以在安装命令后加上-y参数sudo apt-get install oracle-java8-installer -y，表示安装默认同意，则不会出现这些提示  第四步：检查是否安装成功，控制台输出如下，表示安装成功    thxopen@PC201503302026:~$ java -versionjava version \"1.8.0_161\"Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)      返回目录  Reference      http://www.cnblogs.com/a2211009/p/4265225.html    http://blog.csdn.net/yuzaipiaofei/article/details/7281723  ","categories": ["linux"],
        "tags": ["ubuntu","jdk","java"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-java-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu下安装jenkins",
        "excerpt":"Jenkins是一款由Java编写的开源的持续集成工具。在与Oracle发生争执后，项目从Hudson项目复刻。 Jenkins提供了软件开发的持续集成服务。它运行在Servlet容器中（例如Apache Tomcat）。它支持软件配置管理（SCM）工具（包括AccuRev SCM、CVS、Subversion、Git、Perforce、Clearcase和RTC），可以执行基于Apache Ant和Apache Maven的项目，以及任意的Shell脚本和Windows批处理命令。安装Jenkinsjenkins官网提供了在线安装的方式，软件包集成了jetty服务，安装即可访问，非常方便  在安装jenkins之前，确定已经配置了java环境，不同的jenkins版本需要的java环境也不一样      2.54 (2017-04) 或者更新的版本: 需要 Java 8 支持    1.612 (2015-05) 或者更新的版本: 需要 Java 7 支持    添加key到系统    wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add -        添加资源到/etc/apt/sources.list为了方便管理不同软件的安装源，我们新建一个文件jenkins.list，存放在 sources.list.d 目录下    echo 'deb https://pkg.jenkins.io/debian-stable binary/' | sudo tee /etc/apt/sources.list.d/jenkins.list        更新本地包，然后安装jenkins    sudo apt-get updatesudo apt-get install jenkins      配置端口默认情况下，jenkins使用的是8080端口，如果端口没有被其他的程序占用，则可以直接在浏览器访问http://127.0.0.1:8080，开始使用jenkins。如果端口被其他程序占用，可以通过修改jenkins的配置文件（在 /etc/default/ 目录下），更改端口sudo vi /etc/default/jenkins打开文件，文件尾部部分，如下所示...# port for HTTP connector (default 8080; disable with -1)HTTP_PORT=8080...把8080修改成自己想要的，保存退出，重新启动服务停止jenkins服务（可能会要求你输入当前用户的密码）/etc/init.d/jenkins stopCorrect java version found[....] Stopping jenkins (via systemctl): jenkins.service==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ===Authentication is required to stop 'jenkins.service'.Authenticating as: ubuntu,,, (ubuntu)Password:==== AUTHENTICATION COMPLETE ===. ok重新启动jenkins服务，同样需要输入密码/etc/init.d/jenkins startCorrect java version found[....] Starting jenkins (via systemctl): jenkins.service==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ===Authentication is required to start 'jenkins.service'.Authenticating as: ubuntu,,, (ubuntu)Password:==== AUTHENTICATION COMPLETE ===. ok初始化jenkins为了确保管理员安全地安装 Jenkins，首次访问jenkins会要求输入密码才能继续，密码存放在 /var/lib/jenkins/secrets/initialAdminPassword查看密码，输入到密码框进行下一步sudo cat /var/lib/jenkins/secrets/initialAdminPassword点击继续后，会有一个等待时间，然后进入新手入门向导界面，如下图所示：这里我们选择默认选项，推荐安装插件，确定后进入安装界面，如下图所示：插件安装大概要持续一会儿，慢慢等待安装完成。插件安装完成之后需要配置一个管理员用户，创建一个账户，保存下一步。接下来进行实例配置，我们使用默认给出的地址即可，他是jenkins访问的根路径，直接保存并完成。大功告成，jenkins配置完成，可以开始使用了  ps: 点击开始使用后页面是空白的，把jenkins服务重启一下，然后重新访问即可升级jenkinsapt-get安装方式简化了软件安装以及软件启动和停止，但实际就是用内置的web服务加上jenkins.war，默认情况下这个文件在/usr/share/jenkins/ 目录，如果要对其升级，只需要替换这个文件即可。为了保险起见，你可以备份这个文件，然后在jenkins下载页面找到 Generic Java package (.war) ，把下载下来的文件放到/usr/share/jenkins/ 目录，下载好了重新启动完成升级操作。停止jenkins$ sudo service jenkins stop备份jenkins之前的版本$ sudo mv /usr/share/jenkins/jenkins.war /usr/share/jenkins/jenkins_backup.war下载最新版$ cd /usr/share/jenkins/$ sudo wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war--2019-04-15 16:13:28--  http://mirrors.jenkins.io/war-stable/latest/jenkins.warResolving mirrors.jenkins.io (mirrors.jenkins.io)... 52.202.51.185Connecting to mirrors.jenkins.io (mirrors.jenkins.io)|52.202.51.185|:80... connected.HTTP request sent, awaiting response... 302 FoundLocation: http://ftp-nyc.osuosl.org/pub/jenkins/war-stable/2.164.2/jenkins.war [following]--2019-04-15 16:13:29--  http://ftp-nyc.osuosl.org/pub/jenkins/war-stable/2.164.2/jenkins.warResolving ftp-nyc.osuosl.org (ftp-nyc.osuosl.org)... 64.50.233.100, 2600:3404:200:237::2Connecting to ftp-nyc.osuosl.org (ftp-nyc.osuosl.org)|64.50.233.100|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 77330993 (74M) [application/x-java-archive]Saving to: ‘jenkins.war’启动jenkins$ sudo service jenkins start返回目录  Reference      https://pkg.jenkins.io/debian-stable/    https://zh.wikipedia.org/wiki/Jenkins_(%E8%BD%AF%E4%BB%B6)    https://stackoverflow.com/questions/38966105/jenkins-setup-wizard-blank-page  ","categories": ["linux"],
        "tags": ["ubuntu","jenkins"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-jenkins-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu下安装MongoDB",
        "excerpt":"MongoDB是专为可扩展性，高性能和高可用性而设计的面向文档的数据库一、安装MongoDB  1，添加公钥    sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 9DA31620334BD75D9DCB49F368818C72E52529D4        2，添加源到本地    echo \"deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.3 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.3.list              ps:可以把https://repo.mongodb.org/apt/ubuntu替换成http://mirrors.aliyun.com/mongodb/apt/ubuntu，安装时下载速度会有所改善        3，更新本地包数据库    sudo apt-get update        4，安装MongoDB    sudo apt-get install -y mongodb-org      二、配置MongoDBMongoDB默认的配置文件存放在/etc/mongod.conf，通过修改这个配置文件可以更改MongoDB的数据实例目录，端口，访问ip通过vi命令打开，如下：sudo vi /etc/mongod.conf# mongod.conf# for documentation of all options, see:#   http://docs.mongodb.org/manual/reference/configuration-options/# Where and how to store data.storage:  dbPath: /var/lib/mongodb  journal:    enabled: true#  engine:#  mmapv1:#  wiredTiger:# where to write logging data.systemLog:  destination: file  logAppend: true  path: /var/log/mongodb/mongod.log# network interfacesnet:  port: 9007  bindIp: 0.0.0.02.1、修改访问端口在文件偏底部部分，找到 port，修改为自己想要的端口，这里修改为 9007 (建议修改，使用默认端口容易被遭到攻击)2.2、修改访问的ip在同样的地方找到 bindIp 修改允许访问的ip，这里修改为 0.0.0.0 表示任意ip都可访问到此服务（线上环境根据实际情况配置）保存，退出即可2.3、添加访问用户  2.3.1 启动MongoDB    sudo service mongod start        通过查看日志文件/var/log/mongodb/mongod.log，如果有如下内容表示启动成功    [initandlisten] waiting for connections on port 9007        2.3.2 通过shell连接到MongoDB(MongoDB默认端口是27017，由于上面修改了端口，连接的时候需要指定)    mongo --port 9007MongoDB shell version: 3.3connecting to: 127.0.0.1:9007/test&gt;         2.3.3 创建用户(MongoDB默认有一个test的库，下面的操作结果为创建一个demo用户，密码是123456，并且指定test库可以读写)    db.createUser({user:'demo',pwd:'123456',roles: [{role:'readWrite',db:'test'}]})        2.3.4 校验新增的用户是否成功    db.auth('demo','123456')1        控制台打印1代表验证成功，0代表失败  2.4、开启安全检查编辑/etc/mongod.conf文件打开权限验证（在文件偏底部，找到#security，放开注释改成如下所示）sudo vi /etc/mongod.confsecurity:  authorization: enabled保存，退出重新启动MongoDB，然后使用用户登录sudo service mongod restartmongo --port 9007 -u demo -p 123456MongoDB shell version: 3.3connecting to: 127.0.0.1:9007/test&gt; 查看我们创建的用户，校验是否成功&gt; show users  {  \t\"_id\" : \"test.demo\",  \t\"user\" : \"demo\",  \t\"db\" : \"test\",  \t\"roles\" : [  \t\t{  \t\t\t\"role\" : \"readWrite\",  \t\t\t\"db\" : \"test\"  \t\t}  \t]  }返回目录  Reference:      https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/    https://docs.mongodb.com/manual/reference/configuration-options/#security-options  ","categories": ["linux"],
        "tags": ["ubuntu","mongodb"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-mongodb-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu下安装MySQL",
        "excerpt":"MySQL是一个开放源代码的关系数据库管理系统，性能高、成本低、可靠性好，已经成为最流行的开源数据库。安装MySQLsudo apt-get install mysql-server mysql-client安装过程中会要求输入root用户的密码，记下自己输入的密码即可更改默认端口mysql默认的端口是3306，一般情况下我们会更改默认端口，当你数据库暴露在外网时可以一定程度上防止攻击编辑目录 /etc/mysql/mysql.conf.d/mysqld.cnf 下mysql的配置文件：sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf# * Basic Settingsuser            = mysqlpid-file        = /var/run/mysqld/mysqld.pidsocket          = /var/run/mysqld/mysqld.sockport            = 7777   #修改自己需要的端口basedir         = /usrdatadir         = /var/lib/mysqltmpdir          = /tmplc-messages-dir = /usr/share/mysqlskip-external-locking这里演示把默认端口修改为7777，保存修改，重启mysql即可sudo service mysql restart重启之后，通过netstat命令查询端口来验证是否修改成功sudo netstat -nltp|grep 7777tcp        0      0 0.0.0.0:7777            0.0.0.0:*               LISTEN      226042/mysqld授权可以访问的客户端默认情况下，mysql只允许本地操作，如果我们的mysql安装在服务器上，避免不了远程连接，为了方便，这里我允许所有ip远程操作mysql首先登录到mysql，授权root用户可以从任意ip获得所有特权mysql -uroot -pEnter password:mysql&gt; grant all privileges on *.* to 'root'@'%' identified by '你的密码';mysql&gt; flush privileges;mysql&gt; exit;ps：为了安全，你可以指定ip和操作权限然后，更改mysql配置文件允许从任意ip连接sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf## Instead of skip-networking the default is now to listen only on# localhost which is more compatible and is not less secure.bind-address            = 0.0.0.0  #把127.0.0.1修改为0.0.0.0即可sudo service mysql restart把127.0.0.1修改为0.0.0.0即可，然后保存修改，重启mysql生效开启日志mysql有一个二进制操作日志（Binary Logging），包含描述数据库更改的“事件”，例如表创建操作或对表数据的更改。这个日志可以在一定程度上恢复数据，参考 在ubuntu下使用mysqlbinlog恢复drop后的数据 了解如何通过日志恢复误删的数据。默认情况下，日志功能是关闭的，我们需要手动配置编辑目录 /etc/mysql/mysql.conf.d/mysqld.cnf 下mysql的配置文件：sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf# The following can be used as easy to replay backup logs or for replication.# note: if you are setting up a replication slave, see README.Debian about#       other settings you may need to change.server-id               = 1log_bin                 = /var/log/mysql/mysql-bin.logexpire_logs_days        = 10max_binlog_size   = 100M去掉 server-id 和 log_bin 前面的注释，保存重启mysql服务即可开启日志记录功能在console中使用mysql检测是否可以正常使用mysql，打开命令行，使用root用户和刚刚输入的密码连接到mysqlthxopen@Thxopen:~$ mysql -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \\g.Your MySQL connection id is 6Server version: 5.7.22-0ubuntu0.16.04.1 (Ubuntu)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt;出现上述代表mysql安装成功，可以正常使用使用MySQL Workbench操作mysql数据MySQL Workbench 是一个可视化的，可以对mysql配置、用户管理、备份、数据建模、SQL开发等进行操作的综合管理工具。支持在Windows, Linux 和 Mac OS X上使用。在官网上下载对应平台的安装包，安装即可使用。工具欢迎面如下图所示：界面看起来比较清爽，简洁，但是功能非常强大。可以通过【加号】按钮新建一个mysql连接，如下图所示：输入mysql服务器地址、端口、密码，点击【Test Connection】检查是否连接成功。进入MySQL Workbench主界面，如下图所示：主要关注的是中间部分，分别有sql脚本输入区域，表格数据显示区域，历史脚本显示区域整体来说MySQL Workbench还是一个不错的可视化的工具，官方出品，推荐一下。返回目录  Reference      http://www.jianshu.com/p/3111290b87f4  ","categories": ["linux"],
        "tags": ["ubuntu","nginx"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-mysql-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu下安装Nginx",
        "excerpt":"Nginx是一个异步框架的Web服务器，也可以用作反向代理，负载平衡器 和 HTTP缓存。方法一：apt-get安装第一步：安装Nginx在Ubuntu下在线安装Nginx非常简单，只需要一行命令即可sudo apt-get install nginx默认安装后会自己启动，打开浏览器访问127.0.0.1即可看到nginx默认的欢迎界面  ps：确认80端口没有被其他应用程序占用第二步：配置访问权限（ Permission denied ）由于我使用Nginx对本地路径做映射，默认情况下nginx会创建自己的用户名和用户组，这样我用非Nginx的用户创建的文件可能会不能访问，出现Permission denied的错误提示，这里我修改了配置文件让nginx使用同样的用户配置文件一般会在/etc/nginx/nginx.conf这个文件第一行即是user nginx; # 修改成自己的用户，这里我用户名是ubuntu#下面是修改后的user ubuntu;修改完后保存退出，然后重启nginx即可sudo service nginx restart如何安装最新版Nginx2018年7月7日 更新默认情况下，通过命令安装的Nginx不是官方的最新版本，而是一个相对稳定的版本（1.10.0）。在项目中我需要用到gRPC，希望也能通过Nginx来进行负载均衡，发现Nginx从1.13.10版本才开始支持gRPC，迫使我要升级Nginx哪怎么通过命令安装官方最新的Nginx呢？下面来告诉大家，希望能帮助到需要的小伙伴  第一步：找到最新的发行版 ,添加源到本地apt-get sources列表中，如果你的系统是ubuntu 16.04，则可以使用下面的源    echo 'deb http://nginx.org/packages/mainline/ubuntu/ xenial nginx' | sudo tee /etc/apt/sources.list.d/nginx.list      ps: 如果是Ubuntu 14.04就把xenial换成trusty，附一张对照表            系统版本      Codename      支持平台                  12.04      precise      x86_64, i386              14.04      trusty      x86_64, i386, aarch64/arm64              15.10      wily      x86_64, i386              16.04      xenial      x86_64, i386        第二步：添加秘钥    wget -O- http://nginx.org/keys/nginx_signing.key | sudo apt-key add        第三步：更新本地包数据库    sudo apt-get update        第四步：安装Nginx    sudo apt-get install -y nginx        第五步：查看版本    nginx -vnginx version: nginx/1.15.0      可以看到，已经是最新的1.15.0方法二：源码编译安装源码编译安装由3个步骤：配置(configure)、编译(make)、安装(make install)。第一步：下载nginx源码，在nginx官网下载页面可以获取指定版本的下载地址wget https://nginx.org/download/nginx-1.15.0.tar.gz   ps:这里我下载到用户目录/home/ubuntu/nginx-1.15.0.tar.gz第二步：解压nginx到当前目录tar -zxvf nginx-1.15.0.tar.gz第三步：配置./configure --prefix=/usr/local/nginx \\--with-http_realip_module \\--with-http_sub_module \\--with-http_gzip_static_module \\--with-http_stub_status_module \\--with-http_v2_module \\--with-pcre \\--with-http_ssl_module \\--with-openssl=/home/ubuntu/openssl-1.0.2p参数解释：  --prefix=/usr/local/nginx 配置安装路径  --with-http_realip_module 获取用户真实ip模块  --with-http_sbu_module 过滤器模块  --with-http_gzip_static_module 静态压缩模块  --with-http_stub_status_module Nginx的客户端状态  --with-http_v2_module http2支持模块  --with-pcre 自动找到PCRE库文件（需要提前安装，或者手动指定pcre目录）  --with-http_ssl_module ssl支持模块  --with-openssl=/home/ubuntu/openssl-1.0.2p openssl源码目录第四步：编译（make）make第五步：安装（make install）make install第六步：启动sudo /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf  ps: 常用参数结束-c 参数指定的是nginx的主配置路径-s stop 停止nginx-t 检测配置文件-s reload 重载配置文件-V 查看编译参数返回目录  Reference      https://juejin.im/entry/5a274c7751882533d022eec2    https://www.jianshu.com/p/7cb1a824333e    http://seanlook.com/2015/05/17/nginx-install-and-config/    http://blog.sina.com.cn/s/blog_68c25adf01014037.html    https://www.cnblogs.com/HKUI/p/5225895.html  ","categories": ["linux"],
        "tags": ["ubuntu","nginx"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-nginx-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu下安装RabbitMQ",
        "excerpt":"RabbitMQ是一套开源（MPL）的消息队列服务软件，是由 LShift 提供的一个 Advanced Message Queuing Protocol (AMQP) 的开源实现，由以高性能、健壮以及可伸缩性出名的 Erlang 写成。安装RabbitMQ  第一步：添加源    echo 'deb http://www.rabbitmq.com/debian/ testing main' | sudo tee /etc/apt/sources.list.d/rabbitmq.list        第二步：添加秘钥    wget -O- https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | sudo apt-key add        第三步：更新源    sudo apt-get update        第四步：安装    sudo apt-get install rabbitmq-server      开启WEB管理界面RabbitMQ默认没有打开WEB管理界面，需要手动操作sudo rabbitmq-plugins enable rabbitmq_management通过上面的命令即可开启，打开浏览器访问 http://127.0.0.1:15672 即可看到如下界面使用默认用户guest，密码guest可以登录允许非本地访问管理界面打开管理界面的功能开关后，虽然guest用户可以访问，但远程访问还需要配置用户才能可以  第一步：配置vhost语法：add_vhost     sudo rabbitmqctl add_vhost demo_vhostsudo rabbitmqctl list_vhosts        rabbitmq默认创建了/vhost，也可以自己创建一个新的vhost来区分，这里可以直接使用默认的    第二步：添加用户语法：add_user      sudo rabbitmqctl add_user demo 123456sudo rabbitmqctl list_users        添加一个用户名demo，密码为123456的用户记录    第三步：设置权限语法：set_permissions [-p ]        sudo rabbitmqctl set_permissions -p \"/\" demo \".*\" \".*\" \".*\"sudo rabbitmqctl list_permissions -p /        设置demo用户可以操作 / vhost 下的资源，比如queue    第四步：设置角色语法：set_user_tags      sudo rabbitmqctl set_user_tags demo administratorsudo rabbitmqctl list_users        设置demo用户为 administrator (管理员权限)  完成上面操作之后即可使用demo用户登录，登录成功之后可以看到如下界面：配置nginx通过80端口访问RabbitMQ web界面在ngxin配置文件里配置以下代码server{    server_name www.example.com;    listen 80;    location /rabbitmq/ {        proxy_pass http://127.0.0.1:15672/;        rewrite ^/rabbitmq/(.*)$ /$1 break;        client_body_buffer_size 128k;        proxy_send_timeout   90;        proxy_read_timeout   90;        proxy_buffer_size    4k;        proxy_buffers     16 32k;        proxy_busy_buffers_size 64k;        proxy_temp_file_write_size 64k;        proxy_connect_timeout 30s;        proxy_set_header   Host   $host;        proxy_set_header   X-Real-IP  $remote_addr;        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;    }        location /rabbitmq/api/queues/ {        proxy_pass http://127.0.0.1:15672/api/queues/%2F/;    }        location /rabbitmq/api/exchanges/ {        proxy_pass http://127.0.0.1:15672/api/exchanges/%2F/;    }}这样，原本要通过 http://www.example.com:15672 访问，现在可以直接使用 http://www.example.com/rabbitmq 访问web界面返回目录  Reference:      https://blog.csdn.net/rickey17/article/details/72756766    https://blog.haohtml.com/archives/15249  ","categories": ["linux"],
        "tags": ["ubuntu","rabbitmq"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-rabbitmq-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu下安装Redis",
        "excerpt":"Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的键值对存储数据库。安装Redissudo apt-get install redis-server更改默认的端口redis默认的访问端口是6379，避免端口被恶意程序使用，我们修改redis的默认端口打开配置文件/etc/redis/redis.confsudo vi /etc/redis/redis.conf大概在文件50行左右，有如下内容  ps:vi编辑器小提示：:set number 设置显示文件内容的行号，方便查找内容/search_content 斜杠加搜索内容，搜索文件里指定内容# Accept connections on the specified port, default is 6379.# If port 0 is specified Redis will not listen on a TCP socket.port 6379修改端口为自己需要的，保存退出，重启redis即可设置访问密码仅仅修改了端口号还是不够的，我们还要设置密码，避免黑客有机可乘还是继续打开配置文件 /etc/redis/redis.confsudo vi /etc/redis/redis.conf大概在390行左右，有如下内容################################## SECURITY #################################### Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other# commands.  This might be useful in environments in which you do not trust# others with access to the host running redis-server.## This should stay commented out for backward compatibility and because most# people do not need auth (e.g. they run their own servers).## Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.##requirepass foobared去掉注释，把foobared改为自己的密码，保存退出，重启redis即可设置从任意ip访问redis服务默认情况下，redis只能在本地使用，通过修改配置，可以远程操作redis同上，打开配置文件 /etc/redis/redis.confsudo vi /etc/redis/redis.conf大概在69行，有如下内容# By default Redis listens for connections from all the network interfaces# available on the server. It is possible to listen to just one or multiple# interfaces using the \"bind\" configuration directive, followed by one or# more IP addresses.## Examples:## bind 192.168.1.100 10.0.0.1bind 127.0.0.1  将 127.0.0.1 改为指定的ip地址 192.168.1.100 （允许添加多个ip，用空格隔开），即允许ip为192.168.1.100机器访问redis服务。（推荐）  也可以将 127.0.0.1 改为 0.0.0.0 表示任意ip都可以访问redis服务。 （不推荐）使用console连接到redisthxopen@Thxopen:/etc/redis$ redis-cli -p 6379 -a your_password127.0.0.1:6379&gt; pingPONG127.0.0.1:6379&gt;看到输出 PONG 表示redis已经启动成功使用Redis Desktop Manager连接到RedisRedis Desktop Manager 是一个跨平台的，开源的redis桌面管理工具。使用这个工具可以很方便的操作redis。从官网选择对应平台的安装包下载安装完成之后打开软件，点击左上角的 【连接到Redis服务器】，填入ip地址、端口和密码，然后点击左下角【测试连接】如上图所示，表示你已经连接成功，你可以使用工具对redis进行操作返回目录","categories": ["linux"],
        "tags": ["ubuntu","redis"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-redis-on-ubuntu.html",
        "teaser":null},{
        "title": "在Ubuntu下安装Tomcat",
        "excerpt":"Tomcat是Java语言里常用的一个WEB应用服务器容器，把开发好的应用程序部署进去，我们就可以通过浏览器访问到应用了。本篇文章通过两个部分介绍Tomcat  安装  配置第一部分介绍怎么安装到主机，第二部分介绍安装好之后怎么配置。安装Tomcat在Ubuntu上安装Tomcat有两种方式：  在线安装，通过apt-get方式  本地安装，下载压缩包手动配置这里介绍的是本地安装，在线安装以后再更新。在线安装只要主机能够连上网络，就能很方便安装好Tomcat。第一步：进入到用户目录，可以直接安装在用户目录下，也可以在用户目录下新建文件夹，这里我放在用户目录下的app文件夹里thxopen@Thxopen:~$ mkdir appthxopen@Thxopen:~$ lsappps: ~ 代表/home/用户名 路径第二步：下载Tomcat到app目录，本次选择Tomcat-8.5.29作为演示thxopen@Thxopen:~$cd appthxopen@Thxopen:~/app$ wget http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.29/bin/apache-tomcat-8.5.29.tar.gz--2018-02-27 22:22:15--  http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.29/bin/apache-tomcat-8.5.29.tar.gz正在解析主机 mirrors.shu.edu.cn (mirrors.shu.edu.cn)... 202.121.199.235正在连接 mirrors.shu.edu.cn (mirrors.shu.edu.cn)|202.121.199.235|:80... 已连接。已发出 HTTP 请求，正在等待回应...200 OK长度： 9532698 (9.1M) [application/x-gzip]正在保存至: “apache-tomcat-8.5.29.tar.gz”apache-tomcat-8.5.29.tar.gz  100%[================================================&gt;]   9.09M   886KB/s    in 11s2018-02-27 22:23:10 (853 KB/s) - 已保存 “apache-tomcat-8.5.29.tar.gz” [9532698/9532698])thxopen@Thxopen:~/app$lsapache-tomcat-8.5.29.tar.gzps: 可能会出现地址无法访问，是正常的，下载地址不定时会有变动，如出现不能下载的情况，前往官网下载页面复制新的下载地址右键复制链接地址，替换上面命令wget 后面的url地址即可第三步：解压并更改Tomcat的名称thxopen@Thxopen:~/app$ tar vxf apache-tomcat-8.5.29.tar.gzapache-tomcat-8.5.29/conf/apache-tomcat-8.5.29/conf/catalina.policyapache-tomcat-8.5.29/conf/catalina.propertiesapache-tomcat-8.5.29/conf/context.xmlapache-tomcat-8.5.29/conf/jaspic-providers.xmlapache-tomcat-8.5.29/conf/jaspic-providers.xsdapache-tomcat-8.5.29/conf/logging.propertiesapache-tomcat-8.5.29/conf/server.xmlapache-tomcat-8.5.29/conf/tomcat-users.xmlapache-tomcat-8.5.29/conf/tomcat-users.xsdapache-tomcat-8.5.29/conf/web.xml...apache-tomcat-8.5.29/bin/catalina.shapache-tomcat-8.5.29/bin/configtest.shapache-tomcat-8.5.29/bin/daemon.shapache-tomcat-8.5.29/bin/digest.shapache-tomcat-8.5.29/bin/setclasspath.shapache-tomcat-8.5.29/bin/shutdown.shapache-tomcat-8.5.29/bin/startup.shapache-tomcat-8.5.29/bin/tool-wrapper.shapache-tomcat-8.5.29/bin/version.shthxopen@Thxopen:~/app$ lsapache-tomcat-8.5.29  apache-tomcat-8.5.29.tar.gzthxopen@Thxopen:~/app$ mv apache-tomcat-8.5.29 tomcat-demo-8888thxopen@Thxopen:~/app$ lsapache-tomcat-8.5.29.tar.gz  tomcat-demo-8888thxopen@Thxopen:~/app$cd tomcat-demo-8888/thxopen@Thxopen:~/app/tomcat-demo-8888$lsbin  conf  lib  LICENSE  logs  NOTICE  RELEASE-NOTES  RUNNING.txt  temp  webapps  workps：这里我把tomcat重命名为tomcat-demo-8888，这样很直观就能看出这个tomcat是运行什么应用端口是多少，建议大家也根据实际情况重命名，当出现多个tomcat时是很有帮助的配置tomcat1、配置启动文件进入/home/thxopen/app/tomcat-demo-8888/bin目录，把catalina.sh文件复制一份，重命名为tomcat-8888thxopen@Thxopen:~$ sudo cp /home/thxopen/app/tomcat-demo-8888/bin/catalina.sh /home/thxopen/app/tomcat-demo-8888/bin/tomcat-8888打开tomcat-8888文件，在文件大概110行左右配置上java环境和tomcat所在目录thxopen@Thxopen:~$ sudo vi /home/thxopen/app/tomcat-demo-8888/bin/tomcat-8888# -----------------------------------------------------------------------------# config java_home pathJAVA_HOME=/usr/lib/jvm/java-8-oracle/jre# config tomcat pathCATALINA_HOME=/home/thxopen/app/tomcat-demo-8888# OS specific support.  $var _must_ be set to either true or false.保存后把修改好的文件移动到/etc/init.d目录下thxopen@Thxopen:~$ sudo mv /home/thxopen/app/tomcat-demo-8888/bin/tomcat-8888 /etc/init.d/2、配置环境变量根据catalina.sh文件里的注释：# -----------------------------------------------------------------------------# Control Script for the CATALINA Server## Environment Variable Prerequisites##   Do not set the variables in this script. Instead put them into a script#   setenv.sh in CATALINA_BASE/bin to keep your customizations separate.#不要直接在catalina.sh设置变量，而是要在CATALINA_BASE/bin目录下的setenv.sh文件里设置正常启动停止tomcat我们还需要设置CATALINA_PID变量，下面是对此变量的解释#   CATALINA_PID    (Optional) Path of the file which should contains the pid#                   of the catalina startup java process, when start (fork) is#                   used在CATALINA_BASE/bin目录下新建setenv.sh文件echo CATALINA_PID=/home/thxopen/app/tomcat-demo-8888/tomcat.pid &gt; setenv.sh3、配置端口在目录/home/thxopen/app/tomcat-demo-8888/conf下打开server.xml文件，在文件大概70行左右配置上自己想要的端口thxopen@Thxopen:~$ sudo vi /home/thxopen/app/tomcat-demo-8888/conf/server.xml &lt;!-- A \"Connector\" represents an endpoint by which requests are received     and responses are returned. Documentation at :     Java HTTP Connector: /docs/config/http.html     Java AJP  Connector: /docs/config/ajp.html     APR (HTTP/AJP) Connector: /docs/apr.html     Define a non-SSL/TLS HTTP/1.1 Connector on port 8080--&gt;&lt;Connector port=\"8888\" protocol=\"HTTP/1.1\"           connectionTimeout=\"20000\"           redirectPort=\"8443\" /&gt;               这里修改为8888端口，保存文件退出即可通过上面的配置，使用如下命令即可操作tomcat/etc/init.d/tomcat-8888 start/etc/init.d/tomcat-8888 stop/etc/init.d/tomcat-8888 restart返回目录","categories": ["linux"],
        "tags": ["ubuntu","tomcat"],
        "url": "http://www.thxopen.com/linux/2018/02/27/install-tomcat-on-ubuntu.html",
        "teaser":null},{
        "title": "在ubuntu下使用mysqlbinlog恢复drop后的数据",
        "excerpt":"背景我肯定跟mysql过不去，覆盖数据在我身上已经发生了2次了，难道我这是上演从删库到跑路么？在上次覆盖了数据之后，我就告诉自己操作数据库先备份，即便错了也可以恢复，这次操作之前我已经很谨慎了，可惜最后还是做错了。同事辛苦几周操作的数据被我一秒钟给覆盖了，我没有着急，我淡定，我回想上次误操作后，打开了mysql的日志功能，据说可以一定程度的恢复数据，这次我来验证一下，通过我几个小时的挣扎，数据恢复过来，但从结果来看，并不是100%的恢复了，没办法，只能再花时间精力把数据重新来过。只可惜什么都有就是没有后悔药，写下此篇，引以为戒，数据一定一定一定要备份！！！操作一定一定一定要谨慎！！！虽然没有100%的恢复，但是如果没有开启log_bin那一定就恢复不了了，至少还有个救命稻草，下文介绍如何使用mysqlbinlog命令恢复drop后的数据查看mysql日志是否开启进入mysql的配置目录，一般在/etc/mysql/mysql.conf.d目录里面，有如下两个文件thxopen@Thxopen:/etc/mysql/mysql.conf.d$ lsmysqld.cnf  mysqld_safe_syslog.cnf编辑mysqld.cnf文件，找到log_bin配置# The following can be used as easy to replay backup logs or for replication.# note: if you are setting up a replication slave, see README.Debian about#       other settings you may need to change.server-id               = 1log_bin                 = /var/log/mysql/mysql-bin.logexpire_logs_days        = 10max_binlog_size   = 500M默认情况下log_bin功能是关闭的，把 server-id 和 log_bin 取消注释，保存退出，重启mysql即可。查找 mysql 日志文件根据log_bin配置的日志目录，我找到了日志thxopen@Thxopen:/etc/mysql/mysql.conf.d$ cd /var/log/mysql/thxopen@Thxopen:/var/log/mysql$ lserror.log  mysql-bin.000001  mysql-bin.000002  mysql-bin.000003  mysql-bin.000004  mysql-bin.indexthxopen@Thxopen:/var/log/mysql$ ll总用量 364160drwxr-x--- 1 mysql adm          512 8月  29 10:06 ./drwxrwxr-x 1 root  syslog       512 11月 18  2017 ../-rw-r----- 1 mysql adm    108427282 8月  29 10:13 error.log-rw-r----- 1 mysql mysql        154 8月  28 19:37 mysql-bin.000001-rw-r----- 1 mysql mysql        177 8月  28 19:55 mysql-bin.000002-rw-r----- 1 mysql mysql  264390804 8月  29 10:06 mysql-bin.000003-rw-r----- 1 mysql mysql        154 8月  29 10:06 mysql-bin.000004-rw-r----- 1 mysql mysql        128 8月  29 10:06 mysql-bin.indexmysql-bin.000001 即为我们需要的日志文件，使用mysqlbinlog命令可以导出可执行的sql文件mysqlbinlog 介绍像一般的系统一样，我们会对系统的每一个操作记录下操作日志，而log_bin就是对数据库的每一个操作记录下的一个二进制的日志，里面包含了我们所有执行的sql语句。通过此命令，我们可以导出我们操作的sql语句，这样达到恢复数据的目的。关于mysqlbinlog命令几个常使用的参数，可以帮助我们更快的找到我们的数据  --start-position 起始位置（不包含）  --stop-position 截止位置  --start-datetime 起始时间  --stop-datetime 截止时间  --base64-output=decode-rows 输出的文件base64解码更多关于mysqlbinlog的参数可以通过参数--help获取模拟实际的操作，新增数据，修改数据，删除表，恢复数据  1，创建一张测试表create table tb_recovery_test(  id int not null ,  column1 varchar(32)          null,  column2 varchar(32)          null);运行结果：mysql&gt; create table tb_recovery_test    -&gt; (    -&gt;   id int not null ,    -&gt;   column1 varchar(32)          null,    -&gt;   column2 varchar(32)          null    -&gt; );Query OK, 0 rows affected (0.05 sec)  2，插入测试数据insert into tb_recovery_test (id,column1,column2)       values (1,'数据操作需谨慎','定期备份数据');insert into tb_recovery_test (id,column1,column2)       values (2,'后悔了','可是没有后悔药');运行结果：mysql&gt; insert into tb_recovery_test (id,column1,column2)    -&gt;       values (1,'数据操作需谨慎','定期备份数据');Query OK, 1 row affected (0.01 sec)mysql&gt; insert into tb_recovery_test (id,column1,column2)    -&gt;       values (2,'后悔了','可是没有后悔药');Query OK, 1 row affected (0.01 sec)mysql&gt; select * from tb_recovery_test;+----+--------------+-------------------+| id | column1      | column2           |+----+--------------+-------------------+|  1 | 数据操作需谨慎 | 定期备份数据        ||  2 | 后悔了        | 可是没有后悔药      |+----+--------------+-------------------+2 rows in set (0.00 sec)  3，修改数据，这里模拟一下真实的场景，对数据进行修改，删除，添加字段操作update tb_recovery_test set column1 = '数据操作需谨慎,定期备份数据,什么都有就是没有后悔药',        column2 = null        where id = 2;delete from tb_recovery_test where id = 1;ALTER TABLE tb_recovery_test ADD column3 varchar(32) NULL;insert into tb_recovery_test (id,column1,column2,column3)       values (3,'新增了一个字段','新增了一个字段','新增了一个字段');update tb_recovery_test set column3 = '修改了新增字段的值' where id = 3;update tb_recovery_test set column2 = '修改了column2字段的值' where id = 2;运行结果：mysql&gt; update tb_recovery_test set column1 = '数据操作需谨慎,定期备份数据,什么都有就是没有后悔药',    -&gt;         column2 = null    -&gt;         where id = 2;Query OK, 1 row affected (0.01 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; delete from tb_recovery_test where id = 1;Query OK, 1 row affected (0.00 sec)mysql&gt; ALTER TABLE tb_recovery_test ADD column3 varchar(32) NULL;Query OK, 0 rows affected (0.10 sec)Records: 0  Duplicates: 0  Warnings: 0mysql&gt; insert into tb_recovery_test (id,column1,column2,column3)    -&gt;       values (3,'新增了一个字段','新增了一个字段','新增了一个字段');Query OK, 1 row affected (0.01 sec)mysql&gt; update tb_recovery_test set column3 = '修改了新增字段的值' where id = 3;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; update tb_recovery_test set column2 = '修改了column2字段的值' where id = 2;Query OK, 1 row affected (0.01 sec)Rows matched: 1  Changed: 1  Warnings: 0mysql&gt; select * from tb_recovery_test;+----+-------------------------------------------------+-------------------------+-----------------+| id | column1                                         | column2                 | column3         |+----+-------------------------------------------------+-------------------------+-----------------+|  2 | 数据操作需谨慎,定期备份数据,什么都有就是没有后悔药       | 修改了column2字段的值     | NULL            ||  3 | 新增了一个字段                                     | 新增了一个字段            | 修改了新增字段的值 |+----+--------------------------------------------------+------------------------+-----------------+2 rows in set (0.00 sec)  4，最后我误操作，把表tb_recovery_test删除drop table tb_recovery_test;运行结果：mysql&gt; drop table tb_recovery_test;Query OK, 0 rows affected (0.03 sec)显然，最后一步操作之后，我们之前所做的操作白费了，还好我们开启了log_bin功能，通过日志来找回误操作删除的数据通过日志文件恢复 tb_recovery_test 数据进入到mysql保存日志的目录，通过前面配置可以知道日志文件保存在 /var/log/mysql/ 下thxopen@Thxopen:/var/log/mysql$ cd /var/log/mysql/thxopen@Thxopen:/var/log/mysql$ lserror.log  mysql-bin.000001  mysql-bin.000002  mysql-bin.000003  mysql-bin.000004  mysql-bin.indexthxopen@Thxopen:/var/log/mysql$ ll总用量 364164drwxr-x--- 1 mysql adm          512 8月  29 10:06 ./drwxrwxr-x 1 root  syslog       512 11月 18  2017 ../-rw-r----- 1 mysql adm    108427282 8月  29 10:13 error.log-rw-r----- 1 mysql mysql        154 8月  28 19:37 mysql-bin.000001-rw-r----- 1 mysql mysql        177 8月  28 19:55 mysql-bin.000002-rw-r----- 1 mysql mysql  264390804 8月  29 10:06 mysql-bin.000003-rw-r----- 1 mysql mysql       3411 8月  29 13:14 mysql-bin.000004-rw-r----- 1 mysql mysql        128 8月  29 10:06 mysql-bin.index从列出的文件可以看出 mysql-bin.000004 文件是最近改动的，一般来说文件的后缀是增长的，根据实际情况，这里我选择最后一个日志文件进行恢复操作执行导出日志操作，先看看导出的sql具体是什么样的sudo mysqlbinlog --base64-output=decode-rows /var/log/mysql/mysql-bin.000004 &gt; ./recovery-decode.sqlps: 添加--base64-output=decode-rows 参数导出的sql文件里不包含数据部分（即insert，delete，update），主要是方便分析，实际导出的sql是不能加这个参数的查看导出sql，我截取了文件的开头和结尾部分，中间部分省略/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#180829 10:06:42 server id 1  end_log_pos 123 CRC32 0xa3922cf1 \tStart: binlog v 4, server v 5.7.22-0ubuntu0.16.04.1-log created 180829 10:06:42 at startup# Warning: this binlog is either in use or was not closed properly.ROLLBACK/*!*/;# at 123#180829 10:06:43 server id 1  end_log_pos 154 CRC32 0xa18892ca \tPrevious-GTIDs# [empty]# at 154#180829 13:07:48 server id 1  end_log_pos 219 CRC32 0x7e4bd4d6 \tAnonymous_GTID\tlast_committed=0\tsequence_number=1\trbr_only=noSET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 219#180829 13:07:48 server id 1  end_log_pos 425 CRC32 0x331aefcb \tQuery\tthread_id=15\texec_time=0\terror_code=0use `thxopen`/*!*/;SET TIMESTAMP=1535519268/*!*/;SET @@session.pseudo_thread_id=15/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create table tb_recovery_test(  id int not null ,  column1 varchar(32)          null,  column2 varchar(32)          null)/*!*/;# at 425#省略了中间的内容#省略了中间的内容#省略了中间的内容#省略了中间的内容# at 1970#180829 13:10:10 server id 1  end_log_pos 2035 CRC32 0x8c8ac254 \tAnonymous_GTID\tlast_committed=6\tsequence_number=7\trbr_only=yes/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 2035#180829 13:10:10 server id 1  end_log_pos 2110 CRC32 0x1d22149c \tQuery\tthread_id=15\texec_time=0\terror_code=0SET TIMESTAMP=1535519410/*!*/;BEGIN/*!*/;# at 2110#180829 13:10:10 server id 1  end_log_pos 2181 CRC32 0xcccc7fab \tTable_map: `thxopen`.`tb_recovery_test` mapped to number 168# at 2181#180829 13:10:10 server id 1  end_log_pos 2287 CRC32 0x322b3ff6 \tWrite_rows: table id 168 flags: STMT_END_F# at 2287#180829 13:10:10 server id 1  end_log_pos 2318 CRC32 0xaa8d7acf \tXid = 3075COMMIT/*!*/;# at 2318#180829 13:10:10 server id 1  end_log_pos 2383 CRC32 0x05b7bd59 \tAnonymous_GTID\tlast_committed=7\tsequence_number=8\trbr_only=yes/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 2383#180829 13:10:10 server id 1  end_log_pos 2458 CRC32 0x171d4eab \tQuery\tthread_id=15\texec_time=0\terror_code=0SET TIMESTAMP=1535519410/*!*/;BEGIN/*!*/;# at 2458#180829 13:10:10 server id 1  end_log_pos 2529 CRC32 0xe95d3272 \tTable_map: `thxopen`.`tb_recovery_test` mapped to number 168# at 2529#180829 13:10:10 server id 1  end_log_pos 2713 CRC32 0x4386d86f \tUpdate_rows: table id 168 flags: STMT_END_F# at 2713#180829 13:10:10 server id 1  end_log_pos 2744 CRC32 0xcde5fff8 \tXid = 3076COMMIT/*!*/;# at 2744#180829 13:10:19 server id 1  end_log_pos 2809 CRC32 0x3b9cc08b \tAnonymous_GTID\tlast_committed=8\tsequence_number=9\trbr_only=yes/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 2809#180829 13:10:19 server id 1  end_log_pos 2884 CRC32 0xb86bbce3 \tQuery\tthread_id=15\texec_time=0\terror_code=0SET TIMESTAMP=1535519419/*!*/;BEGIN/*!*/;# at 2884#180829 13:10:19 server id 1  end_log_pos 2955 CRC32 0x7b3dc472 \tTable_map: `thxopen`.`tb_recovery_test` mapped to number 168# at 2955#180829 13:10:19 server id 1  end_log_pos 3180 CRC32 0x1ff6807f \tUpdate_rows: table id 168 flags: STMT_END_F# at 3180#180829 13:10:19 server id 1  end_log_pos 3211 CRC32 0xda138c1f \tXid = 3077COMMIT/*!*/;# at 3211#180829 13:14:00 server id 1  end_log_pos 3276 CRC32 0x9e823905 \tAnonymous_GTID\tlast_committed=9\tsequence_number=10\trbr_only=noSET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 3276#180829 13:14:00 server id 1  end_log_pos 3411 CRC32 0x2f9c474a \tQuery\tthread_id=15\texec_time=0\terror_code=0SET TIMESTAMP=1535519640/*!*/;DROP TABLE `tb_recovery_test` /* generated by server *//*!*/;SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;从文件里可以看出我一开始的建表语句，也就是我每一步操作都记录在这个日志里，那么我只要把我之前的每一步都再执行一边，数据就能恢复回来，我们按照这个思路操作  1，先确定起始position，这里我选择 end_log_pos 219 ，前面参数解释了，起始点是不包含的所以要选建表语句之前的操作点（也可以选择起始时间 180829 13:07:48）  2，确定截止position end_log_pos 3276 或截止时间 180829 13:14:00  3，导出恢复数据sql#使用position导出sqlsudo mysqlbinlog --start-position=219 --stop-position=3276 /var/log/mysql/mysql-bin.000004 &gt; ./recovery-restore.sql#使用时间导出sqlsudo mysqlbinlog --start-datetime='2018-08-29 13:07:48' --stop-datetime='2018-08-29 13:14:00' /var/log/mysql/mysql-bin.000004 &gt; ./recovery-restore.sql下面为导出的sql前半部分，可以看到BINLOG后面有base64的字符，这个就是对数据的操作/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#180829 10:06:42 server id 1  end_log_pos 123 CRC32 0xa3922cf1 \tStart: binlog v 4, server v 5.7.22-0ubuntu0.16.04.1-log created 180829 10:06:42 at startup# Warning: this binlog is either in use or was not closed properly.ROLLBACK/*!*/;BINLOG 'sv+FWw8BAAAAdwAAAHsAAAABAAQANS43LjIyLTB1YnVudHUwLjE2LjA0LjEtbG9nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACy/4VbEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAAfEskqM='/*!*/;# at 219#180829 13:07:48 server id 1  end_log_pos 425 CRC32 0x331aefcb \tQuery\tthread_id=15\texec_time=0\terror_code=0use `thxopen`/*!*/;SET TIMESTAMP=1535519268/*!*/;SET @@session.pseudo_thread_id=15/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create table tb_recovery_test(  id int not null ,  column1 varchar(32)          null,  column2 varchar(32)          null)/*!*/;# at 425#省略了后面的#省略了后面的#省略了后面的#省略了后面的  4，导入sql到数据库mysql -uroot -p database_name &lt; recovery-restore.sqlps：还可以加入[-f] 参数，强制执行，即忽略所有错误，根据实际情况使用这个参数运行结果：thxopen@Thxopen:~$ mysql -uroot -p thxopen &lt; recovery-restore.sqlEnter password:thxopen@Thxopen:~$ mysql -uroot -pEnter password:Welcome to the MySQL monitor.  Commands end with ; or \\g.Your MySQL connection id is 17Server version: 5.7.22-0ubuntu0.16.04.1-log (Ubuntu)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; use thxopen;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; show tables;+-------------------+| Tables_in_thxopen |+-------------------+| tb_recovery_test  |+-------------------+1 row in set (0.00 sec)mysql&gt; select * from tb_recovery_test;+----+----------------------------------------------+------------------------+------------------+| id | column1                                      | column2                | column3          |+----+----------------------------------------------+------------------------+------------------+|  2 | 数据操作需谨慎,定期备份数据,什么都有就是没有后悔药    | 修改了column2字段的值    | NULL             ||  3 | 新增了一个字段                                  | 新增了一个字段           | 修改了新增字段的值  |+----+----------------------------------------------+------------------------+------------------+2 rows in set (0.00 sec)mysql&gt;导入之后，重新登录到mysql，查看表，查看数据，已经恢复到drop之前的状态了，到此大功告成，数据恢复成功！导入恢复数据到数据库可能会遇到的错误      Duplicate entry 重复的实体，出现此错误代表恢复的sql脚本里，包含创建了实体的语句，重新执行一边，则报错        Duplicate column name 重复的列名称，理由同上        Duplicate key name 重复的键索引，理由同上        Can’t find record in ‘table_name’ 由于业务逻辑，有些数据删除，修改，新增，删除，修改反复这样操作，导致恢复的时候出现此错误        Cannot add or update a child row: a foreign key constraint fails (thxopen.tb_recovery_test, CONSTRAINT FKan5m1ygnxb4ibmq1ncqklji26 FOREIGN KEY (rid) REFERENCES tb_recovery_relate (id))由于外键关联，修改表的数据在另一个表中不存在导致        Table ‘table_name’ already exists 重复的表，恢复sql脚本了包含数据库里已经存在的表        Can’t write; duplicate key in table 创建表的外键名称重复了        MySQL server has gone away 由于导入的恢复sql太大，超过了mysql的限制，需要修改配置文件/etc/mysql/mysql.conf.d/mysqld.cnf 里 max_allowed_packet = 16M 配置，根据实际情况调大一些  总结对于文中的例子，恢复数据是100%的，但是在实际的项目中，虽然开启了log_bin，但不能想着万事大吉就不管了，我就是惨痛的经历，数据感觉50%都没恢复到。简直是血的教训，血的教训，血的教训啊~不过从这个也可以看出系统设计本身的问题，逻辑复杂，耦合度高，关联性太强，比如我误删的数据，由于表之间的关系比较复杂，恢复出来的数据有很多问题。主要是如下几个问题：  手动在Intellij Database Console执行的update语句，在恢复之后没有体现出来，字段是null  部分表的数据完全没有，一条数据也没有  由于我是覆盖数据，都是先drop表，然后又create了表，而日志文件又没有从最开始创建表的，所以执行恢复sql的时候，报了如上列出的所有error，对于重复表，重复字段这些，我把日志里的删除，可以解决，但是对于数据的关联出错，找不到记录的就太多了，没有办法一一修复，为了执行完成sql，导入的时候加了[-f]参数，忽略所有错误因为上面这些问题，加上日志本身也不全，导致数据根本没法100%的恢复说了这么多，还是一句话，没有规矩，不成方圆，做事要小心谨慎，按照一定的流程做事就可以减少犯错误的几率。定期备份数据，操作数据谨慎  Reference      https://www.cnblogs.com/cenalulu/archive/2013/01/08/2850820.html    https://blog.csdn.net/leshami/article/details/41962243    http://www.unixfbi.com/499.html    http://blog.51cto.com/suifu/1845457    https://www.cnblogs.com/leezhxing/p/3347610.html    http://www.hankcs.com/appos/database/mysql-restore-dropped-table.html    https://blog.csdn.net/weixin_41004350/article/details/78547005    https://blog.csdn.net/xyz846/article/details/52210542  ","categories": ["database"],
        "tags": ["mysql","mysqlbinlog","drop","ubuntu"],
        "url": "http://www.thxopen.com/database/2018/08/28/mysqlbinlog-recovery-data.html",
        "teaser":null},{
        "title": "Unknown column 'NaN' in 'field list'",
        "excerpt":"起因使用mysql数据库，在插入数据时，抛出以下异常Unknown column 'NaN' in 'field list'字面上意思：未知的列’NaN’在字段列表中我首先想到的是自己 insert 语句是不是有问题，但想到插入语句是由框架完成的，列因该不会弄错，那是什么原因呢？再看关键字NaN，这个是Not a Number的意思，我联想到我的插入数据包含浮点类型的数据，调试代码发现有除数为0的情况//misV+rigVf 可能为 0float recallRate = rigVf / (misV + rigVf);perCategory.setReCallRate(recallRate);当被除数为0，recallRate的结果就是NaN，导致mysql插入数据的时候，本来因该是一个浮点类型，结果插入了NaN，mysql报错。找到原因了问题就好解决，在设置recallRate值的时候判断一下if(!Float.isNaN(recallRate)){    perCategory.setReCallRate(recallRate);}加上判断之后，问题解决总结编码需要规范，不然就会出现这些低级错误  Reference:      https://www.cnblogs.com/big-xuyue/p/4106130.html  ","categories": ["database"],
        "tags": ["mysql","database","error","exception"],
        "url": "http://www.thxopen.com/database/2018/09/19/unknown-column-nan-in-field-list.html",
        "teaser":null},{
        "title": "像使用mybatis一样使用spring data jpa",
        "excerpt":"简介自从用上了spring data jpa后，已经深深的喜欢上她的这种风格。简单的CURD操作、根据方法名动态生成sql，就这两点我已经很满足了。虽然已经很强大，美中不足的是对原生sql的支持有点欠缺，不过好在有大神弥补了这个小小遗憾，下面介绍大神给的解决方案spring-data-jpa-extraspring-data-jpa-extra是一个可以像使用mybatis一样的spring data jpa扩展，她在spring data jpa上扩展了sql模板的功能，解决下面三个问题：  动态原生查询支持，如mybatis  可以返回任何类型的数据  没有代码，只有sql语句本身强大的spring data jpa，加上动态原生sql的功能，简直就是如虎添翼，下面通过简单的介绍，告诉大家怎么使用这个插件配置作者已经把源码放在github上，并在maven仓库里发布了对应的jar，可供依赖使用，如果你正在使用maven，只需要添加下面代码，即可使用她  第一步：引入依赖&lt;dependency&gt;    &lt;groupId&gt;com.slyak&lt;/groupId&gt;    &lt;artifactId&gt;spring-data-jpa-extra&lt;/artifactId&gt;    &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;ps:github上的readme给出的是2.1.2.RELEASE，但我在使用的时候，只能下载到2.1.1的版本，具体原因不太清楚，大家参考的时候多尝试一下  第二步：开启功能并配置Freemarkimport com.slyak.spring.jpa.FreemarkerSqlTemplates;import com.slyak.spring.jpa.GenericJpaRepositoryFactoryBean;import com.slyak.spring.jpa.GenericJpaRepositoryImpl;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.data.jpa.repository.config.EnableJpaRepositories;/** * spring data jpa extra 配置 * &lt;p&gt; * 2018/9/18 * * @author Keith * @version v0.0.1 */@Configuration//your base package@ComponentScan(\"com.thxopen\")@EnableJpaRepositories(        //your repository package        basePackages = \"com.thxopen.dao.repository\" ,        repositoryBaseClass = GenericJpaRepositoryImpl.class,         repositoryFactoryBeanClass = GenericJpaRepositoryFactoryBean.class)public class RepositoryConfig {    @Bean    public FreemarkerSqlTemplates freemarkerSqlTemplates() {        FreemarkerSqlTemplates templates = new FreemarkerSqlTemplates();        templates.setSuffix(\".sftl\");        return templates;    }}使用  第一步：创建实体和DTOSample.javaimport lombok.Data;import org.hibernate.annotations.Table;import javax.persistence.Column;import javax.persistence.Entity;/** * demo例子 * &lt;p&gt; * 2018/9/18 * * @author Keith * @version v0.0.1 */@Entity(name = \"tb_sample\")@Table(appliesTo = \"tb_sample\",comment = \"demo例子\")@Datapublic class Sample {    @Column(columnDefinition = \"varchar(255) COMMENT '测试字段'\")    private String content;}SampleDTO.javapublic class SampleDTO {    private long id;    private String contentShow;    public long getId() {        return id;    }    public void setId(long id) {        this.id = id;    }    public String getContentShow() {        return contentShow;    }    public void setContentShow(String contentShow) {        this.contentShow = contentShow;    }}SampleQuery.javapublic class SampleQuery {    private String content;    public String getContent() {        return content;    }    public void setContent(String content) {        if (content != null) {            this.content = \"%\" + content + \"%\";        }    }}  第二步：创建Repository与spring data jpa用法不一样的是，需要把继承JpaRepository改为继承GenericJpaRepository，代码如下import com.slyak.spring.jpa.GenericJpaRepository;import com.slyak.spring.jpa.TemplateQuery;import com.thxopen.dao.entity.Sample;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.data.jpa.repository.Query;import org.springframework.data.repository.query.Param;import java.util.HashMap;import java.util.List;import java.util.Map;/** * @author keith * @create 2018年9月18日15:03:59 * @desc **/public interface SampleRepository extends GenericJpaRepository&lt;Sample,Long&gt; {    /**     * spring data jpa 原生     * 根据条件过滤     * 更多写法参考 https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#jpa.query-methods.query-creation     * @param content     * @return     */    List&lt;Sample&gt; findAllByContent(String content);        /**     * spring data jpa 原生的native     * @param name     * @return     */    @Query(nativeQuery = true, value = \"select * from tb_sample where content like ?1\")    List&lt;Sample&gt; findDtos2(@Param(\"name\") String name);    /**     * 分页过滤查询     * @param content     * @param pageable     * @return     */    @TemplateQuery    Page&lt;Sample&gt; findByContent(@Param(\"content\") String content, Pageable pageable);    /**     * 分页对象过滤查询     * @param sampleQuery     * @param pageable     * @return     */    @TemplateQuery    List&lt;Sample&gt; findByTemplateQueryObject(SampleQuery sampleQuery, Pageable pageable);    /**     * 过滤计算总数     * @param content     * @return     */    @TemplateQuery    Long countContent(@Param(\"content\") String content);    /**     * 返回自定义的dto     * @return     */    @TemplateQuery    List&lt;SampleDTO&gt; findDtos();        /**     * 返回map     * keith-fix 目前还有报错，暂且不用     * @return     */    @TemplateQuery    List&lt;Map&lt;String,Object&gt;&gt; findMap();}ps:使用@TemplateQuery自定义注解代表会根据方法名去模板文件里找相应的sql  第三步：在/resources/sqls创建对应的sql模板（tb_sample.sftl），文件名同Entity的name值--findByContent  SELECT * FROM tb_sample WHERE 1 = 1&lt;#if content??&gt;        AND content LIKE :content&lt;/#if&gt;--countContentSELECT count(*) FROM tb_sample WHERE 1 = 1&lt;#if content??&gt;  AND content LIKE :content&lt;/#if&gt;--findDtosSELECT id, content as contentShow FROM tb_sample--findByTemplateQueryObjectSELECT * FROM tb_sample WHERE 1 = 1&lt;#if content??&gt; AND content LIKE :content&lt;/#if&gt;--findMapSELECT * FROM tb_sample--后面的字符串和Repository里的方法名一一对应  第四步：创建测试用例，验证方法import com.thxopen.Application;import com.thxopen.dao.entity.Sample;import com.thxopen.dao.repository.sample.SampleDTO;import com.thxopen.dao.repository.sample.SampleQuery;import com.thxopen.dao.repository.sample.SampleRepository;import lombok.extern.slf4j.Slf4j;import org.junit.Assert;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.domain.Page;import org.springframework.data.domain.PageRequest;import org.springframework.test.context.junit4.SpringRunner;import java.util.List;import java.util.Map;/** * jpa类似mybatis用法测试用例 * 教程参考：https://github.com/slyak/spring-data-jpa-extra * &lt;p&gt; * 2018/9/18 * * @author Keith * @version v0.0.1 */@RunWith(SpringRunner.class)@SpringBootTest(classes = Application.class)@EnableAutoConfiguration@Slf4jpublic class SampleTest {    @Autowired    SampleRepository sampleRepository;    @Test    public void delSomeSample() {        sampleRepository.deleteAll();    }    @Test    public void addSomeSample() {        for (int i = 0; i &lt; 10; i++) {            Sample sample = new Sample();            sample.setContent(\"hello world\" + i);            sampleRepository.save(sample);        }    }    @Test    public void findByTemplateQuery() {        PageRequest pageRequest = new PageRequest(1, 10);        Page&lt;Sample&gt; samples = sampleRepository.findByContent(\"%world%\", pageRequest);        Assert.assertTrue(samples.getTotalElements() == 10);    }    @Test    public void countByTemplateQuery() {        long count = sampleRepository.countContent(\"%world%\");        Assert.assertTrue(count == 10);    }    @Test    public void findByTemplateQueryAndReturnDTOs() {        List&lt;SampleDTO&gt; dtos = sampleRepository.findDtos();        Assert.assertTrue(dtos.size() == 10);    }    @Test    public void findByTemplateQueryWithTemplateQueryObject() {        SampleQuery sq = new SampleQuery();        sq.setContent(\"%world%\");        List&lt;Sample&gt; samples = sampleRepository.findByTemplateQueryObject(sq, null);        Assert.assertTrue(samples.size() == 10);    }    @Test    public void findBySpringElQuery() {        List&lt;Sample&gt; dtos = sampleRepository.findDtos2(\"%world%\");        Assert.assertTrue(dtos.size() == 10);    }    /**     * keith-fix 会报错，问题暂时不知     */    @Test    public void findMap() {        List&lt;Map&lt;String, Object&gt;&gt; listMaps = sampleRepository.findMap();        Assert.assertTrue(listMaps.size() == 10);    }}总结从上面给出的代码可以看出spring-data-jpa-extra确实很强大，在开发中效率能提高很多，希望本文能帮助到大家，同时在这里还要感谢作者的付出，谢谢  Reference:      https://github.com/slyak/spring-data-jpa-extra    https://blog.csdn.net/qq_27384769/article/details/79283391  ","categories": ["java"],
        "tags": ["java","jpa","spring boot","spring data jpa","mybatis","template","query"],
        "url": "http://www.thxopen.com/java/2018/09/19/use-spring-data-jpa-extra-to-write-sql-like-mybatis.html",
        "teaser":null},{
        "title": "Spring Data JPA自动创建表同时生成表和列的注释",
        "excerpt":"创建表格时同时带上注释一般情况下我们使用注解的方式很方便的就可以通过java类生成数据库的表，然后把注释写在字段上，就像下面一样import lombok.Data;import javax.persistence.Entity;import javax.persistence.Table;/** * demo例子 * &lt;p&gt; * 2018/9/18 * * @author Keith * @version v0.0.1 */@Entity@Table(name = \"tb_sample\")@Datapublic class Sample {    /**     * 内容字段     */    private String content;}乍看，觉得已经很明白了，后面维护的人也能看明白。但如对于维护数据库的人来说可能就不是那么容易了，因为他们从数据库里看到的是下面的语句CREATE TABLE `tb_sample` (  `content` varchar(255) DEFAULT NULL) ENGINE=InnoDB AUTO_INCREMENT=92 DEFAULT CHARSET=utf8;确实，这样看起来不怎么友好，为了解决这个问题，我们可以利用org.hibernate.annotations.Table注解和javax.persistence.Column给表和列添加注释，更改之后如下所示：import lombok.Data;import org.hibernate.annotations.Table;import javax.persistence.Column;import javax.persistence.Entity;/** * demo例子 * &lt;p&gt; * 2018/9/18 * * @author Keith * @version v0.0.1 */@Entity(name = \"tb_sample\")@Table(appliesTo = \"tb_sample\",comment = \"demo例子\")@Datapublic class Sample {    @Column(columnDefinition = \"varchar(255) COMMENT '测试字段'\")    private String content;}这样自动创建的表格在数据库里就会是下面的样子：CREATE TABLE `tb_sample` (  `content` varchar(255) DEFAULT NULL COMMENT '测试字段') ENGINE=InnoDB AUTO_INCREMENT=92 DEFAULT CHARSET=utf8 COMMENT='demo例子';这样，不仅java开发能方便的知道实体和每个字段的意思，维护数据库的人也没有压力，是不是挺方便的注意事项使用上面的方式，虽然挺方便，但需要注意以下三点：  1.数据库是mysql  2.需要配合Entity注解name属性一起使用，用上面的例子说明    @Entity(name = \"tb_sample\")@Table(appliesTo = \"tb_sample\",comment = \"demo例子\")public class Sample {        这里Entity的name的值要和Table的appliesTo的值一样。一般情况下，我们没有给Entity的name赋值，默认就是实体的名称（这里是Sample），如果你不指定Entity的name，那么Table的appliesTo的值为Sample，即数据库表名也为Sample    3.实体的别名不再默认是类名，而是name的值这就意味着Repository里本来是可以写类名的（因为默认是Sample）而要写成tb_sample（如下面代码），否则语句会解析错误，报找不到Sample这个实体    @Modifying@Query(\"delete from tb_sample d where d.content=:content\")int deleteByContent(@Param(\"content\") String content);        Reference:      https://segmentfault.com/a/1190000015047290    https://blog.csdn.net/xiaxia_jessica/article/details/43274735  ","categories": ["java"],
        "tags": ["java","jpa","spring boot","spring data jpa","mysql","comment","table","column"],
        "url": "http://www.thxopen.com/java/2018/09/19/use-spring-data-jpa-to-gen-table-and-column-comment-in-mysql.html",
        "teaser":null},{
        "title": "一个Java Developer从windows转mac的那点事",
        "excerpt":"前言从工作以来一直都是使用windows系统，随着工作时间的增长，身边还有使用mac的。都说开发使用mac是绝配，我也没有体验过，只是听说，直到自己真实体验了mac后，一发不可收拾，系统的流畅，让我欲罢不能。不过这么说也有点偏激，但是我也没办法，来看看为什么会这样。      我第一台笔记本（联想 y450）购于2009年10月，退役与2017年2月（没有坏，只是慢了点，除了开发，其他的事情还是杠杠滴）。        然后接着又购买了一台超级本（联想 yoga 910），使用她开发了接近2年。但由于是低压的cpu（很后悔买了这个笔记本做开发，当时不知道怎么想的，买了个低压的），以至于我稍微开多了程序，她就会表现的很不好，让我对低压的笔记本已经很抵触。    ps:做开发的一定不要买低压的cpu，一定！！！      2018年3月我头脑发热，在苹果官网下单了15寸的MacBook Pro（16年款，￥26,488），本来满怀期待，结果第二天早晨我又把订单取消了，原因是朋友告诉我马上要上新一代的cpu了，现在买就太亏了。我想想，16年我没买，我选择18年买，都又要出新的了，确实，当时也没了解清楚，头一热就下单买了，可能是因为招行12期分期免息，让我霸气的就下单了（其实这样是不对的，爽了一时，要痛苦1年，面对接下来每个月2k的还款，我又是多么的伤心）        就在2018年7月份，苹果发布了18年款的MacBook Pro。cpu确实上了新一代的，而且还有更加强劲的i9处理器，这把我心动的，但是有点追求完美的我，不满足，依然忍住了，没有立马就去购买了。在接下来的几个月，我看了各位大神的使用体验，以及评价，发现虽然有了强劲的i9处理器，但因为框架没有更新，承受不住他的发热，导致i9达到一定温度后，会被降频，而不能发挥他本身的性能，这个让要求完美的我，更加纠结了。        纠结了几个月，最终，我抵挡不住诱惑，2018年11月我在网上租了一台MacBook Pro 14年款（ 2.2 GHz Intel Core i7，16G，256G ssd ，15寸），决定先试后买，这样就不会后悔了啊！11月2号收到笔记本后，很是激动！虽然是14年款，但是配置还是挺不错的，我不知道我这个时候要是有一台同配置的windows，使用起来是不是同样的感觉，快，舒服？如果有机会，我再去体验下高配置的windows再说吧。目前来说这台mac已经让我明显感觉用起来很舒服。使用了短短两周，已经喜欢上mac这种感觉，当我再次翻开我的yoga 910时，我已经受不了windows的卡顿，以及从睡眠中唤醒，要等很久才会流畅起来，而mac则像一个丝滑的巧克力在嘴中融化的感觉。  不过联想yoga 910和这款mac本身没有可比性，所以上面说的所有就不要当真啦。本篇文章的正题是下面即将要说的这些。毕竟使用了那么多年windows，一下子切换到mac下很多不习惯和不适应，稍不留神就把windows的习惯带到mac下来，没办法遇到问题只能网上搜一搜。鉴于后面我要购买自己的mac，我把我这个期间遇到的问题记录下来，方便后面再去查。下面这些就是我从windows切换到mac后不懂的，我总结下来，希望能帮助到需要的人。如果你一开始就是使用mac，本篇文章你也能收获很多。我分为以下几个大块，有简单的也有难一点的，没办法，谁叫我是一个开发呢？太喜欢喜欢折腾了……系统篇  打开终端  修改hosts  更改mac的名字  端口占用  tomcat启动提示permission denied  smb window 和 mac 互传文件  在Finder中查看文件大小快捷键篇  更改fn的行为  insert按键  delete反方向删除 fn+delete  ctrl+x    commond+c   alt+commond+v  重命名文件 回车  新建文件夹 commond+shift+n  打开文件/文件夹 commond+o硬件篇  滚轮方向  触控板设置开发篇  安装java环境  在虚拟机里安装windows10  安装virtualbox增强插件实现剪贴板共享，文件拖拽，文件夹共享（windows10）  在虚拟机里安装ubuntu Server  安装virtualbox增强插件实现文件夹共享（Ubuntu Server）  mac安装最新rvm 升级 ruby常用软件  上网          chrome      迅雷        娱乐          视频播放        社交          qq      微信      钉钉        办公          wps for Mac      有道云笔记      网易邮箱大师        工具          ftp软件      终端软件      虚拟机      文本编辑器      有道词典      OneDrive      intellij idea      mac独有功能  dashboard使用","categories": ["mac"],
        "tags": ["windows","mac"],
        "url": "http://www.thxopen.com/mac/2018/11/01/windows-to-mac-skills.html",
        "teaser":null},{
        "title": "如何修改macOS的鼠标滚轮方向",
        "excerpt":"说到鼠标滚轮，这应该是每个从windows转向mac后要遇到的问题，因为两个操作是反的，如果习惯了windows的操作方式，使用mac的时候会很不习惯。如何修改滚轮的方向和windows保持一致呢？【系统偏好设置】 - 【鼠标】 - 【滚动方向：自然】，取消勾选即可  苹果的逻辑是：你滚动鼠标滚轮是在控制屏幕和触摸板的逻辑是一致的，想把屏幕下面的内容拉出来，自然就该向上拉屏幕，也就要向上滚动鼠标滚轮——相当于直接把窗帘撩起来。  微软的逻辑是：你滚动鼠标滚轮是在控制屏幕上的滚动条滚动条当然是向下拉才能把内容拉上去——相当于是通过拉窗户旁边的线卷起窗帘。返回目录  Reference:      https://www.zhihu.com/question/22096248/answer/22485346  ","categories": ["mac"],
        "tags": ["mac","wheel","direction"],
        "url": "http://www.thxopen.com/mac/2018/11/03/hardware-how-to-change-wheel-direction-in-mac.html",
        "teaser":null},{
        "title": "macOS下如何修改hosts文件",
        "excerpt":"hosts文件（域名解析文件）是一个用于储存计算机网络中各节点信息的计算机文件。这个文件负责将主机名称映射到相应的IP地址。hosts文件通常用于补充或取代网络中DNS的功能。和DNS不同的是，计算机的用户可以直接对hosts文件进行控制。由于Mac OS是属于类unix，一些能在unix下用的命令在macOS上也同样试用，而且目录结构也比较相似。作为开发者，我推荐试用命令行方式修改hosts文件，简单快速（如果你有linux的使用经验，你也会认同的）macOS的hosts文件存放在 /etc 目录下  ps:操作下面的命令你需要有vi命令的基础才行  第一步：vi命令打开hosts文件（因为是系统文件，需要使用sudo，会要求输入用户的密码）$ sudo vi /etc/hosts 执行完成后是下面的样子：### Host Database## localhost is used to configure the loopback interface# when the system is booting.  Do not change this entry.##127.0.0.1       localhost::1             localhost  第二步：输入 i 进入编辑模式，在文件末尾添加自己需要添加的映射即可，然后 esc 退出编辑模式，最后输入:wq! 保存并退出（如果不希望更改，输入:q! 直接退出即可）简单的两步操作即可完成对hosts文件的编辑返回目录  Reference:      https://zh.wikipedia.org/wiki/Hosts%E6%96%87%E4%BB%B6    https://www.jianshu.com/p/752211238c1b  ","categories": ["mac"],
        "tags": ["mac","hosts"],
        "url": "http://www.thxopen.com/mac/2018/11/03/system-how-to-modify-host-in-mac.html",
        "teaser":null},{
        "title": "如何修改macOS的触控板滚动方向，点击行为和锁定",
        "excerpt":"触摸板也是mac电脑的一个特色，也是大家喜欢mac的一个重要原因之一。如果操作得好可以完全不需要鼠标，简直就是神器不过刚从windows切换过来有些操作还是不太习惯，主要是以下几个操作：触摸板控制滚轮在windows下虽然鼠标的滚轮是随着滚动条的方向，但是在触摸板上却是跟着屏幕内容滚动（联想yoga 910 就是这样），用了mac后才发现这个叫自然滚动，如果发现滚动方向别扭通过下面的设置更改回来。在mac下进入到【系统偏好设置】 - 【触控板】 - 【滚动缩放】 - 【滚动方向：自然】，勾选上轻触点击习惯了windows的触控板后，轻触就是鼠标左键点击，但mac默认不是这样的，必须要按下触控板才能点击，让我感觉到很不习惯。通过下面的设置可以达到我的要求同样还是在【系统偏好设置】 - 【触控板】- 【光标与点按】 - 【轻点来点按】，勾选上连续轻触两下锁定在windows下还有一个操作已经习惯了，前面是轻触一下代表点按，这下要说的是鼠标点住左键不放（轻触两下触控板完成），mac下默认不是这样，想要拖动窗口，或者选中文字需要按照下面的设置才能解决【系统偏好设置】 - 【辅助功能】- 【鼠标与触控板】 - 【触控板选项】 - 【启动拖拽】，勾选上，并且选择【三指拖移】 mac里没有完全等价的操作，只能说【三指拖移】暂且解决了我的问题，【使用拖移锁定】或者 【不是用拖移锁定】可以自己尝试，我觉得达不到我要的效果。选择【三指拖移】后，切换桌面的操作就变成四指了，这个要取舍一下返回目录  Reference:      https://sspai.com/post/44173  ","categories": ["mac"],
        "tags": ["mac","touchpad"],
        "url": "http://www.thxopen.com/mac/2018/11/04/hardware-touch-pad-function.html",
        "teaser":null},{
        "title": "在虚拟机里安装Ubuntu Server 16",
        "excerpt":"服务器环境大部分都是linux，作为开发来说，和线上环境保持一致会比较方便，而且开发起来也会比较方便。虽然macOS也是类unix，但终究还是有点区别，况且安装了虚拟机出了问题还可以重来。对本身的系统保持一个好的状态，这是我们首先要做到的，想起以前学oracle的时候，在本机安装，结果没装好，连系统都要重做，那是多么痛苦的一段经历。准备工作  virtualbox（虚拟机软件）  Ubuntu Server 下载页面          Ubuntu 16.04.5 Server (64-bit) 种子      通过上面的连接，下载virtualbox和ubuntu server的安装镜像，我们就可以开始了开始安装一，配置虚拟机      1，虚拟机名称和系统类型，这里系统类型选择【Linux】，版本选择【Ubuntu（64-bit）】        2，内存大小，这里可以根据软件推荐的大小配置，我这里推荐的是1G（1024 MB），为了系统更加流畅，我调到 4G （4096 MB）。可以根据电脑的配置适当上调        3，虚拟硬盘，选择【现在创建虚拟硬盘】                  3-1，虚拟硬盘文件类型，选择【VDI（VirtualBox 磁盘映像）】                      3-2，存储在物理硬盘上，选择【动态分配】                      3-3，文件位置和大小，输入磁盘映像的文件名，或者保持默认，调整磁盘大小到10G  （因为是动态分配，这里如果选择超过电脑本身物理大小也没有关系，假设我选择了1T，代表最大不能超过该设定的值，文件实际大小是没有1T的。  所以尽量设置大一些，避免后面系统使用时间越长，占用空间也越大）                    4，配置启动光盘，选择建好的虚拟机，点击【设置】                  4-1，选择【存储】                      4-2，选中光驱，在右边操作界面点击【光盘】按钮                      4-3，添加下载好的Ubuntu Server iso文件，点击【ok】                    5，选择新建的虚拟机，点击【启动】，稍等片刻，进入到安装界面  二，安装Ubuntu Server      1，进入安装界面，首先需要选择语言，这里选择【English】（这里不选择中文是因为安装会有问题，据说是一个bug）        2，选择语言后，进入到ubuntu正式安装界面，选择【Install Ubuntu Server】    3, 在正式安装之前，先看看 Ubuntu 安装程序主菜单，如果在安装过程中出现了问题，可以返回到主菜单，重试某些步骤（实际安装过程直接进入第四步，不会有此界面）          选择安装语言      允许盲人使用盲人显示器访问软件      配置键盘      探测并挂在光盘      装载 debconf 预配置文件      从光盘加载安装程序组件      改变 debconf 的优先级设置      检测光盘的完整性      保存调试日志      允许 shell      终止安装            4，选择安装语言，这里选择【English】        5，选择你的位置，这里选择【United States】        6，配置键盘布局，是否检测键盘布局，这里选择【No】         7，配置键盘布局，选择键盘类型，这里选择【English（US）】        8，配置键盘布局，选择键盘布局，这里选择【English（US）】        9，生效以上配置，需要等待一会儿        10，配置网络，设置hostname，这里输入【ubuntunode1.thxopen.com】，然后选择【Continue】(ps：目的是在其他机器上通过此hostname访问到主机，可以是任意的字符串)        11，设置用户和密码，输入用户的全称，这里输入【ubuntu】，然后选择【Continue】        12，设置用户和密码，输入用户的登录账号，这里输入【ubuntu】，然后选择【Continue】        13，设置用户和密码，输入登录账号的密码，这里输入【12345678】，然后选择【Continue】（根据实际需求设置相应强度的密码）        14，设置用户和密码，重复上一步输入的密码，这里输入【12345678】，然后选择【Continue】        15，设置用户和密码，由于这里密码设置过于简单，提示是否要使用弱密码，这里选择【Yes】        16，设置用户和密码，是否加密home目录，这里选择【No】        17，生效以上配置，需要等一会儿        18，配置时钟，检测到当前时区是亚洲、重庆，这里选择【Yes】        19，磁盘分区，分区方式，这里选择【Guided - use entire disk】使用全部磁盘        20，磁盘分区，选择用来分区的磁盘，这里选择【ATA VBOX HARDDISK】(前面新建虚拟机时候创建的)        21，磁盘分区，使用默认的分区配置，这里选择【Yes】使用默认的配置来分区磁盘        22，生效以上配置，需要等待一会儿        23，配置包管理器，是否设置代理服务器，这里留空，不填写，直接【Continue】        24，配置自动升级，这里选择【No automatic updates】（根据自己的需要是否自动更新系统保持系统安全）        25，选择需要安装的软件，这里勾选【standard system utilities】和【OpenSSH server】，然后选择【Continue】(方向键切换，空格键选择或取消)        26，生效以上配置，需要等一会儿        27，安装GRUB引导装载程序在磁盘上，选择【Yes】        28，安装完成，选择【Continue】系统自动重启        29，重启后自动进入到登录界面    30，输入前面步骤中设置的账号【ubuntu】和密码【12345678】，登录到系统返回目录  Reference:      https://www.linuxidc.com/Linux/2017-11/148341.htm  ","categories": ["mac"],
        "tags": ["ubuntu","mac","virtualbox"],
        "url": "http://www.thxopen.com/mac/2018/11/05/install-ubuntu-server-in-virtualbox.html",
        "teaser":null},{
        "title": "ubuntu server下安装Virtualbox增强插件-实现文件夹共享",
        "excerpt":"由于ubuntu server不是一个桌面系统，那么对于剪贴板，文件拖拽这些需求就没有那么强烈，不过文件的共享倒是一个基本的问题。为了方便虚拟机和主机之间的文件共享，虚拟机提供了virtualbox增强插件解决这个问题。启动ubuntu server虚拟机，按照以下步骤安装virtualbox增强插件一，安装virtualbox增强插件      1，左上角找到【Devices】- 【Insert Guest Additions CD Image…】    2，执行下面命令挂载CD    sudo mount /dev/cdrom /media/cdrom        挂载成功，进入目录可以看到VBoxLinuxAdditions.run安装脚本    ls /media/cdrom32Bit  AUTORUN.INF  cert  runasroot.sh  VBoxLinuxAdditions.run    VBoxWindowsAdditions-amd64.exe  VBoxWindowsAdditions-x86.exe64Bit  autorun.sh   OS2   TRANS.TBL     VBoxSolarisAdditions.pkg  VBoxWindowsAdditions.exe        3，安装VirtualBox guest additions所需要的依赖    sudo apt-get updatesudo apt-get install build-essential linux-headers-`uname -r`        4，执行VBoxLinuxAdditions.run脚本    sudo /media/cdrom/VBoxLinuxAdditions.run      二，配置增强插件      5，配置共享文件夹，【Devices】 - 【Shared Folders】 - 【Shared Folders Settings…】                  5-1,添加一个共享目录，点击右边的【➕】按钮                      5-2，选择本地的一个目录，【Folder Name】填写wwwroot（或者其他名称），然后勾选【Make Permanent】固定分配，点击【ok】                      5-3，保存共享文件夹配置，点击【ok】                5，重启vm    sudo shutdown -r now        6，待重启完毕，创建共享文件夹的挂载点    mkdir ~/wwwroot        7，把共享文件夹挂载到上一步创建的目录    sudo mount -t vboxsf -o uid=1000,gid=1000 wwwroot ~/wwwroot              ps:uid和gid的值为当前用户的，这样就可以用当前登录的用户访问共享文件夹里的内容，不然挂载的文件默认用户是root，组也是root组。通过命令id查看当前用户对应的信息        8，现在可以在vm内访问主机共享的文件夹类容    cd ~/wwwroot      返回目录  Reference:https://gist.github.com/estorgio/1d679f962e8209f8a9232f7593683265https://ubuntuforums.org/showthread.php?t=1398340","categories": ["mac"],
        "tags": ["virtualbox","ubuntu server","文件夹共享"],
        "url": "http://www.thxopen.com/mac/2018/11/05/install-virtualbox-additions-for-ubuntu-server.html",
        "teaser":null},{
        "title": "windows下安装Virtualbox增强插件-实现文件夹共享，共享剪贴板，文件拖拽",
        "excerpt":"为了方便同时操作虚拟机（guest）和主机（host），剪贴板、文件拖拽和文件夹共享是必不可少的。首先启动虚拟机，按照下面的步骤，安装virtualbox增强插件即可解决这些问题。一，安装virtualbox增强插件      1，左上角找到【Devices】- 【Insert Guest Additions CD Image…】        2，然后打开我的电脑，可以看到CD驱动器已经加载        3，打开光盘，看到如下目录，双击【VBoxWindowsAdditions.exe】        4，所有操作都默认即可，一路点击【Next】，然后点击【Install】        5，系统设备安装提示，点击【安装】        6，安装完成，要求重启，点击【Finish】重启即可  二，配置增强插件      1，左上角找到【Devices】- 【Shared Clipboard】，选择【Bidirectional】，实现剪贴板共享，现在你可以在主机上复制，在虚拟机里粘贴（反之亦然，注意windows下是ctrl+c和ctrl+v，在mac下是commond+c和commond+v）        2，【Devices】 - 【Drag and Drop】，选择【Bidirectional】，实现文件拖拽，现在你可以拖拽文件到虚拟机，但是反过来不行，会报错，暂且没有找到方法，如果要从虚拟机拷贝文件到主机，参考下面【文件夹共享】        3，【Devices】 - 【Shared Folders】 - 【Shared Folders Settings…】                  3-1,添加一个共享目录，点击右边的【➕】按钮                      3-2，选择本地的一个目录，勾选【Auto-mount】自动挂载 和【Make Permanent】固定分配，点击【ok】                      3-3，保存共享文件夹配置，点击【ok】                      3-4，这个时候重启虚拟机，可以在网络位置看到共享的文件夹（ps：如果没有，检查windows10是否已经开启了网络发现）                ps：如果遇到粘贴板不能正常使用，检查是否升级了virtualbox软件，如果是，那么需要将对应的增强插件也需要升级，卸载掉已经安装的增强插件，按照以上步骤重新安装增强插件即可返回目录","categories": ["mac"],
        "tags": ["virtualbox","windows10","文件夹共享","共享剪贴板","文件拖拽"],
        "url": "http://www.thxopen.com/mac/2018/11/05/install-virtualbox-additions-for-windows.html",
        "teaser":null},{
        "title": "在虚拟机里安装windows10",
        "excerpt":"见过很多人购买了mac后安装的是windows，现在看来只能说windows普及的好，用不习惯就是用不习惯，mac装windows又怎么了？macOS的确很流畅，就像苹果手机和安卓手机那样的区别，没有细究过为什么macOS系统要比windows流畅，但是不管怎么说各有所长，你要打游戏那就选windows，他们都只是一个工具，哪个用着上手舒服，你就选择那个。同时需要多个操作系统的时候怎么办呢？有些只能在windows下才能运行的程序又怎么办呢？虚拟机在这方面帮我们解决了很多问题，找到问题的解决办法就行，没有绝对的对与错，好与坏。准备工作  virtualbox（虚拟机软件）  windows10 iso通过上面的连接，下载virtualbox和windows10的安装镜像，我们就可以开始了开始安装一，配置虚拟机      1，虚拟机名称和系统类型，这里系统类型选择【Microsoft Windows】，版本选择【windows 10（64-bit）】        2，内存大小，这里可以根据软件推荐的大小配置，我这里推荐的是2G（2048 MB），为了系统更加流畅，我调到 4G （4096 MB）。可以根据电脑的配置适当上调        3，虚拟硬盘，选择【现在创建虚拟硬盘】                  3-1，虚拟硬盘文件类型，选择【VDI（VirtualBox 磁盘映像）】                      3-2，存储在物理硬盘上，选择【动态分配】                      3-3，文件位置和大小，输入磁盘映像的文件名，或者保持默认，调整磁盘大小到50G  （因为是动态分配，这里如果选择超过电脑本身物理大小也没有关系，假设我选择了1T，代表最大不能超过该设定的值，文件实际大小是没有1T的。  所以尽量设置大一些，避免后面系统使用时间越长，占用空间也越大）                    4，配置启动光盘，选择建好的虚拟机，点击【设置】                  4-1，选择【存储】                      4-2，选中光驱，在右边操作界面点击【光盘】按钮                      4-3，添加下载好的windows10 iso文件，点击【ok】                    5，选择新建的虚拟机，点击【启动】，稍等片刻，进入到安装界面  二，安装 windows 10      6，进入到windows10的安装界面，点击【下一步】        7，点击【现在安装】        8，要求输入产品密钥，点击【我没有产品密钥】        9，选择安装的版本，选择【windows 10 专业版】，点击【下一步】        10，适用的声明和许可条款，勾选【我接受许可条款】，点击【下一步】        11，选择安装类型，点击【自定义：仅安装 Windows（高级）】        12，选择安装windows的路径，由于是新装，选择我们新建的磁盘，点击【新建】，使用默认大小，点击【应用】                  12-1，确定创建额外分区，点击【确定】                      12-2，选择【主分区】，点击【下一步】                    13，开始安装，等待自动安装完成        14，安装完成后需要对windows10进行个性化配置，按照界面提示操作即可，到此windows10安装完成 :)  返回目录","categories": ["mac"],
        "tags": ["virtualbox","windows10","mac","虚拟机"],
        "url": "http://www.thxopen.com/mac/2018/11/05/install-windows10-in-virtualbox.html",
        "teaser":null},{
        "title": "在Docker上安装常用的和Java相关的工具",
        "excerpt":"之前已经写过在Ubuntu上安装常用的和Java相关的工具,这次要说的是如何在docker上安装这些工具。何为Docker？  Docker是一个开放源代码软件项目，让应用程序部署在软件货柜下的工作可以自动化进行，借此在Linux操作系统上，提供一个额外的软件抽象层，以及操作系统层虚拟化的自动管理机制。为什么要使用Docker？已经有现成的了，我就不再多说。之所以写这个，就是觉得Docker给我带来极大的便利，我同样希望更多人能够享受到Docker带来的好处。我一直有听说Docker，但一直没有揭开她神秘的面纱。终于我忍不住了，由于一次服务器故障，因为同事执行apt-get命令安装了新的软件，导致系统环境变量发生了改变，导致ssh服务异常，大家都不能远程连上服务器。这个问题在服务器上一直存在，之前不知道什么原因把让我下决心要去了解Docker。/usr/local/lib/libssl.so.1.0.0/usr/local/lib/libcrypto.so.1.0.0  Reference:      https://zh.wikipedia.org/wiki/Docker  ","categories": ["linux","docker"],
        "tags": ["ubuntu","rabbitmq","nginx","redis","jdk","mysql","jenkins","gitlab","mongodb"],
        "url": "http://www.thxopen.com/linux/docker/2019/03/11/install-java-ee-environment-on-docker.html",
        "teaser":null},{
        "title": "使用logback限制日志打印内容长度",
        "excerpt":"简介好的日志打印，对于程序的调试和查找问题是很重要的。目前广泛使用的是logback，配合lombok可以很方便的打印日志。@Slf4jpublic class LogExampleOther {    public static void main(String... args) {    log.error(\"Something else is wrong here\");  }}只需要在类上加上@Slf4j注解即可问题背景由于在实际开发过程中打印日志内容的长度是不可控的，我想在输出的时候控制内容长度，于是我书写如下代码：@Slf4jpublic class LogExampleOther {    public static void main(String... args) {    String message = \"Something else is wrong here\";    if(message.length &gt; 1000){        log.info(\"the content length over limit ，only show the part of front : {} \",message.substring(0,1000));    }else{        log.info(\"the content is {}\",message);    }  }}解决方案时隔多日，发现这样非常不友好，随着需要控制的地方越来越多，这个代码重复出现在项目的各个地方。我想有没有什么配置可以设置日志输出的最大长度呢？一番搜索后最终在logback的文档里找到了答案，原来官方已经提供了方法。以下是文档原文：  By default the relevant information is output as-is. However, with the aid of format modifiers it is possible to change the minimum and maximum width and the justifications of each data field.  The optional format modifier is placed between the percent sign and the conversion character or word.  The first optional format modifier is the left justification flag which is just the minus (-) character. Then comes the optional minimum field width modifier. This is a decimal constant that represents the minimum number of characters to output. If the data item contains fewer characters, it is padded on either the left or the right until the minimum width is reached. The default is to pad on the left (right justify) but you can specify right padding with the left justification flag. The padding character is space. If the data item is larger than the minimum field width, the field is expanded to accommodate the data. The value is never truncated.默认情况下输出给定的字符串，但借助修饰符可以配置最小和最大长度。在%和转换字符之间使用.（点）和-（减号）截断字符串&lt;pattern&gt;%-4relative [%thread] %-5level - %.-1024msg%n&lt;/pattern&gt;上面的输出模板会把超过1024个字符的输出截断，只显示前1024个字符。最终通过查询文档解决了我以前的疑问，让代码更加简洁。logback的转换符对照表为了配置适合自己的日志格式，我们必须弄清楚转换字符的意思，下面附一张logback的转换符对照表            转换字符      效果      解释                  c{length}   lo{length}   logger{length}      %logger mainPackage.sub.sample.Bar mainPackage.sub.sample.Bar      原始记录器名称                     %logger{5} mainPackage.sub.sample.Bar m.s.s.Bar                     C{length}   class{length}      %C mainPackage.sub.sample.Bar mainPackage.sub.sample.Bar      记录器所在类的全路径              contextName/cn             原始记录器上下文名称              d{pattern}   date{pattern}   d{pattern, timezone}   date{pattern, timezone}      %d 2019-4-12 18:01:54,123      日志打印时间                     %date{HH:mm:ss.SSS} 18:01:54.123                     F/file      %F Bar.java      java文件名称              caller{depth} caller{depthStart..depthEnd}  caller{depth, evaluator-1, … evaluator-n}  caller{depthStart..depthEnd, evaluator-1, … evaluator-n}             记录器调用者位置信息              L / line             日志输出所在文件的行号              m / msg / message             日志具体内容              M / method             方法名              n             换行符              p / le / level             日志级别              r / relative             输出自应用程序启动以来直到创建日志记录事件所经过的毫秒数              t / thread             当前线程的名称              X{key:-defaultVal}   mdc{key:-defaultVal}             输出与生成日志记录事件的线程关联的MDC（映射的诊断上下文）              ex{depth}   exception{depth}   throwable{depth}   ex{depth, evaluator-1, …, evaluator-n}   exception{depth, evaluator-1, …, evaluator-n}   throwable{depth, evaluator-1, …, evaluator-n}             输出与日志记录事件关联的异常的堆栈信息。默认情况下，将输出完整堆栈              xEx{depth}   xException{depth}   xThrowable{depth}   xEx{depth, evaluator-1, …, evaluator-n}   xException{depth, evaluator-1, …, evaluator-n}   xThrowable{depth, evaluator-1, …, evaluator-n}             与上面的％throwable相同，但添加了类包装信息              nopex/nopexception             不输出任何信息，有效的忽略了异常              marker             输出与记录器请求关联的标记              property{key}             输出名为key属性关联的值              replace(p){r, t}             替换‘p’内容中‘r’为‘t’，正则表达式操作              rEx{depth}   rootException{depth}   rEx{depth, evaluator-1, …, evaluator-n}   rootException{depth, evaluator-1, …, evaluator-n}             输出与日志记录事件关联的异常的堆栈        Reference:      https://logback.qos.ch/manual/layouts.html#formatModifiers    https://stackoverflow.com/questions/35710008/limit-message-size-in-logback    https://stackoverflow.com/questions/32704470/can-a-logback-message-field-be-truncated-trimmed-to-n-characters  ","categories": ["java"],
        "tags": ["logback","layout","pattern"],
        "url": "http://www.thxopen.com/java/2019/04/12/limit-message-size-in-logback.html",
        "teaser":null},{
        "title": "使用Docker安装oracle 11g",
        "excerpt":"一，简介Oracle Database，又名Oracle RDBMS，或简称Oracle。是甲骨文公司的一款关系数据库管理系统。借助docker，安装oracle不再困难，只需要几步即可。需要注意，在参考本文章之前，需要具备操作docker的基础，怎么使用docker，可以参考这里二，安装2.1、安装oracle 11g镜像到docker2.1.1、搜索符合条件的镜像docker search oracleNAME                                  DESCRIPTION                                     STARS               OFFICIAL            AUTOMATEDoraclelinux                           Official Docker builds of Oracle Linux.         573                 [OK]jaspeen/oracle-11g                    Docker image for Oracle 11g database            99                                      [OK]oracle/openjdk                        Docker images containing OpenJDK Oracle Linux   55                                      [OK]……2.1.2、选择安装 jaspeen/oracle-11g，等待下载安装完成docker pull jaspeen/oracle-11g2.1.3、查看下载好的镜像docker imagesREPOSITORY                 TAG                 IMAGE ID            CREATED             SIZEjaspeen/oracle-11g         latest              0c8711fe4f0f        3 years ago         281MB注意，这个镜像没有直接安装好oracle，他帮我们配置好了环境，提供了安装脚本，我们只需要按照要求把oracle的安装目录配置好，启动镜像，即可2.2、准备oracle 11g安装文件2.2.1、下载oracle 11g安装文件从oracle 官网下载所需要的安装包，这里我们以oracle 11g为例子，分别下载 linux.x64_11gR2_database_1of2.zip 和 linux.x64_11gR2_database_2of2.zip两个压缩包，下载完成后解压到D盘(如下目录结构)D:.└─oracleinstall    └─database        ├─doc        ├─install        ├─response        ├─rpm        ├─sshsetup        ├─stage        ├─runInstaller        └─welcome.html2.3、安装oracle2.3.1、注意事项为什么要解压成上面的目录结构，我们先来看看jaspeen/oracle-11g镜像提供的安装脚本#!/usr/bin/env bashset -esource /assets/colorechotrap \"echo_red '******* ERROR: Something went wrong.'; exit 1\" SIGTERMtrap \"echo_red '******* Caught SIGINT signal. Stopping...'; exit 2\" SIGINTif [ ! -d \"/install/database\" ]; then\techo_red \"Installation files not found. Unzip installation files into mounted(/install) folder\"\texit 1fiecho_yellow \"Installing Oracle Database 11g\"su oracle -c \"/install/database/runInstaller -silent -ignorePrereq -waitforcompletion -responseFile /assets/db_install.rsp\"/opt/oracle/oraInventory/orainstRoot.sh/opt/oracle/app/product/11.2.0/dbhome_1/root.sh从脚本里可以看到它会读取/install/database目录，如果不存在会给出提示Installation files not found. Unzip installation files into mounted(/install) folder2.3.2、启动镜像（执行安装oracle）命令的解释：  docker run 启动容器的命令  privileged 给这个容器特权，安装oracle可能需要操作需要root权限的文件或目录  name 给这个容器名一个名字  p 映射端口  v 挂在文件到容器指定目录 (d:/oracleinstall/database 对应容器 /install/database)  jaspeen/oracle-11g 代表启动指定的容器docker run --privileged --name oracle11g -p 1521:1521 -v d:/oracleinstall:/install jaspeen/oracle-11gDatabase is not installed. Installing...Installing Oracle Database 11gStarting Oracle Universal Installer...Checking Temp space: must be greater than 120 MB.   Actual 47303 MB    PassedChecking swap space: must be greater than 150 MB.   Actual 1023 MB    PassedPreparing to launch Oracle Universal Installer from /tmp/OraInstall2019-04-17_08-14-23AM. Please wait ...You can find the log of this install session at: /opt/oracle/oraInventory/logs/installActions2019-04-17_08-14-23AM.log ……这个安装过程会很漫长，日志也很多，这里只提供部分。注意到日志里有 100% complete 打印，代表oracle安装成功2.3.3、安装完成再次查看运行状态，oracle已经启动完成docker ps -aCONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS                      PORTS                                                                             NAMES7f53f07c93e5        jaspeen/oracle-11g   \"/assets/entrypoint.…\"   About an hour ago   Up About an hour            0.0.0.0:1521-&gt;1521/tcp, 8080/tcp                                                  oracle11g2.3.4、其他需要注意的，如果日志长时间没有更新，检查docker是否已经死掉查看docker的状态docker ps -aError response from daemon: An invalid argument was supplied.如果出现如上提示，表示docker已经死掉，我们只需要重新执行安装步骤，让oracle安装完成  ps:根据我的猜测，我给docker分配的资源不够导致的，我重新把docker的内存和cpu调高一点后oracle顺利安装完成。docker rm oracle11gdocker run --privileged --name oracle11g -p 1521:1521 -v oracleinstall:/install jaspeen/oracle-11g三，配置默认scott用户是被锁定的，我们需要解锁，通过数据库工具即可成功连接到oracle3.1，连接到容器，docker exec -it oracle11g /bin/bash3.2，切换到oracle用户，然后连接到sql控制台[root@7f53f07c93e5 /]# su - oracleLast login: Wed Apr 17 08:29:31 UTC 2019[oracle@7f53f07c93e5 ~]$ sqlplus / as sysdbaSQL*Plus: Release 11.2.0.1.0 Production on Wed Apr 17 09:29:49 2019Copyright (c) 1982, 2009, Oracle.  All rights reserved.Connected to:Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL&gt;3.3，解锁账户SQL&gt; alter user scott account unlock;User altered.SQL&gt; commit;Commit complete.SQL&gt; conn scott/tigerERROR:ORA-28001: the password has expiredChanging password for scottNew password:Retype new password:Password changedConnected.SQL&gt; 3.4，使用dataGrip连接oracle数据库数据库安装完成后，使用默认的sid为orcl，端口为1521，scott/tiger即可连接  Reference:      https://zh.wikipedia.org/wiki/Oracle%E6%95%B0%E6%8D%AE%E5%BA%93    https://hub.docker.com/r/jaspeen/oracle-11g    https://stackoverflow.com/questions/37468788/what-is-the-right-way-to-add-data-to-an-existing-named-volume-in-docker    https://hub.docker.com/_/busybox    http://blog.grayidea.cn/archives/67    https://blog.csdn.net/u013238950/article/details/50999401  ","categories": ["linux","docker"],
        "tags": ["oracle 11g","docker"],
        "url": "http://www.thxopen.com/linux/docker/2019/04/17/install-oracle11g-on-docker.html",
        "teaser":null},{
        "title": "Caused by: java.lang.ClassNotFoundException: springfox.documentation.service.ApiInfo",
        "excerpt":"起因项目中需要使用swagger提供api文档，于是加上依赖：  &lt;dependency&gt;        &lt;groupId&gt;io.springfox&lt;/groupId&gt;        &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;        &lt;version&gt;2.2.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.springfox&lt;/groupId&gt;        &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;        &lt;version&gt;2.2.2&lt;/version&gt;    &lt;/dependency&gt;配置swagger扫描的路径：import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.ParameterBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.schema.ModelRef;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.Parameter;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;import java.util.ArrayList;import java.util.List;/** * swagger配置 * &lt;p&gt; * 2019年4月28日 * * @author Keith * @version v0.0.1 */@Configuration//开启swagger@EnableSwagger2public class Swagger2 {    //在配置文件里设置扫描controller的路径    @Value(\"${swagger.basePackage}\")    String basePackage;    @Bean    public Docket createRestApi() {        ParameterBuilder ticketPar = new ParameterBuilder();        List&lt;Parameter&gt; pars = new ArrayList&lt;Parameter&gt;();        ticketPar.name(\"Authorization\").description(\"token\")                .modelRef(new ModelRef(\"string\")).parameterType(\"header\")                .required(true).build(); //header中的ticket参数非必填，传空也可以        pars.add(ticketPar.build());    //根据每个方法名也知道当前方法在设置什么参数        return new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                .select()                .apis(RequestHandlerSelectors.basePackage(basePackage))                .paths(PathSelectors.any())                .build();//                .globalOperationParameters(pars)  ;  //所有接口请求需要带上的参数    }    private ApiInfo apiInfo() {        return new ApiInfoBuilder()                .title(\"接口名称)                .description(\"接口描述\")                .termsOfServiceUrl(\"服务url\")                .contact(\"联系人\")                .version(\"版本号\")                .build();    }}以上配置在另一个项目中是没问题的，我拷贝过来到新的项目上，启动tomcat，结果报如下错误：Caused by: java.lang.ClassNotFoundException: springfox.documentation.service.ApiInfo疑问intellij idea编译能通过，但是启动tomcat的时候却报类找不到，为什么呢？解决问题我使用的是intellij idea开发，我查看了编译好的war目录，虽然我maven已经引用了依赖，构建也没有问题，但我发现/WEB_INFO/lib确实没有swagger的相关jar。我把问题锁定到Artifacts配置上，我打开Project Structure -》 Project Settings -》Artifacts 发现Available Elements里面Swagger相关的jar没有打包war中，所以tomcat启动会提示类找不到。于是选中swagger相关jar，右键put into /WEB_INFO/lib，再次启动tomcat，问题得到解决。总结intellij idea在修改pom.xml后，没有自动把相关的jar构建到war中，导致发布到tomcat里的war缺失相关jar。手动把缺失的jar构建到war中即可解决问题。","categories": ["java","exception"],
        "tags": ["ClassNotFoundException","java","swagger","intellij idea"],
        "url": "http://www.thxopen.com/java/exception/2019/04/28/apiinfo-class-not-found.html",
        "teaser":null},{
        "title": "使用DataTables\"武装\"你的html表格——开刊",
        "excerpt":"前言三年前，《致在使用DataTables的小伙伴》，看到努力的自己，我想感谢我自己。谢谢你，谢谢一直努力的你！我还想说，我很幸运，我选择了Datatables。我也很感谢那些正在使用以及即将要使用Datatables的小伙伴，因为没有你们，就没有现在的DataTables中文网，没有你们，Datatables中文网也走不到今天。每当看到你们从中文网上获取到答案或者思路，我都感到无比的开心。我永远都忘不了当我使用Datatables服务器模式遇到问题解决不了的时候，有一个人帮我解决，然后我豁然开朗的感觉，我想大家每当问题得到解决的时候那种心情是多么的……但我也要批评我自己，批评自己不够坚持，没有做到有始有终，以为这样就足够了，这是对大家不负责也是对自己不负责。从2014年到2019年，Datatables中文网一直属于半成品状态。我高兴，因为上面的内容能够帮助大家，但我又悲伤，因为内容不够完整，不是所有人都能在上面得到答案。有的人说好，有的人说不好，以前我会在意这些看法，但是现在不会了，人无完人，也没有完美的东西。任何事情都是在一次次修正中，逐渐趋于完美。不管怎么样我还是坚持过来了，没有放弃，那么在接下来的时间里，不仅仅只是坚持，还要把它做得更好。现在越来越多的IT在线教育平台，讲各种各样的知识，技术，框架等等。我也经常会去上面学习，通过看视频，对自己的知识查漏补缺，还可以系统的梳理知识。而且对于一些质量好的视频看过之后有种醍醐灌顶，豁然开朗的感觉，如果看一次不懂还可以看第二次，三次，直到明白为止。正因为如此，我有了做视频的念头，如果我也能把我总结的经验说出来教给别人，把知识分享给更多人，岂不也是一件快乐的事情。所以，我做了。课程目的本次推出Datatables入门第二期 ——《使用Datatables”武装”你的html表格》，旨在给出一个系统的学习路径，解决如下问题：  不知道怎么学习Datatables  新老版本混用，不规范和不标准，阅读代码困难  滥用Datatables，小小需求就用插件导致项目臃肿  不知道怎么把Datatables的强大功能套用到自己的项目中  客户端模式和服务器模式什么区别，怎么使用  等等课程内容  开刊（即本节内容，已完成 2019年05月02日）  第一章，Datatables的6大特性(已完成 2019年06月09日)          DOM属性的介绍        第二章，对于各种数据源该怎么使用Datatables？          Dom数据源      javascript数据      Ajax数据      服务器模式        第三章，打造和自己项目贴近的表格          info，paging，processing，lengthChange，searching        第四章，更方便的操作表格数据          ajax      columns      row      draw      page        实战——制作一个具有增删改查功能的表格          行内编辑      弹框编辑        内容会有变动，只有视频录好后就定下内容，本目录会不断更新直到全部完结课程视频由于服务器不支持视频播放，鼠标右键点我，另存为到本地即可最后，谢谢大家的支持，如有错误的地方还望指出，如果您还有其他的建议或要求，欢迎在下方留言","categories": ["datatables"],
        "tags": ["datatables","视频","入门第二期"],
        "url": "http://www.thxopen.com/datatables/2019/05/02/how-to-make-your-table-stronger.html",
        "teaser":null},{
        "title": "在linux下从jar中替换、修改文件",
        "excerpt":"修改文件内容vi命令在linux下再熟悉不过了，搭配unzip和zip还可以修改压缩包里的文件。  ps: 如果本机还没有安装zip,unzip，先执行安装命令      sudo apt-get install unzip    sudo apt-get install zip  假设现在有如下结构的目录:HelloWorld/└── src    └── main        ├── META-INF        │   └── MANIFEST.MF        ├── java        │   └── com        │       └── thxopen        │           └── demo        │               └── Main.java        └── resources            └── demo.txtMain.java 文件内容如下：package com.thxopen.demo;import java.io.BufferedInputStream;import java.io.IOException;import java.io.InputStream;/** * @author Keith Shan * @date 2019年5月7日 * @site http://www.thxopen.com */public class Main {    public static void main(String[] args) {        System.out.println(\"Hello World!\");        InputStream uri = Main.class.getClassLoader().getResourceAsStream(\"demo.txt\");        BufferedInputStream bf = null;        try {            bf = new BufferedInputStream(uri);            byte[] b = new byte[bf.available()];            bf.read(b);            System.out.println(new String(b));        } catch (IOException e) {            e.printStackTrace();        } finally {            if (bf != null) {                try {                    bf.close();                } catch (IOException e) {                    e.printStackTrace();                }            }        }    }}代码很简单，输出一个Hello World! 然后读取resources/demo.txt文件内容并输出。我们把项目构建成jar上传到服务器，并在服务器上执行。下面是执行输出的结果thxopen@PC201503302026:~/work$ java -jar HelloWorld.jarHello World!I am Keith Shan.现在需要修改demo.txt的内容，改变输出，不需要重新打包上传，使用vi命令即可thxopen@PC201503302026:~/work$ vi HelloWorld.jar\" zip.vim version v28\" Browsing zipfile /home/thxopen/work/HelloWorld.jar\" Select a file with cursor and press ENTERMETA-INF/MANIFEST.MFcom/com/thxopen/com/thxopen/demo/com/thxopen/demo/Main.classdemo.txtMETA-INF/META-INF/HelloWorld.kotlin_module                               然后会列出jar里面的内容，把光标移动到需要编辑的文件，回车即可编辑。  ps: 如果文件比较多，可以使用/filename 来查找定位进入文件编辑状态后，操作就和vi命令一样，这里我新增I am the new String. 内容，:wq!保存退出vi，然后:exit退出jar编辑状态。重新执行thxopen@PC201503302026:~/work$ java -jar HelloWorld.jarHello World!I am Keith Shan.I am the new String.从输出可以看到demo.txt内容被成功修改替换文件修改文件内容对于.class文件来说似乎就不行了，那只能直接替换文件，如果替换文件呢？我修改Main.java文件，修改后内容如下：package com.thxopen.demo;/** * @author Keith Shan * @date 2019年5月7日 * @site http://www.thxopen.com */public class Main {    public static void main(String[] args) {        System.out.println(\"Class file modified\");    }}我把编译好的class文件放到 /com/thxopen/demo目录下，如下所示thxopen@PC201503302026:~/work$ tree.├── HelloWorld.jar└── com    └── thxopen        └── demo            └── Main.class (重新编译好的文件)3 directories, 2 files执行如下命令把文件替换到jar中thxopen@PC201503302026:~/work$ jar -uvf HelloWorld.jar com/thxopen/demo/Main.classadding: com/thxopen/demo/Main.class(in = 557) (out= 351)(deflated 36%)重新执行，class文件已经被替换thxopen@PC201503302026:~/work$ java -jar HelloWorld.jarClass file modified附：jar命令的基本用法thxopen@PC201503302026:~/work$ jarUsage: jar {ctxui}[vfmn0PMe] [jar-file] [manifest-file] [entry-point] [-C dir] files ...Options:    -c  create new archive    -t  list table of contents for archive    -x  extract named (or all) files from archive    -u  update existing archive 更新存在的压缩包    -v  generate verbose output on standard output 生成日志到标准输出    -f  specify archive file name 指定压缩包名称    -m  include manifest information from specified manifest file    -n  perform Pack200 normalization after creating a new archive    -e  specify application entry point for stand-alone application        bundled into an executable jar file    -0  store only; use no ZIP compression    -P  preserve leading '/' (absolute path) and \"..\" (parent directory) components from file names    -M  do not create a manifest file for the entries    -i  generate index information for the specified jar files    -C  change to the specified directory and include the following fileIf any file is a directory then it is processed recursively.The manifest file name, the archive file name and the entry point name arespecified in the same order as the 'm', 'f' and 'e' flags.Example 1: to archive two class files into an archive called classes.jar:       jar cvf classes.jar Foo.class Bar.classExample 2: use an existing manifest file 'mymanifest' and archive all the           files in the foo/ directory into 'classes.jar':       jar cvfm classes.jar mymanifest -C foo/ .","categories": ["linux"],
        "tags": ["jar","linux","vi","zip","unzip"],
        "url": "http://www.thxopen.com/linux/2019/05/07/how-to-modify-or-replace-file-from-jar-on-linux.html",
        "teaser":null},{
        "title": "请停止学习框架 - Stop Learning Frameworks",
        "excerpt":"最近阅读到一篇文章，原文标题《Stop Learning Frameworks》，读完之后感触很深，很赞同作者的观点，这里分享这篇文章，同时练习一下英语翻译，学习一些专业上的英语词汇和表达。下面是译文：请停止学习框架我们是开发者。我们需要与最新的技术保持同步。每天，我们学习编程语言，框架和第三方库。知道越前沿的技术越好。与Angular, React, Vue, Riot, Ember, Knockout这些技术保持同步是很有趣的。  但是我们在浪费时间.时间是我们最宝贵的财富。是有限的，不能再生，而且你不能买到更多。技术，比如时尚，它像光速一样在变化。为了抓住这些，我们必须奔跑。这场比赛没有赢家，因为比赛没有终点。我的导师有一次给我上了一堂课：      导师：“Ed，你在干什么？”    我（带着一种骄傲）：“我在读一本书，关于使用GWT构建现代java应用程序。”    导师：“为了什么？”    我：“作为一个java开发，我需要跟上潮流，而GWT就是潮流。”    导师：“在GWT之前你读过什么技术的书籍么？”    我：“是一本长达500页的 Apache Tapestry 书，Tapestry 之前是潮流”    导师：“Tapestry 现在任然是潮流么？”    我：“不再是，GWT现在是潮流”    导师：“你能重新使用 Tapestry 技能解决现在的问题么？ ”    我：“不行，目前没有人使用它。 ”    导师：“Tapestry 知识能帮你更好的理解 GWT么？ ”    我：“ 不，它不行。但是我看到了一些重叠的模式。 ”    导师：“ 那个是设计模式，它能帮你解决现在的问题么？ ”    我：“ 是的，大多数都可以 ”    导师：“ 新的技术层出不穷，消失也是常有的。但是他们有一些共同点。设置正确的优先级 ，投资80%的时间在学习基础知识上面，剩余的20%学习，库和工具。”    我：“ 额。。 只花20%的时间学习框架，库和工具？”    导师：“是的，反正你在工作中解决问题的时候会学习到”    我：“ 谢谢 ”    导师：“ 稍后再感谢 ”  这个建议改变了我的生活。我丢掉了书柜上所有框架的书，罪恶感从50减到0，终于解脱了！然后我买了一些经久不衰的书籍。这些书占据了我80%的学习时间：  The Pragmatic Programmer 程序员修炼之道: 从小工到专家  Clean Code  代码整洁之道  The Clean Coder 程序员的职业素养  Domain-Driven Design 领域驱动设计  Growing Object-Oriented Software, Guided by Tests 测试驱动的面向对象软件开发  Continuous Delivery 持续交付查看所有的书籍列表我还买了一本当前技术的书籍。根据“林迪效应”，spring框架必须是一个好的投资：  技术预期寿命和它们目前已经存在的时间成正比。每多生存一段时间，它的剩余预期寿命就会增加一点技术在市场上存活的时间越长，投资就越安全。不要急于学习新的技术，它很有可能会死。时间将会展示那些技术值得投资。时间是您最好的顾问。你要学会等待。从那以后的十年，我帮助了50个不同的软件项目。感谢导师的建议，我学到的一切都可以在公司，团队和行业适用。我学习的知识今天任然有用。我没有浪费我的时间。所有的项目看起来都不一样，但如果你看一下项目的内部：  编程语言不一样，但设计是一样的  框架不一样，从始至终就那些设计模式  开发人员不一样，但与人交往是的规则是一样的请记住，框架，库和工具这些层出不穷，消失也是常有的。时间是宝贵的。把你的黄金时间投入到可移植的总是相关的技能上面。  微服务  演进式架构  新的语言  代码整洁之道，设计模式，领域驱动设计  LeSS, SAFe  精益制造原则  Hystrix  容错模式  Docker  持续交付  Angular  WEB，HTTP 和 REST之所以对这个感触很深，我觉得我就陷入了这个死循环中。大数据热门，我就买了很多关于大数据的书籍，Hadoop，Hive，spark，Hbase等等。厚厚的几本书放在那儿吃灰，至今没有翻阅，即便是看了也只是学会了几个工具的使用，对于真正的MapReduce，HDFS这些基础的又理解了多少呢？为什么这些简单的道理自己不能误出来呢？万变不离其宗，所以只有基础扎实，工作中解决问题才能游刃有余。人与人之间交往好，和家人、朋友、同事都能相处好。","categories": ["life"],
        "tags": ["翻译","好文"],
        "url": "http://www.thxopen.com/life/2019/05/14/stop-learning-frameworks.html",
        "teaser":null},{
        "title": "Ctrl+C 和 Ctrl+V 是如何工作的？ - How does Ctrl+c and Ctrl+v work?",
        "excerpt":"本来忙着录视频，但运气不好跟公司发生了一点小矛盾，心情不美丽，所以就瞎逛，在 StackExchange 上看到有人提问“How does Ctrl+c and Ctrl+v work?”，一下就吸引了我的目光，这两个快捷键可是说我们天天都在用，但你要我说出来是如何工作的？我还真是不晓得，不多说，跟着提问者进去瞧瞧，到底是如何工作的？以下是译文:Question：Ctrl+C 和 Ctrl+V 是如何工作的?我一直很好奇，当我将图像（选择它使用快捷键Ctrl+c）复制到word文件（使用ctrl+v粘贴）幕后（操作系统层面）发生了什么事情？AnswerWindows在windows下，剪贴板API和存储缓冲区是由OS提供（显然是内核级别）：  Ctrl+C 告诉程序使用 Win32 API 方法 SetClipboardData()去存储“被复制”的数据","categories": ["life"],
        "tags": ["翻译","好文"],
        "url": "http://www.thxopen.com/life/2019/05/20/how-does-ctrl-c-and-ctrl-v-work.html",
        "teaser":null},{
        "title": "使用OBS录制屏幕",
        "excerpt":"由于要制作Datatables入门第二期视频，需要用到屏幕录制，在网上搜索了很多软件，最后发现OBS非常好。  OBS Studio - Free and open source software for live streaming and screen recording  OBS Studio - 直播和屏幕录制的免费开源软件这个简直太合我意了（偷笑中），不仅免费，而且功能强大，独乐了不如众乐乐，分享下如何使用OBS录制自己的屏幕。下载安装你可以通过官网下载对应的版本，支持windows、mac和linux。本次选择mac版作为例子来讲解。录制屏幕指定窗口录制和其他录制屏幕软件不同的是，OBS它可以指定应用程序窗口来录制，这样即便你在操作其他软件，也不会影响到录制软件打开后，默认会有一个场景，在对应场景里选中【窗口捕获】，点击下方的⚙配置选择窗口捕获来源在下拉列表里可以选择你要捕获的窗口，每个应用程序都会列在这里通过上面两个步骤的设置，就可以录制选定窗口不同应用程序切换在录制Datatables入门第二期视频时，会在ppt和IDE应用程序之间来回切换，这样就需要使用场景来实现。首先，点击左下角场景区域➕，新建一个场景，按照自己的需要命名其次，点击来源区域➕，新建捕获来源选择窗口捕获按照自己的需要命名选择窗口捕获来源最后就有两个场景可供录制我们为场景指定不同的快捷键，这样切换场景的时候就不用回到OBS软件操作点击上图右下方【设置】按钮，进入【热键】设置部分，给场景切换指定快捷键，这样在录制的时候我们可以随时切换录制那个场景  注意：不要设置和其他软件冲突的快捷键，不然会起冲突导致切换场景失效录制电脑输出声音默认设置下，视频录制的声音来自麦克风如果我在电脑上播放歌曲，这时候声音从扬声器播放，然后被麦克风采集（注意看下图两处红色框框，上方的代表在播放音乐，下方代表麦克风采集到扬声器声音）如果我想电脑的声音直接被OBS采集而不是通过麦克风采集，这里需要用到虚拟声卡 —— Soundflower第一步：安装Soundflower  Soundflower - a free audio system extension that allows applications to pass audio to other applications.  Soundflower - 一款免费的音频系统扩展，允许应用程序将音频传递到其他的应用程序。首先下载安装Soundflower，安装完成后打开【Launchpad】找到【音频MIDI设置】点击左下角➕ =》【创建多输出设备】=》点击标题处可以命名，这里重命名为【obs】=》勾选【内建输出】和【Soundflower(2ch)】  解释：这里创建多输出设备的用意在于在录制屏幕的时候同时可以听到电脑输出的声音，如果不设置录制视频的时候自己听不到声音，但视频可以采集到电脑输出的声音第二步：配置OBS上面配置好的虚拟声卡后，在OBS【设置】界面  =》 【音频】 =》 桌面音频设备选择【Soundflower(ch2)】 =》 麦克风/辅助音频设备选择【已禁用】然后电脑声音输出选择第一步新建的【obs】虚拟声卡  解释：由于obs是两个设备，一个是内置的扬声器，一个是虚拟声卡Soundflower(2ch)，这里选择输出设备为obs意味着声卡将会把声音从这两个设备输出，而在上面OBS 【音频】 设置里，我们把桌面音频设备选择的是Soundflower(2ch)，即我们想要的，录制的声音直接从电脑声卡采集，而不是从麦克风  ps: 在选择obs输出之前，请先调好声音大小，因为选择obs后将不能修改声音通过上面两步设置，我们录制屏幕的时候，声音就可以直接采集从电脑声卡输出的声音了  第一个红框表示电脑正在播放音乐  第二个红框表示OBS采集到声卡的输出","categories": ["tools"],
        "tags": ["obs","tools","录屏软件"],
        "url": "http://www.thxopen.com/tools/2019/06/08/record-screen-with-obs.html",
        "teaser":null},{
        "title": "Datatables的4大特性-dom的介绍",
        "excerpt":"本节为Datatables入门第二期 ——《使用Datatables”武装”你的html表格》的第一节，主要讲dom。课程简介何为dom，它是一个磨人的小妖精，之所以把dom放在开篇，我个人觉得它是一个核心，也是一个进入Datatables大门的钥匙，理解了dom算是使用Datatables的入门选手了。废话不多说，跟着视频来，看看dom究竟是什么？本节课程我从以下几个点来讲解：  如何使用Datatables？  理解Datatables基本模型DOM          length changing      filter      information      pagination        DOM引发的一系列”血案”，解密真相，揭开谜底          它的控件我不喜欢，想隐藏掉，怎么做？      表格上下都有翻页控件，怎么做?      按照自己的意愿摆放它的控件，怎么做？      我需要多个条件过滤，它只有一个搜索框，怎么做？      Bootstrap的布局自适应，使用很方便，Datatables可以套用么，怎么做？      改变各个控件的显示位置，怎么做？      通过简单的入门，原理的介绍，还有真实的案例，三部曲带领大家走进Datatables的大门。课程视频由于服务器不支持视频播放，鼠标右键点我，另存为到本地即可最后，谢谢大家的支持，如有错误的地方还望指出，如果您还有其他的建议或要求，欢迎在下方留言","categories": ["datatables"],
        "tags": ["datatables","视频","入门第二期"],
        "url": "http://www.thxopen.com/datatables/2019/06/09/datatables-dom-option.html",
        "teaser":null}]
